<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Module 8 Multivariate data analysis | Applied Biological Data Analysis</title>
  <meta name="description" content="Helping biologists to become more informed users of R and statistical methods." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Module 8 Multivariate data analysis | Applied Biological Data Analysis" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://greenquanteco.github.io/index.html" />
  <meta property="og:image" content="https://greenquanteco.github.io/index.html/C:/Users/ngreen62/OneDrive - Kennesaw State University/ksu/website/lab_logo_02.jpg" />
  <meta property="og:description" content="Helping biologists to become more informed users of R and statistical methods." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Module 8 Multivariate data analysis | Applied Biological Data Analysis" />
  
  <meta name="twitter:description" content="Helping biologists to become more informed users of R and statistical methods." />
  <meta name="twitter:image" content="https://greenquanteco.github.io/index.html/C:/Users/ngreen62/OneDrive - Kennesaw State University/ksu/website/lab_logo_02.jpg" />

<meta name="author" content="Nick Green, Kennesaw State University" />


<meta name="date" content="2022-01-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="mod-07.html"/>
<link rel="next" href="mod-09.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license-and-permissions"><i class="fa fa-check"></i>License and permissions</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-description"><i class="fa fa-check"></i>Course description</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-objectives"><i class="fa fa-check"></i>Course objectives</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-requirements"><i class="fa fa-check"></i>Course requirements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#recommended-reading"><i class="fa fa-check"></i>Recommended reading</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-organization"><i class="fa fa-check"></i>Course organization</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i>About the author</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="mod-01.html"><a href="mod-01.html"><i class="fa fa-check"></i><b>1</b> Statistics in modern biology</a>
<ul>
<li class="chapter" data-level="1.1" data-path="mod-01.html"><a href="mod-01.html#overview"><i class="fa fa-check"></i><b>1.1</b> Overview</a></li>
<li class="chapter" data-level="1.2" data-path="mod-01.html"><a href="mod-01.html#statistics-in-modern-biology"><i class="fa fa-check"></i><b>1.2</b> Statistics in modern biology</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="mod-01.html"><a href="mod-01.html#the-scientific-method"><i class="fa fa-check"></i><b>1.2.1</b> The scientific method</a></li>
<li class="chapter" data-level="1.2.2" data-path="mod-01.html"><a href="mod-01.html#example-data-analysis"><i class="fa fa-check"></i><b>1.2.2</b> Example data analysis</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="mod-01.html"><a href="mod-01.html#misuses-of-statistics"><i class="fa fa-check"></i><b>1.3</b> Misuses of statistics</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="mod-01.html"><a href="mod-01.html#proving-the-trivial-and-meaningless-hypotheses"><i class="fa fa-check"></i><b>1.3.1</b> “Proving” the trivial and meaningless hypotheses</a></li>
<li class="chapter" data-level="1.3.2" data-path="mod-01.html"><a href="mod-01.html#inappropriate-methods"><i class="fa fa-check"></i><b>1.3.2</b> Inappropriate methods</a></li>
<li class="chapter" data-level="1.3.3" data-path="mod-01.html"><a href="mod-01.html#p-hacking-and-data-dredging"><i class="fa fa-check"></i><b>1.3.3</b> <em>P</em>-hacking and data dredging</a></li>
<li class="chapter" data-level="1.3.4" data-path="mod-01.html"><a href="mod-01.html#inadequate-sample-sizes-and-pseudoreplication"><i class="fa fa-check"></i><b>1.3.4</b> Inadequate sample sizes and pseudoreplication</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="mod-01.html"><a href="mod-01.html#p-values-and-null-hypothesis-significance-testing-nhst"><i class="fa fa-check"></i><b>1.4</b> <em>P</em>-values and null hypothesis significance testing (NHST)</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="mod-01.html"><a href="mod-01.html#definition"><i class="fa fa-check"></i><b>1.4.1</b> Definition</a></li>
<li class="chapter" data-level="1.4.2" data-path="mod-01.html"><a href="mod-01.html#history-and-status-of-p-values"><i class="fa fa-check"></i><b>1.4.2</b> History and status of <em>P</em>-values</a></li>
<li class="chapter" data-level="1.4.3" data-path="mod-01.html"><a href="mod-01.html#where-p-values-come-from"><i class="fa fa-check"></i><b>1.4.3</b> Where <em>P</em>-values come from</a></li>
<li class="chapter" data-level="1.4.4" data-path="mod-01.html"><a href="mod-01.html#what-p-values-mean-and-do-not-mean"><i class="fa fa-check"></i><b>1.4.4</b> What <em>P</em>-values mean and do not mean</a></li>
<li class="chapter" data-level="1.4.5" data-path="mod-01.html"><a href="mod-01.html#do-you-need-a-p-value"><i class="fa fa-check"></i><b>1.4.5</b> Do you need a <em>P</em>-value?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="mod-01.html"><a href="mod-01.html#alternatives-to-nhst"><i class="fa fa-check"></i><b>1.5</b> Alternatives to NHST</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="mod-01.html"><a href="mod-01.html#bayesian-inference"><i class="fa fa-check"></i><b>1.5.1</b> Bayesian inference</a></li>
<li class="chapter" data-level="1.5.2" data-path="mod-01.html"><a href="mod-01.html#information-theoretic-methods"><i class="fa fa-check"></i><b>1.5.2</b> Information-theoretic methods</a></li>
<li class="chapter" data-level="1.5.3" data-path="mod-01.html"><a href="mod-01.html#machine-learning"><i class="fa fa-check"></i><b>1.5.3</b> Machine learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="mod-02.html"><a href="mod-02.html"><i class="fa fa-check"></i><b>2</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="mod-02.html"><a href="mod-02.html#getting-started-with-r"><i class="fa fa-check"></i><b>2.1</b> Getting started with R</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="mod-02.html"><a href="mod-02.html#what-is-r"><i class="fa fa-check"></i><b>2.1.1</b> What is R?</a></li>
<li class="chapter" data-level="2.1.2" data-path="mod-02.html"><a href="mod-02.html#advantages-of-r"><i class="fa fa-check"></i><b>2.1.2</b> Advantages of R</a></li>
<li class="chapter" data-level="2.1.3" data-path="mod-02.html"><a href="mod-02.html#disadvantages-of-r"><i class="fa fa-check"></i><b>2.1.3</b> Disadvantages of R</a></li>
<li class="chapter" data-level="2.1.4" data-path="mod-02.html"><a href="mod-02.html#base-r-and-vs.-tidyverse"><i class="fa fa-check"></i><b>2.1.4</b> Base R and (vs.?) <code>tidyverse</code></a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="mod-02.html"><a href="mod-02.html#download-and-install-r-and-rstudio"><i class="fa fa-check"></i><b>2.2</b> Download and install R (and RStudio)</a></li>
<li class="chapter" data-level="2.3" data-path="mod-02.html"><a href="mod-02.html#using-r"><i class="fa fa-check"></i><b>2.3</b> Using R</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="mod-02.html"><a href="mod-02.html#using-the-base-r-gui"><i class="fa fa-check"></i><b>2.3.1</b> Using the base R GUI</a></li>
<li class="chapter" data-level="2.3.2" data-path="mod-02.html"><a href="mod-02.html#using-r-in-rstudio"><i class="fa fa-check"></i><b>2.3.2</b> Using R in RStudio</a></li>
<li class="chapter" data-level="2.3.3" data-path="mod-02.html"><a href="mod-02.html#using-r-with-other-programs"><i class="fa fa-check"></i><b>2.3.3</b> Using R with other programs</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="mod-02.html"><a href="mod-02.html#mod-02-first"><i class="fa fa-check"></i><b>2.4</b> A first R session</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="mod-02.html"><a href="mod-02.html#import-data"><i class="fa fa-check"></i><b>2.4.1</b> Import data</a></li>
<li class="chapter" data-level="2.4.2" data-path="mod-02.html"><a href="mod-02.html#explore-and-visualize-data"><i class="fa fa-check"></i><b>2.4.2</b> Explore and visualize data</a></li>
<li class="chapter" data-level="2.4.3" data-path="mod-02.html"><a href="mod-02.html#transform-data"><i class="fa fa-check"></i><b>2.4.3</b> Transform data</a></li>
<li class="chapter" data-level="2.4.4" data-path="mod-02.html"><a href="mod-02.html#analyze-data"><i class="fa fa-check"></i><b>2.4.4</b> Analyze data</a></li>
<li class="chapter" data-level="2.4.5" data-path="mod-02.html"><a href="mod-02.html#write-out-results"><i class="fa fa-check"></i><b>2.4.5</b> Write out results</a></li>
<li class="chapter" data-level="2.4.6" data-path="mod-02.html"><a href="mod-02.html#save-your-work"><i class="fa fa-check"></i><b>2.4.6</b> Save your work?</a></li>
<li class="chapter" data-level="2.4.7" data-path="mod-02.html"><a href="mod-02.html#whats-next"><i class="fa fa-check"></i><b>2.4.7</b> What’s next?</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="mod-02.html"><a href="mod-02.html#write-and-execute-commands-in-the-r-console"><i class="fa fa-check"></i><b>2.5</b> Write and execute commands in the R console</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="mod-02.html"><a href="mod-02.html#r-commandsbasics"><i class="fa fa-check"></i><b>2.5.1</b> R commands–basics</a></li>
<li class="chapter" data-level="2.5.2" data-path="mod-02.html"><a href="mod-02.html#elements-of-r-code"><i class="fa fa-check"></i><b>2.5.2</b> Elements of R code</a></li>
<li class="chapter" data-level="2.5.3" data-path="mod-02.html"><a href="mod-02.html#the-r-workspace"><i class="fa fa-check"></i><b>2.5.3</b> The R workspace</a></li>
<li class="chapter" data-level="2.5.4" data-path="mod-02.html"><a href="mod-02.html#r-code-basics-assignment-and-operators"><i class="fa fa-check"></i><b>2.5.4</b> R code basics: assignment and operators</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="mod-02.html"><a href="mod-02.html#mod-02-struct"><i class="fa fa-check"></i><b>2.6</b> Basic R data structures</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="mod-02.html"><a href="mod-02.html#vectors"><i class="fa fa-check"></i><b>2.6.1</b> Vectors</a></li>
<li class="chapter" data-level="2.6.2" data-path="mod-02.html"><a href="mod-02.html#data-frames"><i class="fa fa-check"></i><b>2.6.2</b> Data frames</a></li>
<li class="chapter" data-level="2.6.3" data-path="mod-02.html"><a href="mod-02.html#matrices-and-arrays"><i class="fa fa-check"></i><b>2.6.3</b> Matrices and arrays</a></li>
<li class="chapter" data-level="2.6.4" data-path="mod-02.html"><a href="mod-02.html#lists"><i class="fa fa-check"></i><b>2.6.4</b> Lists</a></li>
<li class="chapter" data-level="2.6.5" data-path="mod-02.html"><a href="mod-02.html#s4-objects"><i class="fa fa-check"></i><b>2.6.5</b> S4 objects</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="mod-02.html"><a href="mod-02.html#r-data-types"><i class="fa fa-check"></i><b>2.7</b> R data types</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="mod-02.html"><a href="mod-02.html#character-type"><i class="fa fa-check"></i><b>2.7.1</b> Character type</a></li>
<li class="chapter" data-level="2.7.2" data-path="mod-02.html"><a href="mod-02.html#numeric-type"><i class="fa fa-check"></i><b>2.7.2</b> Numeric type</a></li>
<li class="chapter" data-level="2.7.3" data-path="mod-02.html"><a href="mod-02.html#integer-type"><i class="fa fa-check"></i><b>2.7.3</b> Integer type</a></li>
<li class="chapter" data-level="2.7.4" data-path="mod-02.html"><a href="mod-02.html#logical-type"><i class="fa fa-check"></i><b>2.7.4</b> Logical type</a></li>
<li class="chapter" data-level="2.7.5" data-path="mod-02.html"><a href="mod-02.html#special-values"><i class="fa fa-check"></i><b>2.7.5</b> Special values</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="mod-02.html"><a href="mod-02.html#manage-r-code-as-scripts-.r-files"><i class="fa fa-check"></i><b>2.8</b> Manage R code as scripts (.r files)</a></li>
<li class="chapter" data-level="2.9" data-path="mod-02.html"><a href="mod-02.html#manage-and-use-r-packages"><i class="fa fa-check"></i><b>2.9</b> Manage and use R packages</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="mod-02.html"><a href="mod-02.html#your-r-library"><i class="fa fa-check"></i><b>2.9.1</b> Your R library</a></li>
<li class="chapter" data-level="2.9.2" data-path="mod-02.html"><a href="mod-02.html#installing-packages-using-the-r-gui"><i class="fa fa-check"></i><b>2.9.2</b> Installing packages using the R GUI</a></li>
<li class="chapter" data-level="2.9.3" data-path="mod-02.html"><a href="mod-02.html#installing-packages-in-rstudio"><i class="fa fa-check"></i><b>2.9.3</b> Installing packages in RStudio</a></li>
<li class="chapter" data-level="2.9.4" data-path="mod-02.html"><a href="mod-02.html#installing-packages-using-the-r-console"><i class="fa fa-check"></i><b>2.9.4</b> Installing packages using the R console</a></li>
<li class="chapter" data-level="2.9.5" data-path="mod-02.html"><a href="mod-02.html#working-with-packages-in-r"><i class="fa fa-check"></i><b>2.9.5</b> Working with packages in R</a></li>
<li class="chapter" data-level="2.9.6" data-path="mod-02.html"><a href="mod-02.html#package-dependencies"><i class="fa fa-check"></i><b>2.9.6</b> Package dependencies</a></li>
<li class="chapter" data-level="2.9.7" data-path="mod-02.html"><a href="mod-02.html#citing-packages"><i class="fa fa-check"></i><b>2.9.7</b> Citing packages</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="mod-02.html"><a href="mod-02.html#r-documentation"><i class="fa fa-check"></i><b>2.10</b> R documentation</a>
<ul>
<li class="chapter" data-level="2.10.1" data-path="mod-02.html"><a href="mod-02.html#documentation-help-files"><i class="fa fa-check"></i><b>2.10.1</b> Documentation (help) files</a></li>
<li class="chapter" data-level="2.10.2" data-path="mod-02.html"><a href="mod-02.html#r-vignettes"><i class="fa fa-check"></i><b>2.10.2</b> R vignettes</a></li>
<li class="chapter" data-level="2.10.3" data-path="mod-02.html"><a href="mod-02.html#official-r-project-resources"><i class="fa fa-check"></i><b>2.10.3</b> Official R Project resources</a></li>
<li class="chapter" data-level="2.10.4" data-path="mod-02.html"><a href="mod-02.html#unofficial-online-resources"><i class="fa fa-check"></i><b>2.10.4</b> Unofficial online resources</a></li>
<li class="chapter" data-level="2.10.5" data-path="mod-02.html"><a href="mod-02.html#r-books"><i class="fa fa-check"></i><b>2.10.5</b> R books</a></li>
<li class="chapter" data-level="2.10.6" data-path="mod-02.html"><a href="mod-02.html#two-reminders"><i class="fa fa-check"></i><b>2.10.6</b> Two reminders</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mod-03.html"><a href="mod-03.html"><i class="fa fa-check"></i><b>3</b> Data manipulation with R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="mod-03.html"><a href="mod-03.html#mod-03-inout"><i class="fa fa-check"></i><b>3.1</b> Data import and export</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="mod-03.html"><a href="mod-03.html#importing-data-preliminaries"><i class="fa fa-check"></i><b>3.1.1</b> Importing data: preliminaries</a></li>
<li class="chapter" data-level="3.1.2" data-path="mod-03.html"><a href="mod-03.html#importing-data-from-text-files-with-read.csv-and-read.table"><i class="fa fa-check"></i><b>3.1.2</b> Importing data from text files with <code>read.csv()</code> and <code>read.table()</code></a></li>
<li class="chapter" data-level="3.1.3" data-path="mod-03.html"><a href="mod-03.html#importing-data-from-saved-workspaces"><i class="fa fa-check"></i><b>3.1.3</b> Importing data from saved workspaces</a></li>
<li class="chapter" data-level="3.1.4" data-path="mod-03.html"><a href="mod-03.html#importing-data-special-cases"><i class="fa fa-check"></i><b>3.1.4</b> Importing data: special cases:</a></li>
<li class="chapter" data-level="3.1.5" data-path="mod-03.html"><a href="mod-03.html#export-data-from-r"><i class="fa fa-check"></i><b>3.1.5</b> Export data from R</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="mod-03.html"><a href="mod-03.html#making-values-in-r"><i class="fa fa-check"></i><b>3.2</b> Making values in R</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="mod-03.html"><a href="mod-03.html#producing-arbitrary-values-with-c"><i class="fa fa-check"></i><b>3.2.1</b> Producing arbitrary values with <code>c()</code></a></li>
<li class="chapter" data-level="3.2.2" data-path="mod-03.html"><a href="mod-03.html#generating-regular-values"><i class="fa fa-check"></i><b>3.2.2</b> Generating regular values</a></li>
<li class="chapter" data-level="3.2.3" data-path="mod-03.html"><a href="mod-03.html#generating-random-values"><i class="fa fa-check"></i><b>3.2.3</b> Generating random values</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="mod-03.html"><a href="mod-03.html#selecting-data-with"><i class="fa fa-check"></i><b>3.3</b> Selecting data with <code>[]</code></a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="mod-03.html"><a href="mod-03.html#mod-03-brackets"><i class="fa fa-check"></i><b>3.3.1</b> Basics of brackets</a></li>
<li class="chapter" data-level="3.3.2" data-path="mod-03.html"><a href="mod-03.html#extracting-and-selecting-data-with-logical-tests"><i class="fa fa-check"></i><b>3.3.2</b> Extracting and selecting data with logical tests</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="mod-03.html"><a href="mod-03.html#managing-dates-and-characters"><i class="fa fa-check"></i><b>3.4</b> Managing dates and characters</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="mod-03.html"><a href="mod-03.html#temporal-data-and-dates"><i class="fa fa-check"></i><b>3.4.1</b> Temporal data and dates</a></li>
<li class="chapter" data-level="3.4.2" data-path="mod-03.html"><a href="mod-03.html#character-data-text"><i class="fa fa-check"></i><b>3.4.2</b> Character data (text)</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="mod-03.html"><a href="mod-03.html#mod-03-dataframe"><i class="fa fa-check"></i><b>3.5</b> Data frame management</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="mod-03.html"><a href="mod-03.html#data-frame-structure"><i class="fa fa-check"></i><b>3.5.1</b> Data frame structure</a></li>
<li class="chapter" data-level="3.5.2" data-path="mod-03.html"><a href="mod-03.html#common-data-frame-operations"><i class="fa fa-check"></i><b>3.5.2</b> Common data frame operations</a></li>
<li class="chapter" data-level="3.5.3" data-path="mod-03.html"><a href="mod-03.html#other-data-frame-operations"><i class="fa fa-check"></i><b>3.5.3</b> Other data frame operations</a></li>
<li class="chapter" data-level="3.5.4" data-path="mod-03.html"><a href="mod-03.html#mod-03-reshape"><i class="fa fa-check"></i><b>3.5.4</b> Reshaping data frames</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="mod-04.html"><a href="mod-04.html"><i class="fa fa-check"></i><b>4</b> Exploratory data analysis</a>
<ul>
<li class="chapter" data-level="4.1" data-path="mod-04.html"><a href="mod-04.html#descriptive-and-summary-statistics"><i class="fa fa-check"></i><b>4.1</b> Descriptive and summary statistics</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="mod-04.html"><a href="mod-04.html#basic-summary-statistics"><i class="fa fa-check"></i><b>4.1.1</b> Basic summary statistics</a></li>
<li class="chapter" data-level="4.1.2" data-path="mod-04.html"><a href="mod-04.html#summarizing-data-with-the-apply-family"><i class="fa fa-check"></i><b>4.1.2</b> Summarizing data with the <code>apply()</code> family</a></li>
<li class="chapter" data-level="4.1.3" data-path="mod-04.html"><a href="mod-04.html#mod-04-tabagg"><i class="fa fa-check"></i><b>4.1.3</b> Tabulation and aggregation</a></li>
<li class="chapter" data-level="4.1.4" data-path="mod-04.html"><a href="mod-04.html#aggregation-aka-pivot-tables"><i class="fa fa-check"></i><b>4.1.4</b> Aggregation (aka: pivot tables)</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="mod-04.html"><a href="mod-04.html#mod-04-vis"><i class="fa fa-check"></i><b>4.2</b> Visualizing data distributions</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="mod-04.html"><a href="mod-04.html#boxplots-aka-box-and-whisker-plots"><i class="fa fa-check"></i><b>4.2.1</b> Boxplots (aka: box-and-whisker plots)</a></li>
<li class="chapter" data-level="4.2.2" data-path="mod-04.html"><a href="mod-04.html#histograms"><i class="fa fa-check"></i><b>4.2.2</b> Histograms</a></li>
<li class="chapter" data-level="4.2.3" data-path="mod-04.html"><a href="mod-04.html#kernel-density-plots"><i class="fa fa-check"></i><b>4.2.3</b> Kernel density plots</a></li>
<li class="chapter" data-level="4.2.4" data-path="mod-04.html"><a href="mod-04.html#empirical-cumulative-distribution-plots-ecdf"><i class="fa fa-check"></i><b>4.2.4</b> Empirical cumulative distribution plots (ECDF)</a></li>
<li class="chapter" data-level="4.2.5" data-path="mod-04.html"><a href="mod-04.html#quantile-quantile-qq-plots"><i class="fa fa-check"></i><b>4.2.5</b> Quantile-quantile (QQ) plots</a></li>
<li class="chapter" data-level="4.2.6" data-path="mod-04.html"><a href="mod-04.html#how-should-i-plot-my-data"><i class="fa fa-check"></i><b>4.2.6</b> How should I plot my data?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="mod-04.html"><a href="mod-04.html#mod-04-dists1"><i class="fa fa-check"></i><b>4.3</b> Statistical distributions</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="mod-04.html"><a href="mod-04.html#probability-distributions"><i class="fa fa-check"></i><b>4.3.1</b> Probability distributions</a></li>
<li class="chapter" data-level="4.3.2" data-path="mod-04.html"><a href="mod-04.html#probability-distributions-in-r"><i class="fa fa-check"></i><b>4.3.2</b> Probability distributions in R</a></li>
<li class="chapter" data-level="4.3.3" data-path="mod-04.html"><a href="mod-04.html#discrete-distributions"><i class="fa fa-check"></i><b>4.3.3</b> Discrete distributions</a></li>
<li class="chapter" data-level="4.3.4" data-path="mod-04.html"><a href="mod-04.html#continuous-distributions"><i class="fa fa-check"></i><b>4.3.4</b> Continuous distributions</a></li>
<li class="chapter" data-level="4.3.5" data-path="mod-04.html"><a href="mod-04.html#distributions-summary"><i class="fa fa-check"></i><b>4.3.5</b> Distributions summary</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="mod-04.html"><a href="mod-04.html#mod-04-dists2"><i class="fa fa-check"></i><b>4.4</b> Fitting and testing distributions</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="mod-04.html"><a href="mod-04.html#estimating-distributional-parameters"><i class="fa fa-check"></i><b>4.4.1</b> Estimating distributional parameters</a></li>
<li class="chapter" data-level="4.4.2" data-path="mod-04.html"><a href="mod-04.html#graphical-methods-for-examining-distributions"><i class="fa fa-check"></i><b>4.4.2</b> Graphical methods for examining distributions</a></li>
<li class="chapter" data-level="4.4.3" data-path="mod-04.html"><a href="mod-04.html#formal-tests-for-distributions"><i class="fa fa-check"></i><b>4.4.3</b> Formal tests for distributions</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="mod-04.html"><a href="mod-04.html#mod-04-trans"><i class="fa fa-check"></i><b>4.5</b> Data transformations</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="mod-04.html"><a href="mod-04.html#why-transform"><i class="fa fa-check"></i><b>4.5.1</b> Why transform?</a></li>
<li class="chapter" data-level="4.5.2" data-path="mod-04.html"><a href="mod-04.html#transforms-vs.-link-functions"><i class="fa fa-check"></i><b>4.5.2</b> Transforms vs. link functions</a></li>
<li class="chapter" data-level="4.5.3" data-path="mod-04.html"><a href="mod-04.html#log-transformation"><i class="fa fa-check"></i><b>4.5.3</b> Log transformation</a></li>
<li class="chapter" data-level="4.5.4" data-path="mod-04.html"><a href="mod-04.html#rank-transformation"><i class="fa fa-check"></i><b>4.5.4</b> Rank transformation</a></li>
<li class="chapter" data-level="4.5.5" data-path="mod-04.html"><a href="mod-04.html#other-transforms-less-common"><i class="fa fa-check"></i><b>4.5.5</b> Other transforms (less common)</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="mod-04.html"><a href="mod-04.html#multivariate-data-exploration"><i class="fa fa-check"></i><b>4.6</b> Multivariate data exploration</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="mod-04.html"><a href="mod-04.html#scatterplots-for-two-variables"><i class="fa fa-check"></i><b>4.6.1</b> Scatterplots for two variables</a></li>
<li class="chapter" data-level="4.6.2" data-path="mod-04.html"><a href="mod-04.html#mod-04-smat"><i class="fa fa-check"></i><b>4.6.2</b> Scatterplot matrices for many variables</a></li>
<li class="chapter" data-level="4.6.3" data-path="mod-04.html"><a href="mod-04.html#lattice-plots-for-hierarchical-data"><i class="fa fa-check"></i><b>4.6.3</b> Lattice plots for hierarchical data</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="mod-04.html"><a href="mod-04.html#ordination-brief-introduction"><i class="fa fa-check"></i><b>4.7</b> Ordination (brief introduction)</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="mod-04.html"><a href="mod-04.html#principal-components-analysis-pca"><i class="fa fa-check"></i><b>4.7.1</b> Principal components analysis (PCA)</a></li>
<li class="chapter" data-level="4.7.2" data-path="mod-04.html"><a href="mod-04.html#nonmetric-multidimensional-scaling-nmds"><i class="fa fa-check"></i><b>4.7.2</b> Nonmetric multidimensional scaling (NMDS)</a></li>
<li class="chapter" data-level="4.7.3" data-path="mod-04.html"><a href="mod-04.html#plotting-ordinations"><i class="fa fa-check"></i><b>4.7.3</b> Plotting ordinations</a></li>
<li class="chapter" data-level="4.7.4" data-path="mod-04.html"><a href="mod-04.html#ordination-wrap-up-for-now"><i class="fa fa-check"></i><b>4.7.4</b> Ordination wrap-up (for now)</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="mod-04.html"><a href="mod-04.html#mod-04-prob"><i class="fa fa-check"></i><b>4.8</b> Common statistical problems</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="mod-04.html"><a href="mod-04.html#outliers-and-erroneous-values"><i class="fa fa-check"></i><b>4.8.1</b> Outliers and erroneous values</a></li>
<li class="chapter" data-level="4.8.2" data-path="mod-04.html"><a href="mod-04.html#autocorrelation"><i class="fa fa-check"></i><b>4.8.2</b> Autocorrelation</a></li>
<li class="chapter" data-level="4.8.3" data-path="mod-04.html"><a href="mod-04.html#mod-04-multicol"><i class="fa fa-check"></i><b>4.8.3</b> Collinearity</a></li>
<li class="chapter" data-level="4.8.4" data-path="mod-04.html"><a href="mod-04.html#missing-data"><i class="fa fa-check"></i><b>4.8.4</b> Missing data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mod-05.html"><a href="mod-05.html"><i class="fa fa-check"></i><b>5</b> Generalized linear models (GLM)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="mod-05.html"><a href="mod-05.html#mod-05-lm"><i class="fa fa-check"></i><b>5.1</b> Prelude with linear models</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="mod-05.html"><a href="mod-05.html#assumptions-of-linear-models"><i class="fa fa-check"></i><b>5.1.1</b> Assumptions of linear models</a></li>
<li class="chapter" data-level="5.1.2" data-path="mod-05.html"><a href="mod-05.html#linear-regression-in-r"><i class="fa fa-check"></i><b>5.1.2</b> Linear regression in R</a></li>
<li class="chapter" data-level="5.1.3" data-path="mod-05.html"><a href="mod-05.html#multiple-linear-regression"><i class="fa fa-check"></i><b>5.1.3</b> Multiple linear regression</a></li>
<li class="chapter" data-level="5.1.4" data-path="mod-05.html"><a href="mod-05.html#mod-05-anova"><i class="fa fa-check"></i><b>5.1.4</b> ANOVA and ANCOVA with <code>lm()</code></a></li>
<li class="chapter" data-level="5.1.5" data-path="mod-05.html"><a href="mod-05.html#variations-on-linear-models"><i class="fa fa-check"></i><b>5.1.5</b> Variations on linear models</a></li>
<li class="chapter" data-level="5.1.6" data-path="mod-05.html"><a href="mod-05.html#example-linear-regression-workflow"><i class="fa fa-check"></i><b>5.1.6</b> Example linear regression workflow</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="mod-05.html"><a href="mod-05.html#mod-05-basic"><i class="fa fa-check"></i><b>5.2</b> GLM basics</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="mod-05.html"><a href="mod-05.html#example-glms"><i class="fa fa-check"></i><b>5.2.1</b> Example GLMS</a></li>
<li class="chapter" data-level="5.2.2" data-path="mod-05.html"><a href="mod-05.html#glm-families"><i class="fa fa-check"></i><b>5.2.2</b> GLM families</a></li>
<li class="chapter" data-level="5.2.3" data-path="mod-05.html"><a href="mod-05.html#glm-link-functions"><i class="fa fa-check"></i><b>5.2.3</b> GLM link functions</a></li>
<li class="chapter" data-level="5.2.4" data-path="mod-05.html"><a href="mod-05.html#deviance-and-other-glm-diagnostics"><i class="fa fa-check"></i><b>5.2.4</b> Deviance and other GLM diagnostics</a></li>
<li class="chapter" data-level="5.2.5" data-path="mod-05.html"><a href="mod-05.html#to-pseudo-r2-or-not-to-pseudo-r2"><i class="fa fa-check"></i><b>5.2.5</b> To pseudo-<em>R</em><sup>2</sup> or not to pseudo-<em>R</em><sup>2</sup>?</a></li>
<li class="chapter" data-level="5.2.6" data-path="mod-05.html"><a href="mod-05.html#common-glms"><i class="fa fa-check"></i><b>5.2.6</b> Common GLMs</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="mod-05.html"><a href="mod-05.html#mod-05-loglin"><i class="fa fa-check"></i><b>5.3</b> Log-linear models</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="mod-05.html"><a href="mod-05.html#mod-05-loglin-examp"><i class="fa fa-check"></i><b>5.3.1</b> Example with simulated data</a></li>
<li class="chapter" data-level="5.3.2" data-path="mod-05.html"><a href="mod-05.html#example-with-real-data"><i class="fa fa-check"></i><b>5.3.2</b> Example with real data</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="mod-05.html"><a href="mod-05.html#mod-05-poisson"><i class="fa fa-check"></i><b>5.4</b> Poisson GLM for counts</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="mod-05.html"><a href="mod-05.html#example-with-simulated-data"><i class="fa fa-check"></i><b>5.4.1</b> Example with simulated data</a></li>
<li class="chapter" data-level="5.4.2" data-path="mod-05.html"><a href="mod-05.html#example-with-real-data-1"><i class="fa fa-check"></i><b>5.4.2</b> Example with real data</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="mod-05.html"><a href="mod-05.html#mod-05-quasi"><i class="fa fa-check"></i><b>5.5</b> Quasi-Poisson and negative binomial GLM</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="mod-05.html"><a href="mod-05.html#example-with-simulated-data-1"><i class="fa fa-check"></i><b>5.5.1</b> Example with simulated data</a></li>
<li class="chapter" data-level="5.5.2" data-path="mod-05.html"><a href="mod-05.html#example-with-real-data-2"><i class="fa fa-check"></i><b>5.5.2</b> Example with real data</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="mod-05.html"><a href="mod-05.html#mod-05-logistic"><i class="fa fa-check"></i><b>5.6</b> Logistic regression for binary outcomes</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="mod-05.html"><a href="mod-05.html#example-with-simulated-data-2"><i class="fa fa-check"></i><b>5.6.1</b> Example with simulated data</a></li>
<li class="chapter" data-level="5.6.2" data-path="mod-05.html"><a href="mod-05.html#example-with-real-data-3"><i class="fa fa-check"></i><b>5.6.2</b> Example with real data</a></li>
<li class="chapter" data-level="5.6.3" data-path="mod-05.html"><a href="mod-05.html#mod-05-auc"><i class="fa fa-check"></i><b>5.6.3</b> Logistic GLM diagnostics: AUC and ROC</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="mod-05.html"><a href="mod-05.html#mod-05-binom"><i class="fa fa-check"></i><b>5.7</b> Binomial GLM for proportional data</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="mod-05.html"><a href="mod-05.html#binomial-glm"><i class="fa fa-check"></i><b>5.7.1</b> Binomial GLM</a></li>
<li class="chapter" data-level="5.7.2" data-path="mod-05.html"><a href="mod-05.html#example-with-simulated-data-3"><i class="fa fa-check"></i><b>5.7.2</b> Example with simulated data</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="mod-05.html"><a href="mod-05.html#mod-05-gamma"><i class="fa fa-check"></i><b>5.8</b> Gamma models for overdispersed data</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="mod-05.html"><a href="mod-05.html#example-with-simulated-data-4"><i class="fa fa-check"></i><b>5.8.1</b> Example with simulated data</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="mod-05.html"><a href="mod-05.html#mod-05-beyond"><i class="fa fa-check"></i><b>5.9</b> Beyond GLM: Overview of GAM and GEE</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="mod-05.html"><a href="mod-05.html#mod-05-gam"><i class="fa fa-check"></i><b>5.9.1</b> Generalized additive models (GAM)</a></li>
<li class="chapter" data-level="5.9.2" data-path="mod-05.html"><a href="mod-05.html#mod-05-gee"><i class="fa fa-check"></i><b>5.9.2</b> Generalized estimating equations (GEE)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="mod-06.html"><a href="mod-06.html"><i class="fa fa-check"></i><b>6</b> Nonlinear models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="mod-06.html"><a href="mod-06.html#background"><i class="fa fa-check"></i><b>6.1</b> Background</a></li>
<li class="chapter" data-level="6.2" data-path="mod-06.html"><a href="mod-06.html#mod-06-intro"><i class="fa fa-check"></i><b>6.2</b> Nonlinear least squares (NLS)</a></li>
<li class="chapter" data-level="6.3" data-path="mod-06.html"><a href="mod-06.html#mod-06-micmen"><i class="fa fa-check"></i><b>6.3</b> Michaelis-Menten curves</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="mod-06.html"><a href="mod-06.html#mod-06-micmen-sim"><i class="fa fa-check"></i><b>6.3.1</b> Example with simulated data</a></li>
<li class="chapter" data-level="6.3.2" data-path="mod-06.html"><a href="mod-06.html#example-with-real-data-4"><i class="fa fa-check"></i><b>6.3.2</b> Example with real data</a></li>
<li class="chapter" data-level="6.3.3" data-path="mod-06.html"><a href="mod-06.html#alternative-strategies-for-the-analysis"><i class="fa fa-check"></i><b>6.3.3</b> Alternative strategies for the analysis</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="mod-06.html"><a href="mod-06.html#mod-06-grow"><i class="fa fa-check"></i><b>6.4</b> Biological growth curves</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="mod-06.html"><a href="mod-06.html#gompertz-and-von-bertalanffy-curves"><i class="fa fa-check"></i><b>6.4.1</b> Gompertz and von Bertalanffy curves</a></li>
<li class="chapter" data-level="6.4.2" data-path="mod-06.html"><a href="mod-06.html#example-with-real-data-5"><i class="fa fa-check"></i><b>6.4.2</b> Example with real data</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="mod-06.html"><a href="mod-06.html#dose-response-curves"><i class="fa fa-check"></i><b>6.5</b> Dose response curves</a></li>
<li class="chapter" data-level="6.6" data-path="mod-06.html"><a href="mod-06.html#alternatives-to-nls"><i class="fa fa-check"></i><b>6.6</b> Alternatives to NLS</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="mod-06.html"><a href="mod-06.html#generalized-nonlinear-models"><i class="fa fa-check"></i><b>6.6.1</b> Generalized nonlinear models</a></li>
<li class="chapter" data-level="6.6.2" data-path="mod-06.html"><a href="mod-06.html#quantile-regression"><i class="fa fa-check"></i><b>6.6.2</b> Quantile regression</a></li>
<li class="chapter" data-level="6.6.3" data-path="mod-06.html"><a href="mod-06.html#mod-06-gam"><i class="fa fa-check"></i><b>6.6.3</b> Generalized additive models (GAM)</a></li>
<li class="chapter" data-level="6.6.4" data-path="mod-06.html"><a href="mod-06.html#classification-and-regression-trees-cart"><i class="fa fa-check"></i><b>6.6.4</b> Classification and regression trees (CART)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="mod-07.html"><a href="mod-07.html"><i class="fa fa-check"></i><b>7</b> Mixed models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="mod-07.html"><a href="mod-07.html#prelude-glm"><i class="fa fa-check"></i><b>7.1</b> Prelude (GLM)</a></li>
<li class="chapter" data-level="7.2" data-path="mod-07.html"><a href="mod-07.html#mod-07-lmm"><i class="fa fa-check"></i><b>7.2</b> Linear mixed models (LMM)</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="mod-07.html"><a href="mod-07.html#formal-definition-and-example"><i class="fa fa-check"></i><b>7.2.1</b> Formal definition and example</a></li>
<li class="chapter" data-level="7.2.2" data-path="mod-07.html"><a href="mod-07.html#example-with-simulated-data-5"><i class="fa fa-check"></i><b>7.2.2</b> Example with simulated data</a></li>
<li class="chapter" data-level="7.2.3" data-path="mod-07.html"><a href="mod-07.html#p-values-in-lmm"><i class="fa fa-check"></i><b>7.2.3</b> <em>P</em>-values in LMM</a></li>
<li class="chapter" data-level="7.2.4" data-path="mod-07.html"><a href="mod-07.html#specifying-random-effects"><i class="fa fa-check"></i><b>7.2.4</b> Specifying random effects</a></li>
<li class="chapter" data-level="7.2.5" data-path="mod-07.html"><a href="mod-07.html#lmm-example-with-real-data"><i class="fa fa-check"></i><b>7.2.5</b> LMM example with real data</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="mod-07.html"><a href="mod-07.html#mod-07-glmm"><i class="fa fa-check"></i><b>7.3</b> Generalized linear mixed models (GLMM)</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="mod-07.html"><a href="mod-07.html#definition-1"><i class="fa fa-check"></i><b>7.3.1</b> Definition</a></li>
<li class="chapter" data-level="7.3.2" data-path="mod-07.html"><a href="mod-07.html#glmm-on-simulated-data"><i class="fa fa-check"></i><b>7.3.2</b> GLMM on simulated data</a></li>
<li class="chapter" data-level="7.3.3" data-path="mod-07.html"><a href="mod-07.html#glmm-on-real-data"><i class="fa fa-check"></i><b>7.3.3</b> GLMM on real data</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="mod-07.html"><a href="mod-07.html#mod-07-nlme"><i class="fa fa-check"></i><b>7.4</b> Nonlinear mixed models (NLME)</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="mod-07.html"><a href="mod-07.html#definition-and-background"><i class="fa fa-check"></i><b>7.4.1</b> Definition and background</a></li>
<li class="chapter" data-level="7.4.2" data-path="mod-07.html"><a href="mod-07.html#nlme-on-simulated-data"><i class="fa fa-check"></i><b>7.4.2</b> NLME on simulated data</a></li>
<li class="chapter" data-level="7.4.3" data-path="mod-07.html"><a href="mod-07.html#nlme-on-real-data"><i class="fa fa-check"></i><b>7.4.3</b> NLME on real data</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="mod-07.html"><a href="mod-07.html#mod-07-gamm"><i class="fa fa-check"></i><b>7.5</b> (Generalized) additive mixed models (AMM/GAMM)</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="mod-07.html"><a href="mod-07.html#example-gamm-with-real-data"><i class="fa fa-check"></i><b>7.5.1</b> Example GAMM with real data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mod-08.html"><a href="mod-08.html"><i class="fa fa-check"></i><b>8</b> Multivariate data analysis</a>
<ul>
<li class="chapter" data-level="8.1" data-path="mod-08.html"><a href="mod-08.html#multivariate-data"><i class="fa fa-check"></i><b>8.1</b> Multivariate data</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="mod-08.html"><a href="mod-08.html#univariate-vs.-multivariate-data"><i class="fa fa-check"></i><b>8.1.1</b> Univariate vs. multivariate data</a></li>
<li class="chapter" data-level="8.1.2" data-path="mod-08.html"><a href="mod-08.html#components-of-multivariate-data"><i class="fa fa-check"></i><b>8.1.2</b> Components of multivariate data</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="mod-08.html"><a href="mod-08.html#mod-08-dist"><i class="fa fa-check"></i><b>8.2</b> Distance metrics: biological (dis)similarity</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="mod-08.html"><a href="mod-08.html#euclidean-distance"><i class="fa fa-check"></i><b>8.2.1</b> Euclidean distance</a></li>
<li class="chapter" data-level="8.2.2" data-path="mod-08.html"><a href="mod-08.html#bray-curtis-and-other-distance-metrics"><i class="fa fa-check"></i><b>8.2.2</b> Bray-Curtis and other distance metrics</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="mod-08.html"><a href="mod-08.html#clustering"><i class="fa fa-check"></i><b>8.3</b> Clustering</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="mod-08.html"><a href="mod-08.html#k-means-clustering"><i class="fa fa-check"></i><b>8.3.1</b> <em>K</em>-means clustering</a></li>
<li class="chapter" data-level="8.3.2" data-path="mod-08.html"><a href="mod-08.html#hierarchical-agglomerative-clustering"><i class="fa fa-check"></i><b>8.3.2</b> Hierarchical agglomerative clustering</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="mod-08.html"><a href="mod-08.html#mod-08-sims"><i class="fa fa-check"></i><b>8.4</b> Analyzing dissimilarity</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="mod-08.html"><a href="mod-08.html#mantel-tests-distance-vs.-distance"><i class="fa fa-check"></i><b>8.4.1</b> Mantel tests: distance vs. distance</a></li>
<li class="chapter" data-level="8.4.2" data-path="mod-08.html"><a href="mod-08.html#comparing-dissimilarity-between-groups"><i class="fa fa-check"></i><b>8.4.2</b> Comparing dissimilarity between groups</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="mod-08.html"><a href="mod-08.html#mod-08-ord"><i class="fa fa-check"></i><b>8.5</b> Ordination</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="mod-08.html"><a href="mod-08.html#principal-components-analysis-pca-1"><i class="fa fa-check"></i><b>8.5.1</b> Principal components analysis (PCA)</a></li>
<li class="chapter" data-level="8.5.2" data-path="mod-08.html"><a href="mod-08.html#nmds-and-other-ordination-methods"><i class="fa fa-check"></i><b>8.5.2</b> NMDS and other ordination methods</a></li>
<li class="chapter" data-level="8.5.3" data-path="mod-08.html"><a href="mod-08.html#other-ordination-techniques"><i class="fa fa-check"></i><b>8.5.3</b> Other ordination techniques</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="mod-09.html"><a href="mod-09.html"><i class="fa fa-check"></i><b>9</b> Planning your analysis (what test?)</a>
<ul>
<li class="chapter" data-level="9.1" data-path="mod-09.html"><a href="mod-09.html#how-to-use-this-guide"><i class="fa fa-check"></i><b>9.1</b> How to use this guide</a></li>
<li class="chapter" data-level="9.2" data-path="mod-09.html"><a href="mod-09.html#what-question-are-you-trying-to-answer"><i class="fa fa-check"></i><b>9.2</b> What question are you trying to answer?</a></li>
<li class="chapter" data-level="9.3" data-path="mod-09.html"><a href="mod-09.html#testing-for-a-difference-in-mean-or-location"><i class="fa fa-check"></i><b>9.3</b> Testing for a difference in mean or location</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="mod-09.html"><a href="mod-09.html#additional-considerations"><i class="fa fa-check"></i><b>9.3.1</b> Additional considerations</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="mod-09.html"><a href="mod-09.html#testing-for-a-continuous-relationship-between-two-or-more-variables"><i class="fa fa-check"></i><b>9.4</b> Testing for a continuous relationship between two or more variables</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="mod-09.html"><a href="mod-09.html#additional-considerations-1"><i class="fa fa-check"></i><b>9.4.1</b> Additional considerations</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="mod-09.html"><a href="mod-09.html#classifying-observations"><i class="fa fa-check"></i><b>9.5</b> Classifying observations</a></li>
<li class="chapter" data-level="9.6" data-path="mod-09.html"><a href="mod-09.html#conclusions"><i class="fa fa-check"></i><b>9.6</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="literature-cited.html"><a href="literature-cited.html"><i class="fa fa-check"></i>Literature Cited</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied Biological Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mod-08" class="section level1" number="8">
<h1><span class="header-section-number">Module 8</span> Multivariate data analysis</h1>
<div id="multivariate-data" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Multivariate data</h2>
<div id="univariate-vs.-multivariate-data" class="section level3" number="8.1.1">
<h3><span class="header-section-number">8.1.1</span> Univariate vs. multivariate data</h3>
<p>Things are not always one or two dimensional. Oftentimes in biology we need to consider many variables at once. This is the realm of <strong>multivariate statistics</strong>. The “multi” in “multivariate” refers to the fact that there are multiple variables or attributes of each sample that we want to understand simultaneously. The terminology can be confusing sometimes because other statistical methods have the word “multiple” in their names. For example, “multiple linear regression” is not considered a multivariate method because there is only one measurement from each sample (the response variable) that is being modeled.</p>
<p>The figure below shows some differences between a univariate analysis and a multivariate one. In the univariate analysis, one and only one variable is the response variable and is assumed to be predicted by (aka: depend on) the others. Frequently, the observations are divided <em>a priori</em> into groups by a factor encoded by one of the predictor variables. This means that the goal of a univariate analysis is to explain patterns in one variable relative to other variables. In a univariate analysis, the emphasis is on discovering relationships between variables, and the observations are a means to that end.</p>
<p>In a multivariate analysis, none of the variables are singled out and all are of interest for explaining differences or similarities between the observations. The observations may come from <em>a priori</em> groups defined in a separate matrix (see below), or the researcher may want to discover how the observations naturally separate into clusters based on the variables (i.e., <em>a posteriori</em> groups). Or, the researcher may want to know which variables, if any, drive most of the variation between observations. The key is that in a multivariate analysis the emphasis is often on discovering patterns between observations, and the variables are a means to that end.</p>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_01.jpg" alt="Illustration of univariate (top) and multivariate (bottom) data." /></p>
</div>
<div id="components-of-multivariate-data" class="section level3" number="8.1.2">
<h3><span class="header-section-number">8.1.2</span> Components of multivariate data</h3>
<p>When planning and executing a multivariate analysis it is very important to keep in mind which components of the dataset are which. These components are usually stored in matrices with a well-defined structure. The key concept is that of the <strong>sample unit</strong> or <strong>observation</strong>. These are individual observations about which many measurements or attributes are recorded. Sample units correspond to rows of the data matrix. Each sample unit has several <strong>attributes</strong> or <strong>variables</strong> associated with it. Variables correspond to columns of the data matrix. The figure below shows the layout of a typical multivariate dataset. The example has 12 observations and 6 variables . In some fields, samples are also called records and variables are called features.</p>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_02.jpg" alt="A typical data matrix for a multivariate analysis." /></p>
<p>Complex datasets often contain data of different types, or sets of variables that capture information about different aspects of the system. For example, you might have variables that contain species abundances, optical densities, concentrations, femur lengths, treatment groups, and so on. When planning a multivariate analysis you need to consider whether and which variables should be grouped together. In an exploratory analysis, perhaps all of the variables are of interest and no subgroups are needed. In many situations, some of the variables will be the “response” variables. These contain the patterns that you are interested in explaining. Other variables might be considered “explanatory variables”. These are variables that may or may not help explain some of the patterns in the first set of variables. Other variables might contain information about the response variables. For all variables except the first set of “response” variables, the key is whether the values are associated with rows of the main data matrix shown above (i.e., with observations), or whether the values are associated with columns of the main data matrix (i.e., with other variables).</p>
<p>The figure below shows the relationship between three interrelated matrices typical in community ecology. Similar matrices can be defined for other fields…just replace “Environmental variables” with another label that helps describe variation among the sample units.</p>
<ul>
<li>The data matrix <strong>A</strong> contains data on the abundance of 6 species at each of 12 sites.</li>
<li>The explanatory matrix <strong>E</strong> contains 4 environmental variables (e.g., temperature, latitude, etc.) for each of the sites. These data describe relationships between observations in <strong>A</strong>.</li>
<li>The trait matrix <strong>S</strong> contains data about traits (e.g., maximum size, longevity, etc.) of the species in the main matrix. These data describe relationships between variables in <strong>A</strong>.</li>
</ul>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_03.jpg" alt="Relationships between data matrices in a multivariate community ecology analysis." /></p>
<p>A biological system of interest might have relationships among all three of these matrices:</p>
<ul>
<li><strong>Patterns within A</strong>: Explaining groupings or trends among the sites in terms of the species present or absent at each site (or, the abundances of species at each site).</li>
<li><strong>Patterns within E</strong>: Discovering groupings among the sites in terms of their environmental variables.</li>
<li><strong>Relationships between A and E</strong>: Relating patterns in environmental variables to patterns in species abundances across sites.</li>
<li><strong>Relating patterns between A and E in terms of S</strong>: Relating species traits to environmental conditions.</li>
<li><strong>Patterns within S</strong>: Identifying clusters of similar species.</li>
</ul>
<p><span class="citation">McCune et al. (<a href="#ref-mccune2002analysis" role="doc-biblioref">2002</a>)</span> give a thorough treatment of the relationships between <strong>S</strong>, <strong>E</strong>, <strong>A</strong>, and other matrices derived from them. For this course, we will focus on analyzing <strong>A</strong> and sometimes <strong>E</strong>. There is a related set of terminology used to describe multivariate analyses in terms of what is being compared. Analyses that seek relationships among samples are said to be in <strong>Q mode</strong>; analyses that seek relationships among variables are in <strong>R mode</strong> <span class="citation">(<a href="#ref-legendre2012numerical" role="doc-biblioref">Legendre and Legendre 2012</a>)</span>. These terms appear to be particular to ecology, but offer a helpful way to distinguish between different multivariate analysis pathways.</p>
</div>
</div>
<div id="mod-08-dist" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> Distance metrics: biological (dis)similarity</h2>
<p>One of the central questions in a multivariate analysis is, “How similar to each other are my samples?” This is a more complicated question than it appears. It’s worth considering for a moment what “similar” even means. Consider the set of organisms below. How would you group them by “similarity”?</p>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_04.jpg" /></p>
<p>Here is one way:</p>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_05.jpg" /></p>
<p>You might have come up with a slightly different set of groupings. This one is just as valid:</p>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_06.jpg" /></p>
<p>These examples illustrate how we might classify the organisms based on qualitative characteristics. But do our choices weight each characteristic equally? After all, fungi and plants are far more different from each other than ants and fish, but the second scheme lumps all non-animals together. Which characteristics of the organisms are really driving our classification decisions?</p>
<p>One way around this problem is to assign numeric scores to characters: 1 if an organism has the trait, and 0 if it doesn’t. The table below illustrates this for a few organisms and characteristics. Note that bacteria have <code>NA</code> for hetertrophy, becuase many bacteria are also autotrophs.</p>
<table style="width:100%;">
<colgroup>
<col width="7%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th>Organism</th>
<th align="center">Multicellular</th>
<th align="center">Heterotrophic</th>
<th align="center">Flowering</th>
<th align="center">Vertebrate</th>
<th align="center">Gills</th>
<th align="center">Amnion</th>
<th align="center">Endothermic</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bacteria</td>
<td align="center">0</td>
<td align="center">NA</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td>Maple</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td>Pine</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td>Octopus</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td>Shark</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td>Mushroom</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td>Frog</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td>Elephant</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td>Penguin</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td>…</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>The <a href="https://greenquanteco.github.io/tax_example_2021-10-27.csv">full table</a> for our organisms has more columns and rows (we’ll get to that later).</p>
<p>The next step is to somehow quantify the similarities between the organisms. It turns out that it’s easier to define <strong>dissimilarity</strong> than it is define similarity. This is because the range of a similarity metric is ill-defined: there is no natural value to assign to identical samples. I.e., what value should identical samples have? Infinity? Some other arbitrary value? The first isn’t very useful, and the second is highly subjective. Dissimilarity, on the other hand, has a natural value to assign to identical samples: 0. Dissimilarity is often expressed as a <strong>distance</strong> through a <strong>hyperspace</strong>. Hyperspace in this context means a coordinate system with one axis (dimension) for each variable in the data.</p>
<p>To quantify distances between taxa, we might try adding up the differences between each pair. We should also square each individual difference, so <span class="math inline">\(1-0\)</span> counts the same as <span class="math inline">\(0-1\)</span>. Then, we add up the squared differences and take the square root to get back to the original scale. For example, the distance between maple and pine in the table above would be:</p>
<p><span class="math display">\[ D(maple,pine)=\sqrt{(1-1)^{2}+(0-0)^{2}+(1-0)^{2}+(0-0)^{2}+(0-0)^{2}+(0-0)^{2}+(0-0)^{2}}=1\]</span></p>
<p>The difference between octopus and penguin would be:</p>
<p><span class="math display">\[ D(octopus,penguin)=\sqrt{(1-1)^{2}+(1-1)^{2}+(0-0)^{2}+(0-1)^{2}+(1-0)^{2}+(0-1)^{2}+(0-1)^{2}}=1\]</span></p>
<p>And the difference between mushrooms and elephants is:</p>
<p><span class="math display">\[ D(mushroom,elephant)=\sqrt{(1-1)^{2}+(1-1)^{2}+(0-0)^{2}+(0-1)^{2}+(1-0)^{2}+(0-1)^{2}+(0-1)^{2}}\approx1.73\]</span></p>
<p>So, for this set of characteristics, octopuses and penguins are twice as different from each other as are maple trees and pine trees, while mushrooms and elephants are not quite as different from each other as octopuses and penguins. Interestingly, mushrooms and elephants are more different from each other than are maples and pines, even though maples and pines are in the same kingdom while mushrooms and plants are not. Does that make sense biologically?</p>
<p>These comparisons were chosen to make a couple of points about quantifying differences. First, the choice of characteristics (or measurements, or metrics, etc.) has a large influence over the calculation. Look over the list again and ask yourself if those characteristics are applicable to all of the organisms. Four of the eight traits are specific to just the animals! Second, the choice of how to combine the differences makes a big difference. There are other methods we could have chosen (see below) that might have measured dissimilarity differently.</p>
<div id="euclidean-distance" class="section level3" number="8.2.1">
<h3><span class="header-section-number">8.2.1</span> Euclidean distance</h3>
<p>The most basic distance metric is the <strong>Euclidean distance</strong>. This is a generalization of the Pythagorean theorem to an arbitrary number of dimensions. The calculations above were presented in a cumbersome way to show how they work, but the Euclidean distance metric is usually written in a more compact format:</p>
<p><span class="math display">\[D(x_{i},x_{h})=\sqrt{\sum_{j=1}^{p}(x_{i,j}-x_{h,j})^{2}} \]</span></p>
<p>In this expression the difference between observation <em>i</em> and observation <em>h</em> (<span class="math inline">\(x[i]\)</span> and <span class="math inline">\(x[h]\)</span>) is the square root of the sum of squared differences between <span class="math inline">\(x_{i}\)</span> and <span class="math inline">\(x_{h}\)</span> in terms of each variable <em>j</em>, up to the number of variables <em>p</em>. When <em>p</em> = 2, this formula reduces to the Pythagorean theorem:</p>
<p><span class="math display">\[D(x_{i},x_{h})=\sqrt{\sum_{j=1}^{2}(x_{i,j}-x_{h,j})^{2}}=\sqrt{(x_{i,1}-x_{h,1})^{2}+(x_{i,2}-x_{h,2})^{2}} \]</span></p>
<p>Again, the Euclidean distance is just the Pythagorean theorem generalized to <em>p</em> dimensions rather than the usual 2. One way to think of the Pythagorean theorem is as the distance between points on the 2-d plane, with the <em>x</em> and <em>y</em> coordinates as the side lengths of the triangle.</p>
<p>Here and for the rest of this course, “dimension” means the same as “variable”. When thinking about multivariate statistics, it can be useful to think of your data as defining a <strong>hyperspace</strong> or <strong>hypervolume</strong>, with one dimension for each variable in your data. Thus a dataset with 2 variables defines a space with 2 dimensions (i.e., a plane); a dataset with 3 dimensions defines a space with 3 dimensions (i.e., a volume), and so on. When discussing multivariate differences between sample units, we usually refer to the differences as distances through these hyperspaces. Each distance metric calculates that distance a slightly different way.</p>
<p>Back to our organism classification example, the figure below shows Euclidean distances for 30 organisms across 12 traits. The distances are distances between each of the 435 unique pairs of taxa in a 12-dimensional hyperspace. Darker colors indicate greater distance—i.e., greater dissimilarity or smaller similarity.</p>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_07.jpg" /></p>
<p>If you examine the chart above you will find that some if the distances are silly: for example, octopuses are presented as more different from owls than they are from bacteria. This suggests that the Euclidean distance metric was maybe not the right one.</p>
</div>
<div id="bray-curtis-and-other-distance-metrics" class="section level3" number="8.2.2">
<h3><span class="header-section-number">8.2.2</span> Bray-Curtis and other distance metrics</h3>
<p>Another distance metric is called the <strong>Manhattan</strong> or <strong>city block</strong> distance. It gets its name from the way that distances are added up by assuming that samples can only be connected by paths that move along one axis (i.e., dimension) at a time. This is analogous to how people in cities can walk along the sidewalks of the city street grid, but cannot cut through blocks. The figure below illustrates this.</p>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_08.jpg" /></p>
<p>The Manhattan distance is longer than the Euclidean distance, but it can sometimes be a better representation of the differences between sample units in terms of many variables. The Manhattan distance is calculated as:</p>
<p><span class="math display">\[D(x_{i},x_{h})=\sum_{j=1}^{p}|x_{i,j}-x_{h,j}|\]</span></p>
<p>The Manhattan distance is not often used by itself, but a relativized version of it is extremely common in biology: the <strong>Bray-Curtis distance</strong>, also known as the <strong>Sørenson distance</strong>. This distance measure is called the Sørenson index when used with binary data (such as 1/0 for presence/absence). The name Bray-Curtis is used when the same formula is applied to continuous data (often proportions or percentages). The Bray-Curtis distance is calculated as:</p>
<p><span class="math display">\[D_{BC}(x_{i},x_{h})=\frac{\sum_{j=1}^{p}|x_{i,j}-x_{h,j}|}{\sum_{i=1}^{p}x_{i,j}+\sum_{i=1}^{p}x_{h,j}}=1-\frac{2\sum_{j=1}^{p}MIN(x_{i,j},x_{h,j})}{\sum_{i=1}^{p}x_{i,j}+\sum_{i=1}^{p}x_{h,j}}\]</span></p>
<p>In the second expression, <em>MIN</em>() is a function that returns the smaller of two values. Notice that the Bray-Curtis distance is essentially the Manhattan distance divided by the shared total values in both samples. This ratio can be thought of as the shared values divided by the total of values. The division makes this value “relativized” (i.e., relative to something else, in the same way that percentages are relative to 100). The figure below shows the approximate relationship between the Euclidean distance, Manhattan distance.</p>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_09.jpg" /></p>
<p>If we recalculate the distance matrix between the taxa in our example, the distances now look like this:</p>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_10.jpg" /></p>
<p>The new distances are an improvement but there is still a lot of room to get better. For example, salamanders are more similar to pines than they are to maples. I’ll leave the interpretation of that finding up to you (hint: there isn’t one…this is a silly example).</p>
<p>There are lots of other distance metrics, but a full exploration is beyond the scope of this course. The table below, adapted from <span class="citation">McCune et al. (<a href="#ref-mccune2002analysis" role="doc-biblioref">2002</a>)</span>, gives some characteristics of some common measures. The range of input data <em>x</em> and distance measures <em>d</em> is provided. For most biological situations where data are nonnormal and relationships are nonlinear, the Bray-Curtis distance is likely to be the most appropriate. When many variables contain lots of 0s, a modified version can be used that adds a “dummy species” present in every sample to stabilize the distances <span class="citation">(<a href="#ref-clarke2006" role="doc-biblioref">Clarke et al. 2006</a>)</span>. The Euclidean metric has strong requirements of multivariate normality and collinearity among variables; the Bray-Curtis metric does not. The other metrics aren’t as commonly used as the Euclidean and Bray-Curtis, but are included here for reference.</p>
<table>
<colgroup>
<col width="22%" />
<col width="27%" />
<col width="27%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th>Metric</th>
<th align="center">Domain of <em>x</em></th>
<th align="center">Range of <em>d</em></th>
<th>Comments</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bray-Curtis (Sørenson)</td>
<td align="center"><span class="math inline">\(x \le 0\)</span></td>
<td align="center"><span class="math inline">\(0 \le d \le 1\)</span></td>
<td>Preferred in many biological situations</td>
</tr>
<tr class="even">
<td>Relative Sørenson (Kulczynski)</td>
<td align="center"><span class="math inline">\(x \le 0\)</span></td>
<td align="center"><span class="math inline">\(0 \le d \le 1\)</span></td>
<td>Relativized by sample totals</td>
</tr>
<tr class="odd">
<td>Jaccard</td>
<td align="center"><span class="math inline">\(x \le 0\)</span></td>
<td align="center"><span class="math inline">\(0 \le d \le 1\)</span></td>
<td>Related to Manhattan distance</td>
</tr>
<tr class="even">
<td>Euclidean (Pythagorean)</td>
<td align="center"><span class="math inline">\(x \in \mathbb{R}\)</span></td>
<td align="center"><span class="math inline">\(0 \le d\)</span></td>
<td>Often requires multivariate normality</td>
</tr>
<tr class="odd">
<td>Relative Euclidean (chord distance)</td>
<td align="center"><span class="math inline">\(x \in \mathbb{R}\)</span></td>
<td align="center"><span class="math inline">\(0 \le d \le \sqrt{2}\)</span> or <span class="math inline">\(0 \le d \le 2\)</span></td>
<td>Euclidean distance on a hypersphere</td>
</tr>
<tr class="even">
<td>Chi-square</td>
<td align="center"><span class="math inline">\(x \ge 0\)</span></td>
<td align="center"><span class="math inline">\(0 \le d\)</span></td>
<td>Euclidean but weighted by sample and variable totals</td>
</tr>
<tr class="odd">
<td>Squared Euclidean</td>
<td align="center"><span class="math inline">\(x \in \mathbb{R}\)</span></td>
<td align="center"><span class="math inline">\(0 \le d\)</span></td>
<td>Square of Euclidean distance</td>
</tr>
<tr class="even">
<td>Mahalanobis</td>
<td align="center"><span class="math inline">\(x \in \mathbb{R}\)</span></td>
<td align="center"><span class="math inline">\(0 \le d\)</span></td>
<td>Distance between groups weighted by intragroup variance</td>
</tr>
</tbody>
</table>
<p>Remember that distances express differences between samples with respect to several variables. This can be visualized as a distance through a hyperspace with as many dimensions as you have variables. As we’ll see in the next section, we can use distances to explore similiarites and differences between samples.</p>
</div>
</div>
<div id="clustering" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> Clustering</h2>
<p>Now that we have a way of quantifying multivariate differences between samples as distance, we can use those measures to explore patterns in data. One application of distance metrics is to use them to organize data into clusters or groups consisting of samples that are more similar to each other than they are to other samples. In other words, the <strong>within-group</strong> distances should be smaller than the <strong>between-group</strong> distances. The figure below illustrates this concept with an imaginary example. The clusters shown cleanly separate black, red, and blue points. For example, the average distance between the black points is smaller than the average distance between the black points and the red or blue points. Likewise, the average distance between the red points is smaller than the average distance between the red points and the black points or the blue points.</p>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_11.jpg" /></p>
<p>There are many methods for clustering observations. Many methods are <strong>hierarchical</strong>, with groups being nested within other groups. Hierarchical methods are often the most useful for biologists, because so many of the phenomena we study have some hierarchical nature to them. Other methods are nonhierarchical. Both approaches work by minimizing within-group distances relative to between group distances. The difference is that hierarchical methods have the constraint that larger groups are formed from subgroups.</p>
<p>Clustering methods also differ in their manner of group construction. Many methods are <strong>agglomerative</strong>, which means that groups are formed by combining samples. Other methods are <strong>divisive</strong>, which means that all samples start in a single group which is then broken up. Examples of each class of clustering method are shown below.</p>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th>Group nature</th>
<th>Group formation</th>
<th>Common methods</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Nonhierarchical</td>
<td>Agglomerative</td>
<td>??</td>
</tr>
<tr class="even">
<td>Nonhierarchical</td>
<td>Divisive</td>
<td><em>K</em>-means clustering</td>
</tr>
<tr class="odd">
<td>Hierarchical</td>
<td>Agglomerative</td>
<td>Ward clustering <span class="citation">(<a href="#ref-ward1963" role="doc-biblioref">Ward 1963</a>)</span></td>
</tr>
<tr class="even">
<td>Hierarchical</td>
<td>Divisive</td>
<td>Association analysis <span class="citation">(<a href="#ref-ludwig1988statistical" role="doc-biblioref">Ludwig et al. 1988</a>, <a href="#ref-legendre2012numerical" role="doc-biblioref">Legendre and Legendre 2012</a>)</span>; TWINSPAN <span class="citation">(<a href="#ref-hill1979" role="doc-biblioref">Hill 1979</a>, <a href="#ref-rolecek2009" role="doc-biblioref">Roleček et al. 2009</a>)</span></td>
</tr>
</tbody>
</table>
<div id="k-means-clustering" class="section level3" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> <em>K</em>-means clustering</h3>
<p><em>K</em>-means clustering is a method for dividing a dataset with <em>n</em> observations, with <em>p</em> variables, into <em>k</em> categories such that each observation belongs to the cluster with the most similar mean . The “mean” for each category (i.e., group) is really a position in a <em>p</em>-dimensional hyperspace called a <strong>centroid</strong>. In this context, centroids are calculated as the point at the central coordinate of each dimension. The mean is most ofen used, but the median can be a useful alternative.</p>
<p>There are several algorithms for <em>k</em>-means clustering. One of the most common works like this:</p>
<ol style="list-style-type: decimal">
<li>Select the desired number of clusters <em>k</em>.</li>
<li>Make an initial guess of the mean of each cluster. I.e., Start with a <em>k</em> random positions in the <em>p</em>-dimensional hyperspace. These positions are known as centroids.</li>
<li>Calculate the Euclidean distance between each sample and each centroid.</li>
<li>Assign each sample to the category corresponding to the nearest centroid.</li>
<li>Update the centroids for each cluster by calculating the new centroid for the samples assigned to each cluster.</li>
<li>Repeat steps 3, 4, and 5 until cluster assignments no longer change.</li>
</ol>
<p>This algorithm is not guaranteed to find the best possible solution, but it usually works. Distance metrics other than the Euclidean can be used, but Euclidean is most common. Transforming, scaling, and/or standardizing variables so that they are all on the same scale can improve the results.</p>
<p>The figure below shows the effects of <em>k</em>-means clustering on a pretend dataset with 2 variables with <span class="math inline">\(k = 3\)</span>. The group assignments were determined because groups with those centroids had the smallest possible set of Euclidean distances between the points and the group centroids (right panel). Group centroids are added to the plot in yellow.</p>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_12.jpg" /></p>
<p>How many clusters are appropriate? That’s a good question to ask, and sometimes a tricky question to answer. One common way to assess the optimal <em>k</em> is to try several <em>k</em> and calculate the within-cluster sum of squared errors (<em>WSS</em>) for all points. The optimal value of <em>k</em> is the value at which a plot of <em>WSS</em> vs. <em>k</em> starts to bend. The example below illustrates this method for the data above.</p>
<div class="sourceCode" id="cb1610"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1610-1"><a href="mod-08.html#cb1610-1" aria-hidden="true" tabindex="-1"></a><span class="co"># generate a random dataset with 3 clusters</span></span>
<span id="cb1610-2"><a href="mod-08.html#cb1610-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb1610-3"><a href="mod-08.html#cb1610-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">20</span>, <span class="dv">5</span>, <span class="dv">2</span>), <span class="fu">rnorm</span>(<span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">2</span>))</span>
<span id="cb1610-4"><a href="mod-08.html#cb1610-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">10</span>, <span class="dv">3</span>, <span class="dv">2</span>), <span class="fu">rnorm</span>(<span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">2</span>), <span class="fu">rnorm</span>(<span class="dv">10</span>, <span class="dv">14</span>, <span class="dv">2</span>))</span>
<span id="cb1610-5"><a href="mod-08.html#cb1610-5" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x,y)</span>
<span id="cb1610-6"><a href="mod-08.html#cb1610-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1610-7"><a href="mod-08.html#cb1610-7" aria-hidden="true" tabindex="-1"></a><span class="co"># perform k-means clustering with k from 2 to 8</span></span>
<span id="cb1610-8"><a href="mod-08.html#cb1610-8" aria-hidden="true" tabindex="-1"></a>kvec <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">8</span></span>
<span id="cb1610-9"><a href="mod-08.html#cb1610-9" aria-hidden="true" tabindex="-1"></a>nk <span class="ot">&lt;-</span> <span class="fu">length</span>(kvec)</span>
<span id="cb1610-10"><a href="mod-08.html#cb1610-10" aria-hidden="true" tabindex="-1"></a>k.list <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&quot;list&quot;</span>, nk)</span>
<span id="cb1610-11"><a href="mod-08.html#cb1610-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nk){</span>
<span id="cb1610-12"><a href="mod-08.html#cb1610-12" aria-hidden="true" tabindex="-1"></a>    k.list[[i]] <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(dat, kvec[i])</span>
<span id="cb1610-13"><a href="mod-08.html#cb1610-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1610-14"><a href="mod-08.html#cb1610-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1610-15"><a href="mod-08.html#cb1610-15" aria-hidden="true" tabindex="-1"></a><span class="co"># gather WSS for each k</span></span>
<span id="cb1610-16"><a href="mod-08.html#cb1610-16" aria-hidden="true" tabindex="-1"></a>wss <span class="ot">&lt;-</span> <span class="fu">sapply</span>(k.list, <span class="cf">function</span>(x){x<span class="sc">$</span>tot.withinss})</span>
<span id="cb1610-17"><a href="mod-08.html#cb1610-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1610-18"><a href="mod-08.html#cb1610-18" aria-hidden="true" tabindex="-1"></a><span class="co"># plot WSS vs. k</span></span>
<span id="cb1610-19"><a href="mod-08.html#cb1610-19" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb1610-20"><a href="mod-08.html#cb1610-20" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(kvec, wss, <span class="at">type=</span><span class="st">&quot;o&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">pch=</span><span class="fl">1.5</span>,</span>
<span id="cb1610-21"><a href="mod-08.html#cb1610-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;Clusters (k)&quot;</span>,</span>
<span id="cb1610-22"><a href="mod-08.html#cb1610-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab=</span><span class="st">&quot;Total WSS&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-716-1.png" width="672" /></p>
<p>Notice that total <em>WSS</em> drops off much more slowly above 3 clusters. That is, going from 3 to 4 clusters reduces <em>WSS</em> much less than going from 2 to 3 clusters. The result above could reasonably justify 3 or 4 clusters. The figure below shows how the data are divided into 3 and 4 clusters.</p>
<div class="sourceCode" id="cb1611"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1611-1"><a href="mod-08.html#cb1611-1" aria-hidden="true" tabindex="-1"></a><span class="co"># assemble values needed for plots</span></span>
<span id="cb1611-2"><a href="mod-08.html#cb1611-2" aria-hidden="true" tabindex="-1"></a><span class="do">## get clusters</span></span>
<span id="cb1611-3"><a href="mod-08.html#cb1611-3" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>k3 <span class="ot">&lt;-</span> k.list[[<span class="fu">which</span>(kvec <span class="sc">==</span> <span class="dv">3</span>)]]<span class="sc">$</span>cluster</span>
<span id="cb1611-4"><a href="mod-08.html#cb1611-4" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>k4 <span class="ot">&lt;-</span> k.list[[<span class="fu">which</span>(kvec <span class="sc">==</span> <span class="dv">4</span>)]]<span class="sc">$</span>cluster</span>
<span id="cb1611-5"><a href="mod-08.html#cb1611-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1611-6"><a href="mod-08.html#cb1611-6" aria-hidden="true" tabindex="-1"></a><span class="do">## coordinates of group centroids</span></span>
<span id="cb1611-7"><a href="mod-08.html#cb1611-7" aria-hidden="true" tabindex="-1"></a>km3 <span class="ot">&lt;-</span> k.list[[<span class="fu">which</span>(kvec <span class="sc">==</span> <span class="dv">3</span>)]]</span>
<span id="cb1611-8"><a href="mod-08.html#cb1611-8" aria-hidden="true" tabindex="-1"></a>km4 <span class="ot">&lt;-</span> k.list[[<span class="fu">which</span>(kvec <span class="sc">==</span> <span class="dv">4</span>)]]</span>
<span id="cb1611-9"><a href="mod-08.html#cb1611-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1611-10"><a href="mod-08.html#cb1611-10" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>cenx3 <span class="ot">&lt;-</span> km3<span class="sc">$</span>centers[dat<span class="sc">$</span>k3,<span class="dv">1</span>]</span>
<span id="cb1611-11"><a href="mod-08.html#cb1611-11" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>ceny3 <span class="ot">&lt;-</span> km3<span class="sc">$</span>centers[dat<span class="sc">$</span>k3,<span class="dv">2</span>]</span>
<span id="cb1611-12"><a href="mod-08.html#cb1611-12" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>cenx4 <span class="ot">&lt;-</span> km4<span class="sc">$</span>centers[dat<span class="sc">$</span>k4,<span class="dv">1</span>]</span>
<span id="cb1611-13"><a href="mod-08.html#cb1611-13" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>ceny4 <span class="ot">&lt;-</span> km4<span class="sc">$</span>centers[dat<span class="sc">$</span>k4,<span class="dv">2</span>]</span>
<span id="cb1611-14"><a href="mod-08.html#cb1611-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1611-15"><a href="mod-08.html#cb1611-15" aria-hidden="true" tabindex="-1"></a><span class="do">## colors for each group</span></span>
<span id="cb1611-16"><a href="mod-08.html#cb1611-16" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>col3 <span class="ot">&lt;-</span> <span class="fu">rainbow</span>(<span class="dv">3</span>)[dat<span class="sc">$</span>k3]</span>
<span id="cb1611-17"><a href="mod-08.html#cb1611-17" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>col4 <span class="ot">&lt;-</span> <span class="fu">rainbow</span>(<span class="dv">4</span>)[dat<span class="sc">$</span>k4]</span>
<span id="cb1611-18"><a href="mod-08.html#cb1611-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1611-19"><a href="mod-08.html#cb1611-19" aria-hidden="true" tabindex="-1"></a><span class="co"># make plot</span></span>
<span id="cb1611-20"><a href="mod-08.html#cb1611-20" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb1611-21"><a href="mod-08.html#cb1611-21" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>dat<span class="sc">$</span>col3, <span class="at">cex=</span><span class="fl">1.4</span>,</span>
<span id="cb1611-22"><a href="mod-08.html#cb1611-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;Variable 1&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Variable 2&quot;</span>,</span>
<span id="cb1611-23"><a href="mod-08.html#cb1611-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">main=</span><span class="fu">expression</span>(<span class="fu">italic</span>(k)<span class="sc">==</span><span class="dv">3</span>))</span>
<span id="cb1611-24"><a href="mod-08.html#cb1611-24" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(dat<span class="sc">$</span>cenx3, dat<span class="sc">$</span>ceny3, dat<span class="sc">$</span>x, dat<span class="sc">$</span>y,</span>
<span id="cb1611-25"><a href="mod-08.html#cb1611-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span>dat<span class="sc">$</span>col3, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb1611-26"><a href="mod-08.html#cb1611-26" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(dat<span class="sc">$</span>cenx3, dat<span class="sc">$</span>ceny3, <span class="at">pch=</span><span class="dv">21</span>, <span class="at">cex=</span><span class="dv">2</span>,</span>
<span id="cb1611-27"><a href="mod-08.html#cb1611-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">bg=</span><span class="st">&quot;yellow&quot;</span>, <span class="at">col=</span>dat<span class="sc">$</span>col3, <span class="at">lwd=</span><span class="dv">4</span>)</span>
<span id="cb1611-28"><a href="mod-08.html#cb1611-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1611-29"><a href="mod-08.html#cb1611-29" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>dat<span class="sc">$</span>col4, <span class="at">cex=</span><span class="fl">1.4</span>,</span>
<span id="cb1611-30"><a href="mod-08.html#cb1611-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;Variable 1&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Variable 2&quot;</span>,</span>
<span id="cb1611-31"><a href="mod-08.html#cb1611-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">main=</span><span class="fu">expression</span>(<span class="fu">italic</span>(k)<span class="sc">==</span><span class="dv">4</span>))</span>
<span id="cb1611-32"><a href="mod-08.html#cb1611-32" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(dat<span class="sc">$</span>cenx4, dat<span class="sc">$</span>ceny4, dat<span class="sc">$</span>x, dat<span class="sc">$</span>y,</span>
<span id="cb1611-33"><a href="mod-08.html#cb1611-33" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span>dat<span class="sc">$</span>col4, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb1611-34"><a href="mod-08.html#cb1611-34" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(dat<span class="sc">$</span>cenx4, dat<span class="sc">$</span>ceny4, <span class="at">pch=</span><span class="dv">21</span>, <span class="at">cex=</span><span class="dv">2</span>,</span>
<span id="cb1611-35"><a href="mod-08.html#cb1611-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">bg=</span><span class="st">&quot;yellow&quot;</span>, <span class="at">col=</span>dat<span class="sc">$</span>col4, <span class="at">lwd=</span><span class="dv">4</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-717-1.png" width="864" /></p>
<p>Most of the group assignments stayed the same, but the algorithm split the blue group when <em>k</em> increased from 3 to 4. Accepting the 3 cluster or 4 cluster solution is as much of a biological decision as it is a statistical one. When you get to this point, you need to think about whether the groups make sense or not. Notice that <em>k</em>-means clustering does not necessarily result in groups of equal sizes. This may or may not be a problem depending on the structure of your dataset and the question you are trying to answer.</p>
<p>Below is another example of <em>k</em>-means clustering applied to the taxonomy dataset from above. Examine the figure and ask yourself whether the groupings make sense from a biological perspective. Note that the code block below requires that you have the data file <code>tax_example_2021-10-27.csv</code> in your R home directory. Download it <a href="https://greenquanteco.github.io/tax_example_2021-10-27.csv">here</a>. Note that this is a completely made-up dataset, so you should not use it for anything important.</p>
<div class="sourceCode" id="cb1612"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1612-1"><a href="mod-08.html#cb1612-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1612-2"><a href="mod-08.html#cb1612-2" aria-hidden="true" tabindex="-1"></a>in.name <span class="ot">&lt;-</span> <span class="st">&quot;tax_example_2021-10-27.csv&quot;</span></span>
<span id="cb1612-3"><a href="mod-08.html#cb1612-3" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(in.name, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb1612-4"><a href="mod-08.html#cb1612-4" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(dat) <span class="ot">&lt;-</span> dat<span class="sc">$</span>organism</span>
<span id="cb1612-5"><a href="mod-08.html#cb1612-5" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>organism <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb1612-6"><a href="mod-08.html#cb1612-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(dat)</span></code></pre></div>
<pre><code>##          multicellular heterotrophic flowering vertebrate gills amnion
## bacteria             0           0.5         0          0     0      0
## maple                1           0.0         1          0     0      0
## pine                 1           0.0         0          0     0      0
## octopus              1           1.0         0          0     1      0
## shark                1           1.0         0          1     1      0
## mushroom             1           1.0         0          0     0      0
##          endothermic tetrapod dna opisthokont protostome deuterostome
## bacteria           0        0   1           0          0            0
## maple              0        0   1           0          0            0
## pine               0        0   1           0          0            0
## octopus            0        0   1           1          1            0
## shark              0        0   1           1          0            1
## mushroom           0        0   1           1          0            0</code></pre>
<div class="sourceCode" id="cb1614"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1614-1"><a href="mod-08.html#cb1614-1" aria-hidden="true" tabindex="-1"></a>kvec <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">8</span></span>
<span id="cb1614-2"><a href="mod-08.html#cb1614-2" aria-hidden="true" tabindex="-1"></a>nk <span class="ot">&lt;-</span> <span class="fu">length</span>(kvec)</span>
<span id="cb1614-3"><a href="mod-08.html#cb1614-3" aria-hidden="true" tabindex="-1"></a>k.list <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&quot;list&quot;</span>, nk)</span>
<span id="cb1614-4"><a href="mod-08.html#cb1614-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nk){</span>
<span id="cb1614-5"><a href="mod-08.html#cb1614-5" aria-hidden="true" tabindex="-1"></a>    k.list[[i]] <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(dat, kvec[i])</span>
<span id="cb1614-6"><a href="mod-08.html#cb1614-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1614-7"><a href="mod-08.html#cb1614-7" aria-hidden="true" tabindex="-1"></a>wss <span class="ot">&lt;-</span> <span class="fu">sapply</span>(k.list, <span class="cf">function</span>(x){x<span class="sc">$</span>tot.withinss})</span>
<span id="cb1614-8"><a href="mod-08.html#cb1614-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1614-9"><a href="mod-08.html#cb1614-9" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb1614-10"><a href="mod-08.html#cb1614-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(kvec, wss, <span class="at">type=</span><span class="st">&quot;o&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">pch=</span><span class="fl">1.5</span>,</span>
<span id="cb1614-11"><a href="mod-08.html#cb1614-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;Clusters (k)&quot;</span>,</span>
<span id="cb1614-12"><a href="mod-08.html#cb1614-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab=</span><span class="st">&quot;Total WSS&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-718-1.png" width="672" /></p>
<p>Four clusters appears to be the “elbow” of the curve, but this varied from run to run (try changing the random number seed and seeing if you get different results). Let’s use <em>k</em> = 4.</p>
<div class="sourceCode" id="cb1615"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1615-1"><a href="mod-08.html#cb1615-1" aria-hidden="true" tabindex="-1"></a><span class="co"># assemble values needed for plots</span></span>
<span id="cb1615-2"><a href="mod-08.html#cb1615-2" aria-hidden="true" tabindex="-1"></a><span class="do">## get clusters</span></span>
<span id="cb1615-3"><a href="mod-08.html#cb1615-3" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>k4 <span class="ot">&lt;-</span> k.list[[<span class="fu">which</span>(kvec <span class="sc">==</span> <span class="dv">4</span>)]]<span class="sc">$</span>cluster</span>
<span id="cb1615-4"><a href="mod-08.html#cb1615-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1615-5"><a href="mod-08.html#cb1615-5" aria-hidden="true" tabindex="-1"></a><span class="do">## coordinates of group centroids</span></span>
<span id="cb1615-6"><a href="mod-08.html#cb1615-6" aria-hidden="true" tabindex="-1"></a>km4 <span class="ot">&lt;-</span> k.list[[<span class="fu">which</span>(kvec <span class="sc">==</span> <span class="dv">4</span>)]]</span>
<span id="cb1615-7"><a href="mod-08.html#cb1615-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1615-8"><a href="mod-08.html#cb1615-8" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>cenx4 <span class="ot">&lt;-</span> km4<span class="sc">$</span>centers[dat<span class="sc">$</span>k4,<span class="dv">1</span>]</span>
<span id="cb1615-9"><a href="mod-08.html#cb1615-9" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>ceny4 <span class="ot">&lt;-</span> km4<span class="sc">$</span>centers[dat<span class="sc">$</span>k4,<span class="dv">2</span>]</span>
<span id="cb1615-10"><a href="mod-08.html#cb1615-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1615-11"><a href="mod-08.html#cb1615-11" aria-hidden="true" tabindex="-1"></a><span class="do">## colors for each group</span></span>
<span id="cb1615-12"><a href="mod-08.html#cb1615-12" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>col4 <span class="ot">&lt;-</span> <span class="fu">rainbow</span>(<span class="dv">4</span>)[dat<span class="sc">$</span>k4]</span>
<span id="cb1615-13"><a href="mod-08.html#cb1615-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1615-14"><a href="mod-08.html#cb1615-14" aria-hidden="true" tabindex="-1"></a><span class="co"># use PCA to define a reduced dimensional space</span></span>
<span id="cb1615-15"><a href="mod-08.html#cb1615-15" aria-hidden="true" tabindex="-1"></a><span class="co"># (we&#39;ll cover PCA in detail later)</span></span>
<span id="cb1615-16"><a href="mod-08.html#cb1615-16" aria-hidden="true" tabindex="-1"></a>pr1 <span class="ot">&lt;-</span> <span class="fu">prcomp</span>(dat[,<span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>])</span>
<span id="cb1615-17"><a href="mod-08.html#cb1615-17" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>x <span class="ot">&lt;-</span> pr1<span class="sc">$</span>x[,<span class="dv">1</span>]</span>
<span id="cb1615-18"><a href="mod-08.html#cb1615-18" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>y <span class="ot">&lt;-</span> pr1<span class="sc">$</span>x[,<span class="dv">2</span>]</span>
<span id="cb1615-19"><a href="mod-08.html#cb1615-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1615-20"><a href="mod-08.html#cb1615-20" aria-hidden="true" tabindex="-1"></a><span class="co"># make plot</span></span>
<span id="cb1615-21"><a href="mod-08.html#cb1615-21" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb1615-22"><a href="mod-08.html#cb1615-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(dat<span class="sc">$</span>x, dat<span class="sc">$</span>y, <span class="at">type=</span><span class="st">&quot;n&quot;</span>,</span>
<span id="cb1615-23"><a href="mod-08.html#cb1615-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;PC 1(54%)&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PC2 (19%)&quot;</span>)</span>
<span id="cb1615-24"><a href="mod-08.html#cb1615-24" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(dat<span class="sc">$</span>x, <span class="fu">jitter</span>(dat<span class="sc">$</span>y, <span class="at">amount=</span><span class="fl">0.1</span>),</span>
<span id="cb1615-25"><a href="mod-08.html#cb1615-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rownames</span>(dat), <span class="at">col=</span>dat<span class="sc">$</span>col4)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-719-1.png" width="672" /></p>
<p>It’s a little hard to see some of the names, even with the jittering of the Y coordinates. How did the algorithm do? The groups appear to mostly make sense, but there are some oddities. For example:</p>
<ul>
<li>Elephants and penguins are more similar than either is to other mammals or birds, respectively (although they are in the same group).</li>
<li>Salamanders and frogs were grouped with fish and echinoderms, despite being tetrapods.</li>
<li>Mushrooms are clustered with the protostome invertebrates, despite being more closely related to yeast (which are grouped with the microbes and plants).</li>
</ul>
<p>So, the results of the <em>k</em>-means clustering are mostly okay, but there is definitely plenty of room for improvement.</p>
</div>
<div id="hierarchical-agglomerative-clustering" class="section level3" number="8.3.2">
<h3><span class="header-section-number">8.3.2</span> Hierarchical agglomerative clustering</h3>
<p>One key disadvantage of <em>k</em>-means clustering is that it is not hierarchical: all groups are assumed to be homogenous, with no within-group structure or subgroups. In biological systems this is rarely the case. Many biological phenomena can be understood as hierarchical: for example, phylogeny and taxonomy. Hierarchical clustering can help discover, or at take advantage of, these relationships within your data.</p>
<p>There are many methods of hierarchical clustering, just as there were many methods of <em>k</em>-means clustering. One of the most common is <strong>Ward’s method</strong> <span class="citation">(<a href="#ref-ward1963" role="doc-biblioref">Ward 1963</a>)</span>, which has many variations. The basic procedure is:</p>
<ol style="list-style-type: decimal">
<li>Start with every sample separate (i.e., in its own cluster).</li>
<li>Find a pair of clusters to combine that leads to the smallest increase in total within-cluster variance</li>
<li>Repeat step 2 until a stopping point is reached (varies by method).</li>
</ol>
<p>The within-cluster variance is an example of an <strong>objective function</strong>, which measures how effectively a statistical model represents the data. Different versions of Ward’s method use different objective functions. The most common is the Euclidean distance between cluster centroids. Squared Euclidean distance and other metrics are also seen in the literature.</p>
<p>The example below applies hierarchical clustering to the taxonomy dataset seen above. The base R function for hierarchical clustering is <code>hclust()</code>. The data are provided as a distance matrix rather than as raw values. We’ll use the <code>vegdist()</code> function from package <code>vegan</code> instead of the base R <code>dist()</code> function because it offers more distance metrics. Note that the code below assumes that you have the data file <code>tax_example_2021-10-27.csv</code> (<a href="https://greenquanteco.github.io/tax_example_2021-10-27.csv">here</a>) in your R home directory.</p>
<div class="sourceCode" id="cb1616"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1616-1"><a href="mod-08.html#cb1616-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1616-2"><a href="mod-08.html#cb1616-2" aria-hidden="true" tabindex="-1"></a>in.name <span class="ot">&lt;-</span> <span class="st">&quot;tax_example_2021-10-27.csv&quot;</span></span>
<span id="cb1616-3"><a href="mod-08.html#cb1616-3" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(in.name, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb1616-4"><a href="mod-08.html#cb1616-4" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(dat) <span class="ot">&lt;-</span> dat<span class="sc">$</span>organism</span>
<span id="cb1616-5"><a href="mod-08.html#cb1616-5" aria-hidden="true" tabindex="-1"></a>dat<span class="sc">$</span>organism <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb1616-6"><a href="mod-08.html#cb1616-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1616-7"><a href="mod-08.html#cb1616-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vegan)</span></code></pre></div>
<pre><code>## Loading required package: permute</code></pre>
<pre><code>## This is vegan 2.5-7</code></pre>
<div class="sourceCode" id="cb1619"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1619-1"><a href="mod-08.html#cb1619-1" aria-hidden="true" tabindex="-1"></a>d1 <span class="ot">&lt;-</span> <span class="fu">vegdist</span>(dat, <span class="at">method=</span><span class="st">&quot;euclidean&quot;</span>)</span>
<span id="cb1619-2"><a href="mod-08.html#cb1619-2" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> <span class="fu">vegdist</span>(dat) <span class="co"># default bray-curtis</span></span>
<span id="cb1619-3"><a href="mod-08.html#cb1619-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1619-4"><a href="mod-08.html#cb1619-4" aria-hidden="true" tabindex="-1"></a>h1 <span class="ot">&lt;-</span> <span class="fu">hclust</span>(d1, <span class="at">method=</span><span class="st">&quot;ward.D&quot;</span>)</span>
<span id="cb1619-5"><a href="mod-08.html#cb1619-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(h1)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-720-1.png" width="672" /></p>
<p>The results of hierarchical clustering are usually presented as a <strong>dendrogram</strong>. The word root <em>dendro</em>- means “tree”, which is a good way to think of a dendrogram. The branches show the relationship between the clusters. In the result above, pines and ferns form a cluster, as do maple and ivy. The “pine-fern” and “maple-ivy” clusters together form a bigger cluster.</p>
<p>The clustering based on Bray-Curtis distances is slightly different:</p>
<div class="sourceCode" id="cb1620"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1620-1"><a href="mod-08.html#cb1620-1" aria-hidden="true" tabindex="-1"></a>h2 <span class="ot">&lt;-</span> <span class="fu">hclust</span>(d2, <span class="at">method=</span><span class="st">&quot;ward.D&quot;</span>)</span>
<span id="cb1620-2"><a href="mod-08.html#cb1620-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(h2)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-721-1.png" width="672" /></p>
<p>The results using the Euclidean and Bray-Curtis distance metrics are similar, but both dendrograms make some “interesting” choices. For example, one would expect the most basal (toward the root of the tree) division between animals and non-animals, or between prokaryotes and eukaryotes. Is that the case?</p>
<p>Not at all. The method clustered the taxa in a way that doesn’t match their real-life phylogenetic relationships. This is partly because of the characteristics that were used (a very vertebrate animal-centric set!). This also illustrates the difference between taxonomy, which seeks to combine organisms by shared characteristics; and phylogeny, which results from how lineages divide over time.</p>
</div>
</div>
<div id="mod-08-sims" class="section level2" number="8.4">
<h2><span class="header-section-number">8.4</span> Analyzing dissimilarity</h2>
<p>A metric like the Bray-Curtis or Euclidean metric can quantify how different samples are from each other in terms of many variables simultaneously. The natural next question to ask is, “So what?”. Just as we can compare means between groups, or measure whether two variables are correlated, we can compare distances between groups or test whether two sets of distances are correlated. This document demonstrates some ways to use distance metrics to generalize common univariate and bivariate tests to patterns in higher dimensions.</p>
<div id="mantel-tests-distance-vs.-distance" class="section level3" number="8.4.1">
<h3><span class="header-section-number">8.4.1</span> Mantel tests: distance vs. distance</h3>
<p>One way to use distance metrics in a biological investigation is to calculate different distances between samples using different sets of variables, and then see if those distances are related. For example, an ecologist might calculate distances between sites using plant cover data, and a separate set of distances using soil chemistry data. She would then have one distance metric describing differences between the sites in terms of their plant cover, and a second distance metric describing differences between the sites in terms of their soil characteristics. A natural question to ask then is, “is distance in terms of plant cover related to distance in terms of soil chemistry?”. In other words, “do sites that are more similar in terms of their soil chemistry tend to be more similar in terms of their plant cover?”</p>
<p>Answering these questions is tantamount to calculating a <strong>correlation coefficient between two vectors of distance metrics</strong>. This procedure is called a <strong>Mantel test</strong> <span class="citation">(<a href="#ref-mantel1967detection" role="doc-biblioref">Mantel 1967</a>)</span>. The Mantel correlation coefficient <em>r</em> answers the question, “How is variation in one set of variables related to variation in another set of variables?”.</p>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_13.jpg" /></p>
<p>The example below uses the <code>iris</code> dataset to test whether variation in petal morphology is related to variation in sepal morphology. Note that while the Euclidean distance metric is used here because data are known to be multivariate normal, the Bray-Curtis or other metrics may be more appropriate in other situations.</p>
<div class="sourceCode" id="cb1621"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1621-1"><a href="mod-08.html#cb1621-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get sepal and petal variables from iris</span></span>
<span id="cb1621-2"><a href="mod-08.html#cb1621-2" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> iris[,<span class="fu">grep</span>(<span class="st">&quot;Sepal&quot;</span>, <span class="fu">names</span>(iris))]</span>
<span id="cb1621-3"><a href="mod-08.html#cb1621-3" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> iris[,<span class="fu">grep</span>(<span class="st">&quot;Petal&quot;</span>, <span class="fu">names</span>(iris))]</span>
<span id="cb1621-4"><a href="mod-08.html#cb1621-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1621-5"><a href="mod-08.html#cb1621-5" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate distance metrics</span></span>
<span id="cb1621-6"><a href="mod-08.html#cb1621-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vegan)</span>
<span id="cb1621-7"><a href="mod-08.html#cb1621-7" aria-hidden="true" tabindex="-1"></a>d1 <span class="ot">&lt;-</span> <span class="fu">vegdist</span>(x1, <span class="at">method=</span><span class="st">&quot;euclidean&quot;</span>)</span>
<span id="cb1621-8"><a href="mod-08.html#cb1621-8" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> <span class="fu">vegdist</span>(x2, <span class="at">method=</span><span class="st">&quot;euclidean&quot;</span>)</span>
<span id="cb1621-9"><a href="mod-08.html#cb1621-9" aria-hidden="true" tabindex="-1"></a>d3 <span class="ot">&lt;-</span> <span class="fu">vegdist</span>(x1) <span class="co"># vegdist() default metric = Bray-Curtis</span></span>
<span id="cb1621-10"><a href="mod-08.html#cb1621-10" aria-hidden="true" tabindex="-1"></a>d4 <span class="ot">&lt;-</span> <span class="fu">vegdist</span>(x2)</span>
<span id="cb1621-11"><a href="mod-08.html#cb1621-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1621-12"><a href="mod-08.html#cb1621-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Mantel test on Euclidean distances</span></span>
<span id="cb1621-13"><a href="mod-08.html#cb1621-13" aria-hidden="true" tabindex="-1"></a><span class="fu">mantel</span>(d1, d2)</span></code></pre></div>
<pre><code>## 
## Mantel statistic based on Pearson&#39;s product-moment correlation 
## 
## Call:
## mantel(xdis = d1, ydis = d2) 
## 
## Mantel statistic r: 0.7326 
##       Significance: 0.001 
## 
## Upper quantiles of permutations (null model):
##    90%    95%  97.5%    99% 
## 0.0242 0.0330 0.0409 0.0490 
## Permutation: free
## Number of permutations: 999</code></pre>
<p>The Mantel statistic <em>r</em> is exactly the same as the Pearson product moment correlation <em>r</em> between the two sets of distance metrics (verify this with the command <code>cor(d1, d2)</code>). The significance of the Mantel <em>r</em> is usually calculated by a permutation test instead of the more conventional methods . A <strong>permutation test</strong> for significance works by rearranging, or permuting, the observations many times and comparing a statistic (<em>r</em>) to the distribution of the statistic across the permutations. The <em>P</em>-value is calculated as the proportion of permutations that had a statistic with a magnitude at least as great as the original statistic. In the example above, <em>P</em> = 0.001 because at most 1 out of 999 permutations had an <em>r</em> <span class="math inline">\(\ge\)</span> 0.7326.</p>
<p>The function below will replicate the permutation test done for the Mantel test above. This function is provided for didactic purposes only. You should use the methods built into R and <code>vegan</code> instead. But, studying the code below can help you understand how a permutation test works.</p>
<div class="sourceCode" id="cb1623"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1623-1"><a href="mod-08.html#cb1623-1" aria-hidden="true" tabindex="-1"></a>simple.ptest <span class="ot">&lt;-</span> <span class="cf">function</span>(dm1, dm2, <span class="at">n=</span><span class="dv">999</span>){</span>
<span id="cb1623-2"><a href="mod-08.html#cb1623-2" aria-hidden="true" tabindex="-1"></a>    r <span class="ot">&lt;-</span> <span class="fu">cor</span>(dm1, dm2)</span>
<span id="cb1623-3"><a href="mod-08.html#cb1623-3" aria-hidden="true" tabindex="-1"></a>    dn <span class="ot">&lt;-</span> <span class="fu">length</span>(dm1)</span>
<span id="cb1623-4"><a href="mod-08.html#cb1623-4" aria-hidden="true" tabindex="-1"></a>    rvec <span class="ot">&lt;-</span> <span class="fu">numeric</span>(dn)</span>
<span id="cb1623-5"><a href="mod-08.html#cb1623-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>dn){</span>
<span id="cb1623-6"><a href="mod-08.html#cb1623-6" aria-hidden="true" tabindex="-1"></a>        i1 <span class="ot">&lt;-</span> d1[<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>dn, <span class="at">replace=</span><span class="cn">FALSE</span>)]</span>
<span id="cb1623-7"><a href="mod-08.html#cb1623-7" aria-hidden="true" tabindex="-1"></a>        i2 <span class="ot">&lt;-</span> d2[<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>dn, <span class="at">replace=</span><span class="cn">FALSE</span>)]</span>
<span id="cb1623-8"><a href="mod-08.html#cb1623-8" aria-hidden="true" tabindex="-1"></a>        rvec[i] <span class="ot">&lt;-</span> <span class="fu">cor</span>(i1, i2)</span>
<span id="cb1623-9"><a href="mod-08.html#cb1623-9" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb1623-10"><a href="mod-08.html#cb1623-10" aria-hidden="true" tabindex="-1"></a>    res <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">which</span>(rvec <span class="sc">&gt;=</span> r))<span class="sc">/</span>dn</span>
<span id="cb1623-11"><a href="mod-08.html#cb1623-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(res)</span>
<span id="cb1623-12"><a href="mod-08.html#cb1623-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1623-13"><a href="mod-08.html#cb1623-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1623-14"><a href="mod-08.html#cb1623-14" aria-hidden="true" tabindex="-1"></a><span class="fu">simple.ptest</span>(d1, d2, <span class="dv">999</span>)</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<p>Mantel tests are usually reported by their numerical outputs, but you can plot the results if the test is central to your presentation. The simplest way is to plot the distance metrics on a scatterplot. The example below uses partial transparency to better show the overlapping points. A diagonal red line shows where the two dissimilarities are equal.</p>
<div class="sourceCode" id="cb1625"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1625-1"><a href="mod-08.html#cb1625-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(d1, d2, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span><span class="st">&quot;#00000020&quot;</span>,</span>
<span id="cb1625-2"><a href="mod-08.html#cb1625-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;Sepal dissimilarity (Eucl.)&quot;</span>,</span>
<span id="cb1625-3"><a href="mod-08.html#cb1625-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab=</span><span class="st">&quot;Petal dissimilarity (Eucl.)&quot;</span>)</span>
<span id="cb1625-4"><a href="mod-08.html#cb1625-4" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="fu">max</span>(d1), <span class="fu">max</span>(d2), </span>
<span id="cb1625-5"><a href="mod-08.html#cb1625-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-724-1.png" width="576" /></p>
<p>The figure shows what the Mantel <em>r</em> statistic already indicated: that flowers with similar sepal morphology tend to have similar petal morphology.</p>
<p>Just for fun, the figure below visualizes the Mantel correlation based on the Euclidean (left) and Bray-Curtis (right) distances.</p>
<div class="sourceCode" id="cb1626"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1626-1"><a href="mod-08.html#cb1626-1" aria-hidden="true" tabindex="-1"></a>d3 <span class="ot">&lt;-</span> <span class="fu">vegdist</span>(x1) <span class="co"># default Bray-Curtis</span></span>
<span id="cb1626-2"><a href="mod-08.html#cb1626-2" aria-hidden="true" tabindex="-1"></a>d4 <span class="ot">&lt;-</span> <span class="fu">vegdist</span>(x2)</span>
<span id="cb1626-3"><a href="mod-08.html#cb1626-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mantel</span>(d3, d4)</span></code></pre></div>
<pre><code>## 
## Mantel statistic based on Pearson&#39;s product-moment correlation 
## 
## Call:
## mantel(xdis = d3, ydis = d4) 
## 
## Mantel statistic r: 0.6552 
##       Significance: 0.001 
## 
## Upper quantiles of permutations (null model):
##    90%    95%  97.5%    99% 
## 0.0260 0.0365 0.0459 0.0578 
## Permutation: free
## Number of permutations: 999</code></pre>
<div class="sourceCode" id="cb1628"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1628-1"><a href="mod-08.html#cb1628-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">mar=</span><span class="fu">c</span>(<span class="fl">5.1</span>, <span class="fl">5.1</span>, <span class="fl">1.1</span>, <span class="fl">1.1</span>),</span>
<span id="cb1628-2"><a href="mod-08.html#cb1628-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">bty=</span><span class="st">&quot;n&quot;</span>, <span class="at">lend=</span><span class="dv">1</span>, <span class="at">las=</span><span class="dv">1</span>,</span>
<span id="cb1628-3"><a href="mod-08.html#cb1628-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">cex.axis=</span><span class="fl">1.3</span>, <span class="at">cex.lab=</span><span class="fl">1.3</span>)</span>
<span id="cb1628-4"><a href="mod-08.html#cb1628-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(d1, d2, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span><span class="st">&quot;#00000020&quot;</span>,</span>
<span id="cb1628-5"><a href="mod-08.html#cb1628-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;Sepal dissimilarity (Euclidean)&quot;</span>,</span>
<span id="cb1628-6"><a href="mod-08.html#cb1628-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab=</span><span class="st">&quot;Petal dissimilarity (Euclidean)&quot;</span>)</span>
<span id="cb1628-7"><a href="mod-08.html#cb1628-7" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="fu">max</span>(d1), <span class="fu">max</span>(d2), </span>
<span id="cb1628-8"><a href="mod-08.html#cb1628-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb1628-9"><a href="mod-08.html#cb1628-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1628-10"><a href="mod-08.html#cb1628-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(d3, d4, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span><span class="st">&quot;#00000020&quot;</span>,</span>
<span id="cb1628-11"><a href="mod-08.html#cb1628-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;Sepal dissimilarity (Bray-Curtis)&quot;</span>,</span>
<span id="cb1628-12"><a href="mod-08.html#cb1628-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab=</span><span class="st">&quot;Petal dissimilarity (Bray-Curtis)&quot;</span>)</span>
<span id="cb1628-13"><a href="mod-08.html#cb1628-13" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="fu">max</span>(d3), <span class="fu">max</span>(d4), </span>
<span id="cb1628-14"><a href="mod-08.html#cb1628-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-725-1.png" width="864" /></p>
<p>Interestingly, the Bray-Curtis distances seemed to fall into two clusters in terms of the petal dissimilarity. That probably has something to do with the difference between <em>I</em>. <em>setosa</em> and the other species, but I haven’t investigated it.</p>
<p>The Mantel test can also be performed with correlation coefficients other than the linear correlation coefficient. This makes sense if the correlation appears nonlinear. For example, if one dissimilarity metric increases consistently with the other dissimilarity metric, but not in a straight line. The most common alternative is the Spearman’s rank correlation coefficient <span class="math inline">\(\rho\)</span> (“rho”).</p>
<div class="sourceCode" id="cb1629"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1629-1"><a href="mod-08.html#cb1629-1" aria-hidden="true" tabindex="-1"></a><span class="co"># euclidean distance metric</span></span>
<span id="cb1629-2"><a href="mod-08.html#cb1629-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mantel</span>(d1, d2, <span class="at">method=</span><span class="st">&quot;spearman&quot;</span>)</span></code></pre></div>
<pre><code>## 
## Mantel statistic based on Spearman&#39;s rank correlation rho 
## 
## Call:
## mantel(xdis = d1, ydis = d2, method = &quot;spearman&quot;) 
## 
## Mantel statistic r: 0.7258 
##       Significance: 0.001 
## 
## Upper quantiles of permutations (null model):
##    90%    95%  97.5%    99% 
## 0.0197 0.0253 0.0298 0.0362 
## Permutation: free
## Number of permutations: 999</code></pre>
<div class="sourceCode" id="cb1631"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1631-1"><a href="mod-08.html#cb1631-1" aria-hidden="true" tabindex="-1"></a><span class="co"># bray-curtis metric</span></span>
<span id="cb1631-2"><a href="mod-08.html#cb1631-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mantel</span>(d3, d4, <span class="at">method=</span><span class="st">&quot;spearman&quot;</span>)</span></code></pre></div>
<pre><code>## 
## Mantel statistic based on Spearman&#39;s rank correlation rho 
## 
## Call:
## mantel(xdis = d3, ydis = d4, method = &quot;spearman&quot;) 
## 
## Mantel statistic r:  0.69 
##       Significance: 0.001 
## 
## Upper quantiles of permutations (null model):
##    90%    95%  97.5%    99% 
## 0.0247 0.0331 0.0392 0.0540 
## Permutation: free
## Number of permutations: 999</code></pre>
<p>Changing from a linear to nonlinear correlation coefficient slightly decreased the Mantel correlation for the Euclidean distances (0.7326 to 0.7258), and slightly increased the correlation for the Bray-Curtis distances (0.6552 to 0.69). Examine the figure above and see if you can work out why this is.</p>
<p>The figure below shows the two sets of distances with two lines: a straight line to represent the linear correlation <em>r</em> and a spline curve to represent the nonlinear correlation <span class="math inline">\(\rho\)</span>.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-727-1.png" width="864" /></p>
</div>
<div id="comparing-dissimilarity-between-groups" class="section level3" number="8.4.2">
<h3><span class="header-section-number">8.4.2</span> Comparing dissimilarity between groups</h3>
<p>Just as the Mantel test generalizes the idea of correlation from “one variable vs. one variable” to “many variables vs. many variables”, other techniques generalize the idea of group differences from “difference in means between groups” to “differences in centroids between groups”. This section demonstrates three common tests for multivariate differences between groups.</p>
<div id="analysis-of-similarity-anosim-distances-between-groups" class="section level4" number="8.4.2.1">
<h4><span class="header-section-number">8.4.2.1</span> Analysis of similarity (ANOSIM): distances between groups</h4>
<p>The <strong>analysis of similarities (ANOSIM)</strong> is a nonparametric, ANOVA-like test that tests whether similarity between groups is greater than or equal to the similarity within groups <span class="citation">(<a href="#ref-clarke1993" role="doc-biblioref">Clarke 1993</a>)</span>. This is analogous to how ANOVA tests whether the difference in means (i.e., variance) between groups is greater than or equal to the variance within groups. What makes the test nonparametric is that it operates on the rank-transformed distance matrix rather than on the actual distance metrics.</p>
<p>The <code>vegan</code> function <code>anosim()</code> is used for ANOSIM. The function takes the original data matrix, a grouping variable, and can use any distance metric available in <code>vegan::vegdist()</code>. The example below uses the Euclidean metric because the data are known to be multivariate normal; you may need to use the Bray-Curtis or another metric with your own data.</p>
<div class="sourceCode" id="cb1633"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1633-1"><a href="mod-08.html#cb1633-1" aria-hidden="true" tabindex="-1"></a>a1 <span class="ot">&lt;-</span> <span class="fu">anosim</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>],</span>
<span id="cb1633-2"><a href="mod-08.html#cb1633-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">grouping=</span>iris<span class="sc">$</span>Species,</span>
<span id="cb1633-3"><a href="mod-08.html#cb1633-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">distance=</span><span class="st">&quot;euclidean&quot;</span>)</span>
<span id="cb1633-4"><a href="mod-08.html#cb1633-4" aria-hidden="true" tabindex="-1"></a>a1</span></code></pre></div>
<pre><code>## 
## Call:
## anosim(x = iris[, 1:4], grouping = iris$Species, distance = &quot;euclidean&quot;) 
## Dissimilarity: euclidean 
## 
## ANOSIM statistic R: 0.8794 
##       Significance: 0.001 
## 
## Permutation: free
## Number of permutations: 999</code></pre>
<p>Like the Mantel test, ANOSIM estimates a <em>P</em>-value by permutation. In this case, the permutation is of group membership. The underlying idea is that if there are no differences between groups (i.e., if the null hypothesis were true), then group membership is irrelevant and changing group memberships should not affect any test statistics. The ANOSIM statistic <em>R</em> expresses the relationship between the difference in mean ranks between groups (<span class="math inline">\(mr_{between}\)</span>) and the within groups (<span class="math inline">\(mr_{within}\)</span>).</p>
<p><span class="math display">\[R=\frac{mr_{between}-mr_{within}}{\frac{1}{4}n(n-1)}\]</span></p>
<p>The denominator scales the difference in mean ranks from -1 to 1. <em>R</em> = 0 means that grouping is unrelated to differences in mean ranks; greater <em>R</em> values indicate that differences between groups are greater than differences within groups; smaller <em>R</em> values indicate the reverse. The <em>R</em> value in our test above suggests that about 87.9% of the variation in the rank order of the distance matrix can be attributed to differences between species of <em>Iris</em>.</p>
</div>
<div id="mod-08-manova" class="section level4" number="8.4.2.2">
<h4><span class="header-section-number">8.4.2.2</span> MANOVA and PERMANOVA: distances between centroids</h4>
<p><strong>Multivariate analysis of variance (MANOVA)</strong> is an extension of ANOVA with multiple response variables. The underlying theory and matrix algebra is very similar to ANOVA, and so many of the same assumptions apply (just in many dimensions instead of one). For that reason, MANOVA is often not appropriate for real biological data without careful experimental design and exploratory data analysis to confirm that the test’s assumptions are met.</p>
<div class="sourceCode" id="cb1635"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1635-1"><a href="mod-08.html#cb1635-1" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span>
<span id="cb1635-2"><a href="mod-08.html#cb1635-2" aria-hidden="true" tabindex="-1"></a>mod1 <span class="ot">&lt;-</span> <span class="fu">manova</span>(Y<span class="sc">~</span>iris<span class="sc">$</span>Species)</span>
<span id="cb1635-3"><a href="mod-08.html#cb1635-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1635-4"><a href="mod-08.html#cb1635-4" aria-hidden="true" tabindex="-1"></a><span class="co"># (M)ANOVA table</span></span>
<span id="cb1635-5"><a href="mod-08.html#cb1635-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod1, <span class="at">test=</span><span class="st">&quot;Pillai&quot;</span>)</span></code></pre></div>
<pre><code>##               Df Pillai approx F num Df den Df    Pr(&gt;F)    
## iris$Species   2 1.1919   53.466      8    290 &lt; 2.2e-16 ***
## Residuals    147                                            
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb1637"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1637-1"><a href="mod-08.html#cb1637-1" aria-hidden="true" tabindex="-1"></a><span class="co"># coefficients for each response and level of predictor</span></span>
<span id="cb1637-2"><a href="mod-08.html#cb1637-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod1)</span></code></pre></div>
<pre><code>##                        Sepal.Length Sepal.Width Petal.Length Petal.Width
## (Intercept)                   5.006       3.428        1.462       0.246
## iris$Speciesversicolor        0.930      -0.658        2.798       1.080
## iris$Speciesvirginica         1.582      -0.454        4.090       1.780</code></pre>
<p><strong>Permutational analysis of variance (PERMANOVA)</strong> is a nonparametric version of MANOVA <span class="citation">(<a href="#ref-anderson2001" role="doc-biblioref">Anderson 2001</a>)</span>. It is nonparametric because it uses permutation of group membership to determine statistical significance instead of calculating an <em>F</em> statistic based on probability theory. The most common R function for PERMANOVA is <code>adonis()</code> from the <code>vegan</code> package.</p>
<div class="sourceCode" id="cb1639"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1639-1"><a href="mod-08.html#cb1639-1" aria-hidden="true" tabindex="-1"></a>mod2 <span class="ot">&lt;-</span> <span class="fu">adonis</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]<span class="sc">~</span>iris<span class="sc">$</span>Species, <span class="at">method=</span><span class="st">&quot;euclidean&quot;</span>)</span>
<span id="cb1639-2"><a href="mod-08.html#cb1639-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1639-3"><a href="mod-08.html#cb1639-3" aria-hidden="true" tabindex="-1"></a><span class="co"># (perm)anova table</span></span>
<span id="cb1639-4"><a href="mod-08.html#cb1639-4" aria-hidden="true" tabindex="-1"></a>mod2</span></code></pre></div>
<pre><code>## 
## Call:
## adonis(formula = iris[, 1:4] ~ iris$Species, method = &quot;euclidean&quot;) 
## 
## Permutation: free
## Number of permutations: 999
## 
## Terms added sequentially (first to last)
## 
##               Df SumsOfSqs MeanSqs F.Model      R2 Pr(&gt;F)    
## iris$Species   2    592.07 296.037  487.33 0.86894  0.001 ***
## Residuals    147     89.30   0.607         0.13106           
## Total        149    681.37                 1.00000           
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb1641"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1641-1"><a href="mod-08.html#cb1641-1" aria-hidden="true" tabindex="-1"></a><span class="co"># coefficients for each response and level of predictor</span></span>
<span id="cb1641-2"><a href="mod-08.html#cb1641-2" aria-hidden="true" tabindex="-1"></a>mod2<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##               Sepal.Length Sepal.Width Petal.Length Petal.Width
## (Intercept)     5.84333333   3.0573333        3.758   1.1993333
## iris$Species1  -0.83733333   0.3706667       -2.296  -0.9533333
## iris$Species2   0.09266667  -0.2873333        0.502   0.1266667</code></pre>
</div>
<div id="mod-08-mrpp" class="section level4" number="8.4.2.3">
<h4><span class="header-section-number">8.4.2.3</span> MRPP: differences in location</h4>
<p><strong>Multiple response permutation procedures (MRPP)</strong> is a permutational test for location that is very similar to ANOSIM <span class="citation">(<a href="#ref-mccune2002analysis" role="doc-biblioref">McCune et al. 2002</a>)</span>. The practical difference between MRPP and ANOSIM is that MRPP is typically used on coordinates within an ordination space (usually NMDS), while ANOSIM is usually used with all variables (i.e., on the original data).</p>
<p>In this example, we first fit an NMDS ordination to the <code>iris</code> data, then use MRPP to test whether the 3 species differ from each other. NMDS will be described in detail in its own page, but for now just understand that proximity in NMDS coordinates represents proximity in terms of the original variables. The question addressed by the MRPP is basically the same as asking whether the 3 clouds of points in the ordination space overlap or not.</p>
<div class="sourceCode" id="cb1643"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1643-1"><a href="mod-08.html#cb1643-1" aria-hidden="true" tabindex="-1"></a><span class="co"># NMDS ordination</span></span>
<span id="cb1643-2"><a href="mod-08.html#cb1643-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vegan)</span>
<span id="cb1643-3"><a href="mod-08.html#cb1643-3" aria-hidden="true" tabindex="-1"></a>n1 <span class="ot">&lt;-</span> <span class="fu">metaMDS</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span></code></pre></div>
<pre><code>## Run 0 stress 0.03775523 
## Run 1 stress 0.03775524 
## ... Procrustes: rmse 9.172761e-06  max resid 5.394399e-05 
## ... Similar to previous best
## Run 2 stress 0.03775524 
## ... Procrustes: rmse 8.541023e-06  max resid 7.918737e-05 
## ... Similar to previous best
## Run 3 stress 0.05313096 
## Run 4 stress 0.04367533 
## Run 5 stress 0.04355785 
## Run 6 stress 0.03775522 
## ... New best solution
## ... Procrustes: rmse 7.683165e-06  max resid 7.674469e-05 
## ... Similar to previous best
## Run 7 stress 0.03775524 
## ... Procrustes: rmse 6.562437e-06  max resid 2.98595e-05 
## ... Similar to previous best
## Run 8 stress 0.04367538 
## Run 9 stress 0.0505973 
## Run 10 stress 0.04804019 
## Run 11 stress 0.05059737 
## Run 12 stress 0.03775521 
## ... New best solution
## ... Procrustes: rmse 8.597169e-06  max resid 4.289104e-05 
## ... Similar to previous best
## Run 13 stress 0.03775522 
## ... Procrustes: rmse 2.949822e-06  max resid 1.237819e-05 
## ... Similar to previous best
## Run 14 stress 0.03775523 
## ... Procrustes: rmse 1.114005e-05  max resid 5.032798e-05 
## ... Similar to previous best
## Run 15 stress 0.06096633 
## Run 16 stress 0.0436752 
## Run 17 stress 0.03775525 
## ... Procrustes: rmse 1.186399e-05  max resid 7.094844e-05 
## ... Similar to previous best
## Run 18 stress 0.04709617 
## Run 19 stress 0.04367538 
## Run 20 stress 0.04713709 
## *** Solution reached</code></pre>
<div class="sourceCode" id="cb1645"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1645-1"><a href="mod-08.html#cb1645-1" aria-hidden="true" tabindex="-1"></a><span class="co"># extract scores (coordinates)</span></span>
<span id="cb1645-2"><a href="mod-08.html#cb1645-2" aria-hidden="true" tabindex="-1"></a>nx <span class="ot">&lt;-</span> <span class="fu">scores</span>(n1)[,<span class="dv">1</span>]</span>
<span id="cb1645-3"><a href="mod-08.html#cb1645-3" aria-hidden="true" tabindex="-1"></a>ny <span class="ot">&lt;-</span> <span class="fu">scores</span>(n1)[,<span class="dv">2</span>]</span>
<span id="cb1645-4"><a href="mod-08.html#cb1645-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1645-5"><a href="mod-08.html#cb1645-5" aria-hidden="true" tabindex="-1"></a><span class="co"># set up some colors for the plot</span></span>
<span id="cb1645-6"><a href="mod-08.html#cb1645-6" aria-hidden="true" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">rainbow</span>(<span class="dv">3</span>)</span>
<span id="cb1645-7"><a href="mod-08.html#cb1645-7" aria-hidden="true" tabindex="-1"></a>use.cols <span class="ot">&lt;-</span> cols[<span class="fu">as.numeric</span>(iris<span class="sc">$</span>Species)]</span>
<span id="cb1645-8"><a href="mod-08.html#cb1645-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1645-9"><a href="mod-08.html#cb1645-9" aria-hidden="true" tabindex="-1"></a><span class="co"># make the plot</span></span>
<span id="cb1645-10"><a href="mod-08.html#cb1645-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(nx, ny, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>use.cols, </span>
<span id="cb1645-11"><a href="mod-08.html#cb1645-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">cex=</span><span class="fl">1.5</span>,</span>
<span id="cb1645-12"><a href="mod-08.html#cb1645-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;NMDS 1&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;NMDS 2&quot;</span>)</span>
<span id="cb1645-13"><a href="mod-08.html#cb1645-13" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;top&quot;</span>, <span class="at">legend=</span><span class="fu">unique</span>(iris<span class="sc">$</span>Species),</span>
<span id="cb1645-14"><a href="mod-08.html#cb1645-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">pch=</span><span class="dv">16</span>, <span class="at">cex=</span><span class="fl">1.5</span>, <span class="at">col=</span>cols)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-731-1.png" width="672" /></p>
<p>The figure suggests that there is good separation between at least <em>I</em>. <em>setosa</em> and the other species, and likely separation between <em>I</em>. <em>versicolor</em> and <em>I</em>. <em>virginica</em>. The MRPP will test whether or not the clouds of points overlap.</p>
<div class="sourceCode" id="cb1646"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1646-1"><a href="mod-08.html#cb1646-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mrpp</span>(<span class="fu">scores</span>(n1), iris<span class="sc">$</span>Species)</span></code></pre></div>
<pre><code>## 
## Call:
## mrpp(dat = scores(n1), grouping = iris$Species) 
## 
## Dissimilarity index: euclidean 
## Weights for groups:  n 
## 
## Class means and counts:
## 
##       setosa  versicolor virginica
## delta 0.09269 0.1086     0.1035   
## n     50      50         50       
## 
## Chance corrected within-group agreement A: 0.6635 
## Based on observed delta 0.1016 and expected delta 0.3018 
## 
## Significance of delta: 0.001 
## Permutation: free
## Number of permutations: 999</code></pre>
<p>The test statistics are delta (<span class="math inline">\(\delta\)</span>), the weighted mean within-group distance; and <em>A</em>, the chance-corrected within-group agreement or agreement statistic.</p>
<ul>
<li>The <span class="math inline">\(\delta\)</span> value for each group with expresses how homogenous the group is.
<ul>
<li>When <span class="math inline">\(\delta\)</span> = 0, all members of a group are identical (i.e., have identical location in the NMDS space).</li>
<li>The mean of the group-level <span class="math inline">\(\delta\)</span> is reported as the “observed delta”.</li>
</ul></li>
<li>The agreement statistic <em>A</em> scales <span class="math inline">\(\delta\)</span> to the within-group homogeneity expected by chance if group membership was unrelated to location (expected delta in the output above).
<ul>
<li>Greater values of <em>A</em> indicate higher agreement within groups.</li>
<li><em>A</em> ranges from 0 (heterogeneity within groups equal to heterogeneity expected by chance) to 1 (items within groups identical).</li>
<li>In practice, values of <em>A</em> &gt; 0.3 are rather high.</li>
</ul></li>
</ul>
<p>The significance of the MRPP is calculated by permutation, just as in the Mantel test or ANOSIM. As with any statistical test, the <em>P</em>-value is sensitive to not only the effect size, but also the sample size. Large sample sizes can make tiny differences appear statistically significant, so it is up to you as a biologist to interpret the output of the test.</p>
</div>
</div>
</div>
<div id="mod-08-ord" class="section level2" number="8.5">
<h2><span class="header-section-number">8.5</span> Ordination</h2>
<p>In the <a href="mod-08.html#mod-08-sims">last section</a> we saw an application of <strong>ordination</strong>: representing high-dimensional relationships between objects in a 2-d space. This is done in such a way as to represent important patterns in the data in few enough dimensions for our 3-d brains to handle.</p>
<p>Ordination is literally <strong>ordering observations along two or more axes</strong>. That is, coming up with a new coordinate system that shows relationships between observations. How that ordering is done varies wildly among techniques. One broad class of techniques, collectively called <strong>eigenvector</strong> based methods, use the power of linear algebra to place the data into a new coordinate system that better captures the patterns in the data. The other class uses <strong>Monte Carlo sampling</strong> to find arrangements of samples that retain the important patterns in reduced dimension space.</p>
<p>No matter how they work, all ordination methods have the same goal: representing patterns found in many dimensions in fewer dimensions. For this course our focus will be on interpretation rather than calculation. The applications of ordination overlap with those of the multivariate techniques that we have already seen:</p>
<ul>
<li><strong>Cluster identification</strong>: observations that are closer to each other in the ordination space are more similar to each other</li>
<li><strong>Dimension reduction</strong>: the axes of an ordination are estimates of synthetic variables that combine information about many variables at once</li>
</ul>
<div id="principal-components-analysis-pca-1" class="section level3" number="8.5.1">
<h3><span class="header-section-number">8.5.1</span> Principal components analysis (PCA)</h3>
<div id="pca-intro" class="section level4" number="8.5.1.1">
<h4><span class="header-section-number">8.5.1.1</span> PCA intro</h4>
<p>Principal components analysis (PCA) is a method for extracting synthetic gradients from a multivariate dataset that capture most of the variation in that dataset. These gradients are calculated by finding linear combinations of the variables that minimize sums of squared deviations from the gradient. This means that PCA has a lot in common with linear regression, and many of the same assumptions apply.
If you’ve never heard of principal components analysis or ordination, it might be worth watching a video that explains and shows the basic ideas. Here is one that only takes 5 minutes and has a nice theme song (accessed 2021-08-10) .
Imagine a dataset with 2 variables, <em>x</em> and <em>y</em>. You could capture and display all the information about this dataset in a 2-d scatterplot, by simply plotting <em>y</em> vs. <em>x</em>. Likewise, you could capture and display all of the information about a 3-dimensional dataset with a 3-d plot. For 4 or more dimensions, a true scatterplot can’t be rendered sensibly or even understood by our pathetic meat-based brains.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-733-1.png" width="576" /></p>
<p>One way to describe the variation in the dataset above is to think about how the samples vary along each axis. The figure below shows how the variation among samples can be broken down into the variation in Variable 1 and the variation in Variable 2. When we say “variation in variable 1”, we mean “deviation between the values of variable 1 and the mean of variable 1”. That is what is shown in the figure below.</p>
<ul>
<li>Each point, or sample, has a Variable 1 coordinate and a Variable 2 coordinate.</li>
<li>Each point’s value for Variable 1 can be thought of as the difference between that value and the mean of Variable 1.</li>
<li>Likewise, each point’s value for Variable 2 can be thought of as the difference between that value and the mean of Variable 2.</li>
<li>The position of each point can thus be reframed as its deviation with respect to the Variable 1, and its deviation with respect to Variable 2. This reframing is the same as centering each variable (i.e., subtracting the mean).</li>
<li>The total variance among the samples is equal to the variance with respect to Variable 1 plus the variance with respect to Variable 2.</li>
</ul>
<p><img src="_main_files/figure-html/unnamed-chunk-734-1.png" width="864" /></p>
<p>The figure above shows how the total variation in the dataset is split up (“partitioned”) into variation in Variable 1 and variation in Variable 2.</p>
<p>Describing each observation as its deviation from the mean of each variable has the effect of <strong>centering</strong> the points at the origin. Notice that the variation, expressed as sums of squared deviations, is unchanged.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-735-1.png" width="864" /></p>
<p>If variables have different ranges, it is a good idea to scale them as well as center them (aka: standardizing or <em>Z</em>-scaling). This means that the original values are converted to <em>Z</em>-scores by subtracting the mean and dividing by the SD. Trying to use PCA or other eigenvector-based methods without standardizing variables will distort the results. Standardization puts variation along any axis on equal footing.</p>
<p>The figure below shows the data as deviations from variable means after standardization. Note that the sums of squares are equal in both directions now.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-736-1.png" width="864" />
If our goal is to describe variation in the data as succinctly as possible, then using Variable 1 and Variable 2 as axes might not be the best approach. Notice that most of the variation in the points doesn’t line up exactly with either of the variables, but along the red arrow shown below. The rest of the variation is along the direction perpendicular to the red arrow, illustrated by the blue arrow. (Note that the arrows may only appear perpendicular if the plot is precisely square).</p>
<p><img src="_main_files/figure-html/unnamed-chunk-737-1.png" width="576" /></p>
<p>The red arrow is a vector that contains information about both Variable 1 and Variable 2. It is tricky, but not too hard, to calculate each observation’s deviations from the mean of that vector (left panel below). We can also calculate the deviations along a perpendicular vector, because even after describing the variation in the “red” direction, there is still some variation in the “blue” direction (right panel).</p>
<pre><code>## [1] 21.44365</code></pre>
<pre><code>## [1] 76.55635</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-738-1.png" width="960" /></p>
<p>We know that the variation on the red and blue axes is the same as the variation on the <em>X</em> and <em>Y</em> axes, because the sums of squares are the same. The red and blue axes are just different ways of orienting the data to express the same patterns. All we really did was <strong>rotate</strong> the original coordinate system (defined by Variables 1 and 2) to a new coordinate system (defined by red and blue).</p>
<p>You may have guessed that the red and blue axes have special names: they are the <strong>principal components</strong> of this dataset. Principal components (PCs) are <strong>synthetic</strong> or <strong>composite axes</strong> that capture most of the variation. A PC is a <strong>linear combination</strong> of each of the original variables. This is easy to see in the figure above, because PC1 is defined by its coordinates. The same logic is true with more variables; it’s just harder to visualize.</p>
</div>
<div id="pcamore-details" class="section level4" number="8.5.1.2">
<h4><span class="header-section-number">8.5.1.2</span> PCA–more details</h4>
<p>The procedure above illustrates the geometric interpretation of PCA. The general procedure is:</p>
<ol style="list-style-type: decimal">
<li>Begin with the samples as a cloud of n points in a p-dimensional space.</li>
<li>Center (and usually scale) the axes in the point cloud. This will place the origin of the new coordinate system at the <em>p</em>-dimensional centroid of the cloud.</li>
<li>Rotate the axes to maximize the variance along the axes. As the angle of rotation <span class="math inline">\(\theta\)</span> changes, the variance <span class="math inline">\(\sigma^{2}\)</span> will also change.</li>
<li>Continue to rotate the axes until the variance along each axis is maximized. Because the data are changed only by rotation, the Euclidean distances between them are preserved.</li>
</ol>
<p>The other way PCA can be understood is in the language of linear algebra. The procedure is roughly given by:</p>
<ol style="list-style-type: decimal">
<li>Calculate the variance-covariance matrix <strong>S</strong> of the data matrix <strong>A</strong>. This is a <em>p</em> <span class="math inline">\(\times\)</span> <em>p</em> square matrix with the variances of each variable on the diagonal, and covariances between pairs of variables in the upper and lower triangles.</li>
<li>Find the eigenvalues <span class="math inline">\(\lambda\)</span> of <strong>S</strong>. Each eigenvalue represents a portion of the original total variance–the proportion corresponding to a particular principal component.</li>
<li>Find the eigenvectors. For each eigenvalue <span class="math inline">\(\lambda\)</span>, there is an eigenvector that contains the coefficients of the linear equation for that principal component. Together the eigenvectors form a <em>p</em> <span class="math inline">\(\times\)</span> <em>p</em> matrix, <strong>Y</strong>.</li>
<li>Find the scores for the original samples on each principal component as <span class="math inline">\(\textbf{X} = \textbf{AY}\)</span>.
The linear algebra method of PCA in R is illustrated below.</li>
</ol>
<div class="sourceCode" id="cb1650"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1650-1"><a href="mod-08.html#cb1650-1" aria-hidden="true" tabindex="-1"></a><span class="co"># generate some random data for PCA</span></span>
<span id="cb1650-2"><a href="mod-08.html#cb1650-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1650-3"><a href="mod-08.html#cb1650-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb1650-4"><a href="mod-08.html#cb1650-4" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="dv">1</span>, <span class="dv">20</span>)</span>
<span id="cb1650-5"><a href="mod-08.html#cb1650-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fl">1.2</span> <span class="sc">+</span> <span class="fl">1.7</span><span class="sc">*</span>x <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">15</span>)</span>
<span id="cb1650-6"><a href="mod-08.html#cb1650-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1650-7"><a href="mod-08.html#cb1650-7" aria-hidden="true" tabindex="-1"></a><span class="co"># produces data with a linear relationship between x and y</span></span>
<span id="cb1650-8"><a href="mod-08.html#cb1650-8" aria-hidden="true" tabindex="-1"></a><span class="co"># data matrix: n rows * p columns</span></span>
<span id="cb1650-9"><a href="mod-08.html#cb1650-9" aria-hidden="true" tabindex="-1"></a>A <span class="ot">&lt;-</span> <span class="fu">cbind</span>(x,y)</span>
<span id="cb1650-10"><a href="mod-08.html#cb1650-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1650-11"><a href="mod-08.html#cb1650-11" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize each variable</span></span>
<span id="cb1650-12"><a href="mod-08.html#cb1650-12" aria-hidden="true" tabindex="-1"></a>A <span class="ot">&lt;-</span> <span class="fu">apply</span>(A, <span class="dv">2</span>, scale)</span>
<span id="cb1650-13"><a href="mod-08.html#cb1650-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1650-14"><a href="mod-08.html#cb1650-14" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate variance-covariance matrix S</span></span>
<span id="cb1650-15"><a href="mod-08.html#cb1650-15" aria-hidden="true" tabindex="-1"></a>S <span class="ot">&lt;-</span> <span class="fu">cov</span>(A)</span></code></pre></div>
<p>The variance-covariance matrix <strong>S</strong> contains the variances of the variables on the diagonal. Both variances are 1 because we scaled the variables (compare to <code>cov(A)</code> to see the difference). This matrix <strong>S</strong> is symmetric because the covariance function is reflexive; i.e., Cov(x,y) = Cov(y,x). The variance-covariance matrix is useful because it contains information about both the spread (variance) and orientation (covariance) in the data. For a dataset like ours with 2 variables, the variance-covariance matrix has 2 dimensions (one for each variable).</p>
<p><span class="math display">\[ \textbf{S}= \begin{bmatrix}Var(x) &amp; Cov(x,y) \\ Cov(y,x) &amp; Var(y) \end{bmatrix} \]</span></p>
<div class="sourceCode" id="cb1651"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1651-1"><a href="mod-08.html#cb1651-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate eigenvalues and eigenvectors</span></span>
<span id="cb1651-2"><a href="mod-08.html#cb1651-2" aria-hidden="true" tabindex="-1"></a>eigens <span class="ot">&lt;-</span> <span class="fu">eigen</span>(S)</span>
<span id="cb1651-3"><a href="mod-08.html#cb1651-3" aria-hidden="true" tabindex="-1"></a>evals <span class="ot">&lt;-</span> eigens<span class="sc">$</span>values</span>
<span id="cb1651-4"><a href="mod-08.html#cb1651-4" aria-hidden="true" tabindex="-1"></a>evecs <span class="ot">&lt;-</span> eigens<span class="sc">$</span>vectors</span></code></pre></div>
<p>PCA is all about defining a new coordinate system for the data that preserves Euclidean distances, but maximizes the variance captured on the axes of the new system. The axes of the new system are found as linear combinations of the original variables. This means that the new coordinate system will have as many dimensions as the original coordinate system.</p>
<p>The data in our example can be thought of as a matrix with two columns; each sample is defined by a vector of length two (one for each dimension). That vector simply contains the <em>x</em> and <em>y</em> coordinates of the sample. If the dataset is matrix <strong>X</strong>, then each point is a vector <span class="math inline">\(v_{i}\)</span> where <em>i</em> = 1, 2, …, <em>n</em> (<em>n</em> = number of samples). For example, the vector [1, 2] corresponds to an observation with <em>x</em> = 1 and <em>y</em> = 2 (this vector is also a row of <strong>X</strong>).</p>
<p>To transform the points in the original coordinate system to a new coordinate system, we multiply each vector <span class="math inline">\(v_{i}\)</span> by a <em>p</em> <span class="math inline">\(\times\)</span> <em>p</em> transformation matrix <strong>T</strong> (recall that <em>p</em> is the number of dimensions) to get the transformed coordinates <span class="math inline">\(b_{i}\)</span>.</p>
<p><span class="math display">\[\textbf{T}v_{i}=b_{i}\]</span></p>
<p>Or written out fully:</p>
<p><span class="math display">\[\begin{bmatrix} \textbf{T}_{1,1} &amp; \textbf{T}_{1,2} \\ \textbf{T}_{2,1} &amp; \textbf{T}_{2,2} \end{bmatrix} \begin{bmatrix} x_{i} \\ y_{i} \end{bmatrix} =\begin{bmatrix}\textbf{T}_{1,1}x_{i} &amp; \textbf{T}_{1,2}y_{i} \\ \textbf{T}_{2,1}x_{i} &amp; \textbf{T}_{2,2}y_{i}\end{bmatrix}\]</span></p>
<p>It turns out that some vectors <span class="math inline">\(v_{i}\)</span> have a very interesting property: when transformed by <strong>T</strong>, they change length but not direction. These vectors are called <strong>eigenvectors</strong>. The <strong>scalar</strong> (aka: constant) that defines the change in their length (aka: magnitude) is called an <strong>eigenvalue</strong>. This property is expressed compactly as:</p>
<p><span class="math display">\[\textbf{T}v_{i}=\lambda b_{i} \]</span></p>
<p>The interpretation of this expression is that transforming a coordinate <span class="math inline">\(v_{i}\)</span> into a new coordinate system with matrix <strong>T</strong> is the same as multiplying <span class="math inline">\(v_{i}\)</span> by the eigenvalue <span class="math inline">\(\lambda\)</span>. If the eigenvectors are collected into a new matrix <strong>V</strong>, and the eigenvalues are collected into a vector <strong>L</strong>, then</p>
<p><span class="math display">\[\textbf{S}\textbf{V}=\textbf{L}\textbf{V} \]</span></p>
<p>Put in terms of our 2-d example,</p>
<p><span class="math display">\[\begin{bmatrix}Var(x) &amp; Cov(x,y) \\ Cov(y,x) &amp; Var(y) \end{bmatrix} \begin{bmatrix} v_{1}\\v_{2} \end{bmatrix}=
\begin{bmatrix}\lambda_{1}\\\lambda_{2} \end{bmatrix}
\begin{bmatrix}v_{1}\\v_{2} \end{bmatrix} \]</span></p>
<p>Once the terms are solved (by the computer!), we can put the eigenvectors in descending order of their eigenvalues to get the principal components.</p>
<div class="sourceCode" id="cb1652"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1652-1"><a href="mod-08.html#cb1652-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate scores by matrix operations</span></span>
<span id="cb1652-2"><a href="mod-08.html#cb1652-2" aria-hidden="true" tabindex="-1"></a>pc <span class="ot">&lt;-</span> A <span class="sc">%*%</span> evecs</span>
<span id="cb1652-3"><a href="mod-08.html#cb1652-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1652-4"><a href="mod-08.html#cb1652-4" aria-hidden="true" tabindex="-1"></a><span class="co"># check that variances = eigenvalues and </span></span>
<span id="cb1652-5"><a href="mod-08.html#cb1652-5" aria-hidden="true" tabindex="-1"></a><span class="co"># covariances = 0 (must be, by definition of PCA)</span></span>
<span id="cb1652-6"><a href="mod-08.html#cb1652-6" aria-hidden="true" tabindex="-1"></a><span class="do">## close enough (&lt;1e-16), probably a numerical limit involved</span></span>
<span id="cb1652-7"><a href="mod-08.html#cb1652-7" aria-hidden="true" tabindex="-1"></a><span class="fu">cov</span>(pc)</span></code></pre></div>
<pre><code>##              [,1]         [,2]
## [1,] 1.625446e+00 9.690887e-17
## [2,] 9.690887e-17 3.745539e-01</code></pre>
<div class="sourceCode" id="cb1654"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1654-1"><a href="mod-08.html#cb1654-1" aria-hidden="true" tabindex="-1"></a><span class="co"># variance explained by each PC</span></span>
<span id="cb1654-2"><a href="mod-08.html#cb1654-2" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(evals<span class="sc">/</span><span class="fu">sum</span>(evals),<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 0.813 0.187</code></pre>
<p>The result shows us that about 81% of the variation is explained by PC1 alone, with the remainder explained by PC2. Notice that all of the variation in the dataset is associated with 1 and only 1 PC. This is part of the definition of PCA–the total variation among the samples does not change. All that changes is how we describe the variation (i.e., how we orient the axes used to describe the samples).</p>
<p>Why go through all of this trouble? Besides the benefit of understanding what PCA is doing, we can use the linear algebra to translate between the coordinate system of the original data, and the coordinates system defined by the PCs. The algebra is complicated, but it boils down to multiplying the matrix of PC scores by the transpose of the eigenvector matrix:</p>
<div class="sourceCode" id="cb1656"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1656-1"><a href="mod-08.html#cb1656-1" aria-hidden="true" tabindex="-1"></a>backxy <span class="ot">&lt;-</span> pc <span class="sc">%*%</span> <span class="fu">t</span>(evecs)</span>
<span id="cb1656-2"><a href="mod-08.html#cb1656-2" aria-hidden="true" tabindex="-1"></a><span class="fu">range</span>(A<span class="sc">-</span>backxy)</span></code></pre></div>
<pre><code>## [1] -4.440892e-16  4.440892e-16</code></pre>
<p>The “back-calculated” coordinates are off by at most 4.5 <span class="math inline">\(\times\)</span> 10<sup>-16</sup>. The differences should technically be 0, but they are approximated to a very small number by R.</p>
</div>
<div id="pca-in-r-package-vegan" class="section level4" number="8.5.1.3">
<h4><span class="header-section-number">8.5.1.3</span> PCA in R (package <code>vegan</code>)</h4>
<p>There are two methods for PCA in base R: <code>prcomp()</code> and <code>princomp()</code>. Both of these methods produce similar outputs, and the only major difference between them is the syntax for extracting results. For this course we are going to use the ordination functions in package <code>vegan</code>. Although designed for community ecology, <code>vegan</code> is widely used for ordination and multivariate analysis in many fields . Importantly, <code>vegan</code> is actively maintained and updated with new techniques as they are developed. Also importantly, <code>vegan</code> offers a common interface for many kinds of ordination.</p>
<p>The example below uses the bat brain dataset that we have used before. Load the dataset into R and take a look. <span class="citation">Hutcheon et al. (<a href="#ref-hutcheon2002" role="doc-biblioref">2002</a>)</span> reported data on brain morphology and lifestyle from 63 species of bats. Their dataset contains the following variables:</p>
<table>
<thead>
<tr class="header">
<th>Variable</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>species</code></td>
<td>Species</td>
</tr>
<tr class="even">
<td><code>family</code></td>
<td>Taxonomic family</td>
</tr>
<tr class="odd">
<td><code>diet</code></td>
<td>Herbivore, gleaner, hawker, or vampire</td>
</tr>
<tr class="even">
<td><code>bow</code></td>
<td>Body weight (g)</td>
</tr>
<tr class="odd">
<td><code>brw</code></td>
<td>Brain weight (<span class="math inline">\(\mu\)</span>g)</td>
</tr>
<tr class="even">
<td><code>aud</code></td>
<td>Auditory nuclei volume (mm<sup>3</sup>)</td>
</tr>
<tr class="odd">
<td><code>mob</code></td>
<td>Main olfactory bulb volume (mm<sup>3</sup>)</td>
</tr>
<tr class="even">
<td><code>hip</code></td>
<td>Hippcampus volume (mm<sup>3</sup>)</td>
</tr>
</tbody>
</table>
<p>Import the dataset <code>bat_data_example.csv</code>. You can download it <a href="https://greenquanteco.github.io/bat_data_example.csv">here</a>. The code below requires that you have the file in your R working directory.</p>
<div class="sourceCode" id="cb1658"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1658-1"><a href="mod-08.html#cb1658-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vegan)</span>
<span id="cb1658-2"><a href="mod-08.html#cb1658-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rgl)</span>
<span id="cb1658-3"><a href="mod-08.html#cb1658-3" aria-hidden="true" tabindex="-1"></a>in.name <span class="ot">&lt;-</span> <span class="st">&quot;bat_data_example.csv&quot;</span></span>
<span id="cb1658-4"><a href="mod-08.html#cb1658-4" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(in.name, <span class="at">header=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p>We are going to explore how brain morphology, measured as volumes of various brain parts, varies with taxonomy and lifestyle. First, we need to make sure that our data are suitable for PCA. We can inspect distributions of the variables with histograms.</p>
<div class="sourceCode" id="cb1659"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1659-1"><a href="mod-08.html#cb1659-1" aria-hidden="true" tabindex="-1"></a>pc.cols <span class="ot">&lt;-</span> <span class="dv">4</span><span class="sc">:</span><span class="fu">ncol</span>(dat)</span>
<span id="cb1659-2"><a href="mod-08.html#cb1659-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))</span>
<span id="cb1659-3"><a href="mod-08.html#cb1659-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(pc.cols)){<span class="fu">hist</span>(dat[,pc.cols[i]])}</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-744-1.png" width="768" /></p>
<p>The histograms suggest that a log transform would be appropriate, because PCA requires multivariate normality.</p>
<div class="sourceCode" id="cb1660"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1660-1"><a href="mod-08.html#cb1660-1" aria-hidden="true" tabindex="-1"></a>dat2 <span class="ot">&lt;-</span> dat</span>
<span id="cb1660-2"><a href="mod-08.html#cb1660-2" aria-hidden="true" tabindex="-1"></a>dat2[,pc.cols] <span class="ot">&lt;-</span> <span class="fu">apply</span>(dat2[,pc.cols], <span class="dv">2</span>, log)</span>
<span id="cb1660-3"><a href="mod-08.html#cb1660-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))</span>
<span id="cb1660-4"><a href="mod-08.html#cb1660-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(pc.cols)){</span>
<span id="cb1660-5"><a href="mod-08.html#cb1660-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">hist</span>(dat2[,pc.cols[i]],</span>
<span id="cb1660-6"><a href="mod-08.html#cb1660-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">main=</span><span class="fu">names</span>(dat2)[pc.cols[i]])</span>
<span id="cb1660-7"><a href="mod-08.html#cb1660-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-745-1.png" width="768" /></p>
<p>Much better. We should also check to see if any of the variables are related to each other. It’s okay if they are, but such relationships need to be kept in mind when interpreting the PCA (or any ordination, for that matter). To explore relationships between the variables, we will use a <code>pairs()</code> plot and a function borrowed from the <code>pairs()</code> help page.</p>
<div class="sourceCode" id="cb1661"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1661-1"><a href="mod-08.html#cb1661-1" aria-hidden="true" tabindex="-1"></a><span class="co"># borrowed from ?pairs examples</span></span>
<span id="cb1661-2"><a href="mod-08.html#cb1661-2" aria-hidden="true" tabindex="-1"></a>panel.cor <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y, <span class="at">digits =</span> <span class="dv">2</span>, <span class="at">prefix =</span> <span class="st">&quot;&quot;</span>, cex.cor, ...)</span>
<span id="cb1661-3"><a href="mod-08.html#cb1661-3" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb1661-4"><a href="mod-08.html#cb1661-4" aria-hidden="true" tabindex="-1"></a>    usr <span class="ot">&lt;-</span> <span class="fu">par</span>(<span class="st">&quot;usr&quot;</span>); <span class="fu">on.exit</span>(<span class="fu">par</span>(usr))</span>
<span id="cb1661-5"><a href="mod-08.html#cb1661-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">par</span>(<span class="at">usr =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb1661-6"><a href="mod-08.html#cb1661-6" aria-hidden="true" tabindex="-1"></a>    r <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">cor</span>(x, y))</span>
<span id="cb1661-7"><a href="mod-08.html#cb1661-7" aria-hidden="true" tabindex="-1"></a>    txt <span class="ot">&lt;-</span> <span class="fu">format</span>(<span class="fu">c</span>(r, <span class="fl">0.123456789</span>), <span class="at">digits =</span> digits)[<span class="dv">1</span>]</span>
<span id="cb1661-8"><a href="mod-08.html#cb1661-8" aria-hidden="true" tabindex="-1"></a>    txt <span class="ot">&lt;-</span> <span class="fu">paste0</span>(prefix, txt)</span>
<span id="cb1661-9"><a href="mod-08.html#cb1661-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(<span class="fu">missing</span>(cex.cor)) cex.cor <span class="ot">&lt;-</span> <span class="fl">0.8</span><span class="sc">/</span><span class="fu">strwidth</span>(txt)</span>
<span id="cb1661-10"><a href="mod-08.html#cb1661-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">text</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>, txt, <span class="at">cex =</span> cex.cor <span class="sc">*</span> r)</span>
<span id="cb1661-11"><a href="mod-08.html#cb1661-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1661-12"><a href="mod-08.html#cb1661-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1661-13"><a href="mod-08.html#cb1661-13" aria-hidden="true" tabindex="-1"></a><span class="co"># make our plot:</span></span>
<span id="cb1661-14"><a href="mod-08.html#cb1661-14" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(dat2[,pc.cols],</span>
<span id="cb1661-15"><a href="mod-08.html#cb1661-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">lower.panel =</span> panel.smooth,</span>
<span id="cb1661-16"><a href="mod-08.html#cb1661-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">upper.panel =</span> panel.cor,</span>
<span id="cb1661-17"><a href="mod-08.html#cb1661-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">gap=</span><span class="dv">0</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-746-1.png" width="768" /></p>
<p>The scatterplot matrix suggests that every variable is closely related to every other variable. This makes sense for morphological data: the sizes of different body parts tend to scale with overall body size. We are interested in brain morphology independent of size, we can factor out size by dividing the volumes of each brain part by the body weight. Because the data are already on the log scale, the division is accomplished by subtracting the log-transformed body weight. The new values of <code>brw</code>, <code>aud</code>, <code>mob</code>, and <code>hip</code> are the sizes of those brain components with body size factored out. Neglecting to factor out body size or overall size prior to an ordination will result in an ordination dominated by body size.</p>
<div class="sourceCode" id="cb1662"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1662-1"><a href="mod-08.html#cb1662-1" aria-hidden="true" tabindex="-1"></a>dat3 <span class="ot">&lt;-</span> dat2</span>
<span id="cb1662-2"><a href="mod-08.html#cb1662-2" aria-hidden="true" tabindex="-1"></a>dat3[,pc.cols[<span class="sc">-</span><span class="dv">1</span>]] <span class="ot">&lt;-</span> <span class="fu">apply</span>(dat3[,pc.cols], <span class="dv">1</span>,</span>
<span id="cb1662-3"><a href="mod-08.html#cb1662-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(x){x[<span class="sc">-</span><span class="dv">1</span>]<span class="sc">-</span>x[<span class="dv">1</span>]})</span>
<span id="cb1662-4"><a href="mod-08.html#cb1662-4" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(dat3[,pc.cols],</span>
<span id="cb1662-5"><a href="mod-08.html#cb1662-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">lower.panel =</span> panel.smooth,</span>
<span id="cb1662-6"><a href="mod-08.html#cb1662-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">upper.panel =</span> panel.cor,</span>
<span id="cb1662-7"><a href="mod-08.html#cb1662-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">gap=</span><span class="dv">0</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-747-1.png" width="768" /></p>
<p>Next, use the function <code>rda()</code> from <code>vegan</code> to calculate the PCA. In this PCA we scale the variables (aka: standardize) by subtracting the mean and dividing by the SD. This has the effect of making each variable have mean = 0 and SD = 1. Scaling is not required for PCA but is <strong><em>highly</em></strong> recommended. If values are not scaled, then the PCA will be dominated by the variables with the greatest values or by the observations with extreme values.</p>
<div class="sourceCode" id="cb1663"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1663-1"><a href="mod-08.html#cb1663-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">rda</span>(dat3[,pc.cols], <span class="at">scale=</span><span class="cn">TRUE</span>)</span>
<span id="cb1663-2"><a href="mod-08.html#cb1663-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(p1)</span></code></pre></div>
<pre><code>## 
## Call:
## rda(X = dat3[, pc.cols], scale = TRUE) 
## 
## Partitioning of correlations:
##               Inertia Proportion
## Total               5          1
## Unconstrained       5          1
## 
## Eigenvalues, and their contribution to the correlations 
## 
## Importance of components:
##                          PC1    PC2    PC3    PC4     PC5
## Eigenvalue            1.4884 1.3471 1.0867 0.9389 0.13888
## Proportion Explained  0.2977 0.2694 0.2173 0.1878 0.02778
## Cumulative Proportion 0.2977 0.5671 0.7844 0.9722 1.00000
## 
## Scaling 2 for species and site scores
## * Species are scaled proportional to eigenvalues
## * Sites are unscaled: weighted dispersion equal on all dimensions
## * General scaling constant of scores:  4.196048 
## 
## 
## Species scores
## 
##         PC1     PC2     PC3     PC4     PC5
## bow  0.6502 -0.3804  0.3746  1.6772 -0.0256
## brw -0.8926 -1.2116 -1.0353  0.2617  0.3410
## aud -1.2718  0.7591  1.0657  0.2616  0.3513
## mob  0.9822  1.2887 -0.8596  0.1665  0.3596
## hip  1.1999 -0.9455  0.8601 -0.5732  0.3456
## 
## 
## Site scores (weighted sums of species scores)
## 
##           PC1      PC2      PC3       PC4       PC5
## sit1  -0.4822 -0.47110 -0.51367  0.032283  0.474975
## sit2  -0.1875  0.46735  0.51711  0.369969 -0.003147
## sit3   0.7140  0.21390 -0.80651 -0.818336 -0.071516
## sit4   0.4038 -0.72892  0.44826 -0.063108  0.690554
## sit5  -0.4484 -0.47079 -0.46877  0.246659 -0.080258
## sit6  -0.1740  0.54116  0.76904 -0.090556  0.443921
## sit7   0.7314  0.13147 -0.08352  0.791550  0.556946
## sit8   0.4378 -0.68647  0.29135 -0.318361 -0.389457
## sit9  -0.6786 -0.40593 -0.49047 -0.055734  0.047201
## sit10 -0.5471  0.46826  0.39227 -0.277305  0.021265
## sit11  0.5047  0.45175 -0.68715 -1.046120 -0.554421
## sit12  0.2737 -0.76045  0.56922 -0.009404  0.423659
## sit13 -0.7074 -0.40835 -0.46360 -0.442119  0.136189
## sit14 -0.4174  0.54986  0.56501  0.390291 -0.996710
## sit15  0.7238  0.23208 -0.69268  0.086960 -0.220235
## sit16  0.4023 -0.71503  0.56602  0.622207 -0.030857
## sit17 -0.5113 -0.39390 -0.48222  1.449440 -0.874003
## sit18 -0.5161  0.65950  0.41766 -0.464633  0.546833
## sit19  0.5582  0.59672 -0.21665  0.456523  0.041643
## sit20  0.7217 -0.57541  0.37694  0.361859  0.367978
## sit21 -0.7814 -0.18490 -0.59536 -0.546239  0.624799
## sit22 -0.5743  0.86534  0.31746 -0.031015 -0.046946
## sit23  0.6501  0.30104 -0.50589  0.704037  0.450911
## sit24  0.1322 -0.48776  0.29655 -0.905271  0.829062
## sit25 -0.6016 -0.09952 -0.25379  0.285644 -0.292755
## sit26  0.1762  0.68850  0.53632  0.011641 -0.162855
## sit27  0.7698  0.39111 -0.48473 -0.523310 -0.586544
## sit28  0.9450 -0.72682  0.51129  0.189683 -0.972058
## sit29 -0.5400 -0.44113 -0.89254  0.077095 -1.008438
## sit30 -0.2476  0.41802  0.76914  0.033110  0.585923
## sit31  0.4579  0.43434 -0.42246 -0.427813  1.254583
## sit32  0.3163 -0.48116  0.14197 -0.583475  0.258704
## sit33 -0.7874 -0.22881 -0.42449  0.020886  0.036846
## sit34 -0.3562  0.67117  0.40279  0.130779  0.254196
## sit35  0.5619  0.57716 -0.36416  0.198927 -0.096652
## sit36  0.3383 -0.69771  0.27202 -0.543479 -0.917745
## sit37 -0.5503 -0.04613 -0.87845 -0.183795  0.366676
## sit38 -0.5610  0.76767  0.14607 -0.233642  0.203234
## sit39  0.5757  0.53175 -0.44112  0.176223 -0.783513
## sit40  0.1957 -0.53875  0.38645 -0.748866  0.152175
## sit41 -0.5793 -0.50413 -0.38612  0.342061  0.134688
## sit42 -0.4700  0.34255  0.60210  0.442490  0.268606
## sit43  0.4381  0.72725 -0.50710 -0.652534 -0.132495
## sit44  0.3847 -0.57265  0.44835 -0.003145  0.642012
## sit45 -0.5225 -0.50720 -0.16657  0.831065  0.048770
## sit46 -0.1615  0.68519  0.58968  0.026128 -0.556304
## sit47  0.9713  0.04069 -0.36804  1.647929  0.094091
## sit48  0.2589 -0.69440  0.08940 -0.926043 -0.419415
## sit49 -0.4445 -0.20883 -0.92458 -0.132031  0.220466
## sit50 -0.5502  0.63824  0.32205  0.014305  0.458476
## sit51  0.5413  0.65064 -0.46422 -0.868767 -0.806164
## sit52  0.3340 -0.79973  0.88265  0.412611  0.351906
## sit53 -0.8137 -0.28059 -0.41296 -0.184942  0.305652
## sit54 -0.2019  0.32853  0.67470 -0.050061 -0.030891
## sit55  0.5214  0.37534 -0.43319 -0.221992  0.717535
## sit56  0.3656 -0.62963  0.49570 -0.443295  0.124316
## sit57 -0.4750 -0.49025 -0.34624  0.481810  0.037603
## sit58 -0.2769  0.47637  0.73519  0.163663  0.314753
## sit59  0.4670  0.13039 -0.27637  0.167998  0.281708
## sit60 -0.1991 -0.86051  0.80864 -0.561143 -0.932744
## sit61 -0.7639 -0.28665 -0.42427  0.151890 -0.689890
## sit62 -0.3285  0.65774  0.99773  0.038309 -1.346359
## sit63  0.5844  0.37256 -0.46123  1.000511  0.233515</code></pre>
<p>The summary of the output contains most of what we need. Of greatest interest are the relative contributions of each PC. That is, how much of the overall variation is associated with each PC.</p>
<p>The overall variation is the sum of the variances of the original variables. The PCA was fit using centered and scaled values, so we need to scale the original data to see the variances that were used in the PCA. The scaling meant that each variable ended up with mean = 0 and variance = 1, so the total variance was equal to 5.</p>
<div class="sourceCode" id="cb1665"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1665-1"><a href="mod-08.html#cb1665-1" aria-hidden="true" tabindex="-1"></a><span class="fu">apply</span>(<span class="fu">scale</span>(dat3[,pc.cols]), <span class="dv">2</span>, var)</span></code></pre></div>
<pre><code>## bow brw aud mob hip 
##   1   1   1   1   1</code></pre>
<p>That total variance of 5 was partitioned into 5 PCs. In PCA, data are ordinated on one PC for each of the original variables. Each PC is a combination of the original variables. The summary table for the PCA shows how the total variance was split up.</p>
<ul>
<li>The first row, <code>Eigenvalue</code>, is the variance associated with each PC. The sum of the eigenvalues equals the total variance, 5.</li>
<li>The <code>Proportion Explained</code> row shows the proportion of total variance captured on each PC. PC1 captures 29.8%, PC2 captured 26.9%, and so on. For example, the proportion of variance explained by PC1, 0.2977, is equal to the eigenvalue of PC1 divided by the total variance (1.4884 / 5).</li>
<li>The <code>Cumulative Proportion</code> row is the running total of proportion of variance explained, starting with PC1. The rule of thumb for PCA is that you should present and interpret enough PCs to capture <span class="math inline">\(\ge\)</span> 80% of the variation. In this example, it takes 3 PCs to get up to about 80% of the variation explained). Two PCs is easier to deal with, but sometimes you need 3.</li>
</ul>
<div class="sourceCode" id="cb1667"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1667-1"><a href="mod-08.html#cb1667-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(p1)<span class="sc">$</span>cont<span class="sc">$</span>importance</span></code></pre></div>
<pre><code>## Importance of components:
##                          PC1    PC2    PC3    PC4     PC5
## Eigenvalue            1.4884 1.3471 1.0867 0.9389 0.13888
## Proportion Explained  0.2977 0.2694 0.2173 0.1878 0.02778
## Cumulative Proportion 0.2977 0.5671 0.7844 0.9722 1.00000</code></pre>
<p>An alternative strategy for deciding how many PCs to interpret is to look at a screeplot, which shows the relative contributions of each PC to the overall variance. The variance is expressed as “Inertia”–the eigenvalues of the PCs. The proportion explained by each axis (seen in the table above), is simply the eigenvalues of the axes divided by the total of all eigenvalues. Some people prefer to present a screeplot that shows proportion of variance explained rather than the eigenvalues.</p>
<div class="sourceCode" id="cb1669"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1669-1"><a href="mod-08.html#cb1669-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb1669-2"><a href="mod-08.html#cb1669-2" aria-hidden="true" tabindex="-1"></a><span class="fu">screeplot</span>(p1, <span class="at">main=</span><span class="st">&quot;Eigenvalues&quot;</span>)</span>
<span id="cb1669-3"><a href="mod-08.html#cb1669-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1669-4"><a href="mod-08.html#cb1669-4" aria-hidden="true" tabindex="-1"></a><span class="co"># alternative version with proportion of variance explained</span></span>
<span id="cb1669-5"><a href="mod-08.html#cb1669-5" aria-hidden="true" tabindex="-1"></a><span class="co"># instead of eigenvalues (variances)</span></span>
<span id="cb1669-6"><a href="mod-08.html#cb1669-6" aria-hidden="true" tabindex="-1"></a>prx <span class="ot">&lt;-</span> <span class="dv">100</span><span class="sc">*</span><span class="fu">summary</span>(p1)<span class="sc">$</span>cont<span class="sc">$</span>importance[<span class="dv">2</span>,]</span>
<span id="cb1669-7"><a href="mod-08.html#cb1669-7" aria-hidden="true" tabindex="-1"></a><span class="fu">barplot</span>(prx, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">30</span>),</span>
<span id="cb1669-8"><a href="mod-08.html#cb1669-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">main=</span><span class="st">&quot;%Variance&quot;</span>,</span>
<span id="cb1669-9"><a href="mod-08.html#cb1669-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab=</span><span class="st">&quot;Proportion of variance explained&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-751-1.png" width="672" /></p>
<p>The <strong>loadings</strong> of the variables express how much each variable is associated with each PC. These values have two interpretations:</p>
<ul>
<li>First, they are the correlations between the variables and the PCs.</li>
<li>Second, they are the coordinates for the biplot vectors (see below), which help us see the relationships between the ordination and the variables.
<ul>
<li>Note: the biplot vectors implied by these coordinates are sometimes rescaled to more faithfully represent the relationships between variables. See <span class="citation">Legendre and Legendre (<a href="#ref-legendre2012numerical" role="doc-biblioref">2012</a>)</span> for a thorough explanation.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb1670"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1670-1"><a href="mod-08.html#cb1670-1" aria-hidden="true" tabindex="-1"></a><span class="fu">scores</span>(p1, <span class="at">choices =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>, <span class="at">display =</span> <span class="st">&quot;species&quot;</span>, <span class="at">scaling =</span> <span class="dv">0</span>)</span></code></pre></div>
<pre><code>##            PC1        PC2        PC3         PC4
## bow  0.2840062 -0.1746469  0.1914720  0.92240824
## brw -0.3898723 -0.5563058 -0.5292561  0.14392406
## aud -0.5555135  0.3485255  0.5448121  0.14388004
## mob  0.4290023  0.5917029 -0.4394228  0.09156649
## hip  0.5241200 -0.4340967  0.4396748 -0.31521900
## attr(,&quot;const&quot;)
## [1] 4.196048</code></pre>
<p>PC1 is most strongly correlated with <code>aud</code> (<em>r</em> = -0.55) and <code>hip</code> (<em>r</em> = 0.52). PC2 is most strongly correlated with <code>mob</code> (<em>r</em> = 0.59) and <code>brw</code> (<em>r</em> = -0.55). Ideally, each PC would have a few variables strongly correlated with it (<em>r</em> &gt; 0.7), but that isn’t the case here. Interestingly, most of the variables are moderately correlated with first three axes. This suggests that none of the variables is strongly driving any of the PCs. We can check this with a biplot.</p>
<p>An ordination <strong>biplot</strong> is probably the most important tool for interpreting the relationships in the data captured by the ordination. It is called a biplot because it presents two kinds of data: <em>similarity between the samples</em> indicated by proximity in the ordination space; and <em>relationships between some set of quantitative variables and the ordination axes</em>. The samples are plotted as points; the variables are plotted as vectors radiating from the origin.</p>
<div class="sourceCode" id="cb1672"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1672-1"><a href="mod-08.html#cb1672-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb1672-2"><a href="mod-08.html#cb1672-2" aria-hidden="true" tabindex="-1"></a><span class="fu">biplot</span>(p1)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-753-1.png" width="576" /></p>
<p>The biplot shows the points (by row name/number) and the five numeric variables that went into the PCA. Each vector shows the projection of a variable into the ordination space.</p>
<ul>
<li>The direction of a vector shows the direction (in ordination space) in which a variable increases. For example, samples in the upper left have increased aud; samples in the upper right have increased mob, and so on. A variable decreases in the direction opposite its vector: samples in the lower right have decreased aud.
<ul>
<li>Compare the variable loadings with the biplot arrows. Do these values make sense?</li>
</ul></li>
<li>Relative angles of vectors reflect the correlation between the underlying variables.
<ul>
<li>Variables whose vectors point in the same direction are positively correlated with each other; the smaller the angle between two vectors, the stronger the correlation (<em>r</em> approaching 1).</li>
<li>Vectors perpendicular to each other are uncorrelated (<em>r</em> close to 0).</li>
<li>Vectors pointing in opposite directions are negatively correlated with each other (<em>r</em> approaching -1).</li>
<li>Correlation coefficients cannot be inferred directly from angles because of how the coordinates on the plot are scaled, but the angles do give a <em>rough</em> idea.</li>
</ul></li>
<li>The length of a vector indicates the strength of the correlation with the ordination space. Longer vectors indicate stronger correlations (|<em>r</em> |).</li>
<li>Each variable vectors represents an axis of the original coordinate system.
<ul>
<li>Shorter vectors have most of their length off the plane of the biplot.</li>
<li>Longer vectors have more of their length near the plane of the biplot.</li>
<li>The biplot is really a plane within the original data coordinate system defined by the PCs.</li>
</ul></li>
</ul>
<p>Because it took 3 PCs to get up to about 80% of the variation, we should present and interpret the first 3 PCs. We can plot other variables with the <code>biplot()</code> command.</p>
<div class="sourceCode" id="cb1673"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1673-1"><a href="mod-08.html#cb1673-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb1673-2"><a href="mod-08.html#cb1673-2" aria-hidden="true" tabindex="-1"></a><span class="fu">biplot</span>(p1, <span class="at">choices=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb1673-3"><a href="mod-08.html#cb1673-3" aria-hidden="true" tabindex="-1"></a><span class="fu">biplot</span>(p1, <span class="at">choices=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))</span>
<span id="cb1673-4"><a href="mod-08.html#cb1673-4" aria-hidden="true" tabindex="-1"></a><span class="fu">biplot</span>(p1, <span class="at">choices=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-754-1.png" width="768" /></p>
<p>Even better, we can make a 3-d plot using the <code>rgl</code> package. Note that the code block below was not run to make this page; try running it on your machine. The plots made by <code>plot3d()</code> are cool because you can rotate them with the mouse. Exporting <code>rgl</code> figures to static image formats like <code>.jpg</code> can be tricky because you must specify the rotation angles, which can pretty much only be done by trial and error.</p>
<div class="sourceCode" id="cb1674"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1674-1"><a href="mod-08.html#cb1674-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rgl)</span>
<span id="cb1674-2"><a href="mod-08.html#cb1674-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb1674-3"><a href="mod-08.html#cb1674-3" aria-hidden="true" tabindex="-1"></a>px <span class="ot">&lt;-</span> <span class="fu">scores</span>(p1, <span class="at">choices=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)<span class="sc">$</span>sites</span>
<span id="cb1674-4"><a href="mod-08.html#cb1674-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot3d</span>(px[,<span class="dv">1</span>], px[,<span class="dv">2</span>], px[,<span class="dv">3</span>],</span>
<span id="cb1674-5"><a href="mod-08.html#cb1674-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;PC1&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PC2&quot;</span>, <span class="at">zlab=</span><span class="st">&quot;PC3&quot;</span>)</span></code></pre></div>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_14.jpg" alt="Screen capture of a 3-d plot produced by rgl::plot3d()" /></p>
<p>We can add more information to the biplots to help us make sense of the data. Let’s color-code the diets.</p>
<div class="sourceCode" id="cb1675"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1675-1"><a href="mod-08.html#cb1675-1" aria-hidden="true" tabindex="-1"></a>diets <span class="ot">&lt;-</span> <span class="fu">sort</span>(<span class="fu">unique</span>(dat3<span class="sc">$</span>diet))</span>
<span id="cb1675-2"><a href="mod-08.html#cb1675-2" aria-hidden="true" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">rainbow</span>(<span class="fu">length</span>(diets))</span>
<span id="cb1675-3"><a href="mod-08.html#cb1675-3" aria-hidden="true" tabindex="-1"></a>use.cols <span class="ot">&lt;-</span> cols[<span class="fu">match</span>(dat3<span class="sc">$</span>diet, diets)]</span>
<span id="cb1675-4"><a href="mod-08.html#cb1675-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1675-5"><a href="mod-08.html#cb1675-5" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb1675-6"><a href="mod-08.html#cb1675-6" aria-hidden="true" tabindex="-1"></a>px <span class="ot">&lt;-</span> <span class="fu">scores</span>(p1, <span class="at">choices=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)<span class="sc">$</span>sites</span>
<span id="cb1675-7"><a href="mod-08.html#cb1675-7" aria-hidden="true" tabindex="-1"></a>vx <span class="ot">&lt;-</span> <span class="fu">scores</span>(p1, <span class="at">choices=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)<span class="sc">$</span>species</span>
<span id="cb1675-8"><a href="mod-08.html#cb1675-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot3d</span>(px[,<span class="dv">1</span>], px[,<span class="dv">2</span>], px[,<span class="dv">3</span>],</span>
<span id="cb1675-9"><a href="mod-08.html#cb1675-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;PC1&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PC2&quot;</span>, <span class="at">zlab=</span><span class="st">&quot;PC3&quot;</span>,</span>
<span id="cb1675-10"><a href="mod-08.html#cb1675-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span>use.cols, <span class="at">size=</span><span class="dv">50</span>)</span>
<span id="cb1675-11"><a href="mod-08.html#cb1675-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(vx)){</span>
<span id="cb1675-12"><a href="mod-08.html#cb1675-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">segments3d</span>(<span class="fu">c</span>(<span class="dv">0</span>, vx[i,<span class="dv">1</span>]), <span class="fu">c</span>(<span class="dv">0</span>, vx[i,<span class="dv">2</span>]), <span class="fu">c</span>(<span class="dv">0</span>, vx[i,<span class="dv">3</span>]), <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb1675-13"><a href="mod-08.html#cb1675-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">text3d</span>(vx[i,<span class="dv">1</span>], vx[i,<span class="dv">2</span>], vx[i,<span class="dv">3</span>], <span class="fu">rownames</span>(vx)[i], <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb1675-14"><a href="mod-08.html#cb1675-14" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_15.jpg" alt="Screen capture of an improved 3-d plot produced by rgl::plot3d()" /></p>
<p>The <code>biplot()</code> command in <code>vegan</code> isn’t very flexible, so we if we want a nicer-looking plot we will need to construct it manually.</p>
<div class="sourceCode" id="cb1676"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1676-1"><a href="mod-08.html#cb1676-1" aria-hidden="true" tabindex="-1"></a>px <span class="ot">&lt;-</span> <span class="fu">scores</span>(p1, <span class="at">choices=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)<span class="sc">$</span>sites</span>
<span id="cb1676-2"><a href="mod-08.html#cb1676-2" aria-hidden="true" tabindex="-1"></a>vx <span class="ot">&lt;-</span> <span class="fu">scores</span>(p1, <span class="at">choices=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>)<span class="sc">$</span>species</span>
<span id="cb1676-3"><a href="mod-08.html#cb1676-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1676-4"><a href="mod-08.html#cb1676-4" aria-hidden="true" tabindex="-1"></a>diets <span class="ot">&lt;-</span> <span class="fu">sort</span>(<span class="fu">unique</span>(dat3<span class="sc">$</span>diet))</span>
<span id="cb1676-5"><a href="mod-08.html#cb1676-5" aria-hidden="true" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">rainbow</span>(<span class="fu">length</span>(diets))</span>
<span id="cb1676-6"><a href="mod-08.html#cb1676-6" aria-hidden="true" tabindex="-1"></a>use.cols <span class="ot">&lt;-</span> cols[<span class="fu">match</span>(dat3<span class="sc">$</span>diet, diets)]</span>
<span id="cb1676-7"><a href="mod-08.html#cb1676-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1676-8"><a href="mod-08.html#cb1676-8" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb1676-9"><a href="mod-08.html#cb1676-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(px[,<span class="dv">1</span>], px[,<span class="dv">2</span>], <span class="at">pch=</span><span class="dv">16</span>, <span class="at">cex=</span><span class="fl">1.4</span>, <span class="at">col=</span>use.cols,</span>
<span id="cb1676-10"><a href="mod-08.html#cb1676-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;PC1&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PC2&quot;</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>))</span>
<span id="cb1676-11"><a href="mod-08.html#cb1676-11" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">0</span>, <span class="dv">0</span>, vx[,<span class="dv">1</span>], vx[,<span class="dv">2</span>], <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb1676-12"><a href="mod-08.html#cb1676-12" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(vx[,<span class="dv">1</span>], vx[,<span class="dv">2</span>], <span class="fu">rownames</span>(vx), <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb1676-13"><a href="mod-08.html#cb1676-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(px[,<span class="dv">1</span>], px[,<span class="dv">3</span>], <span class="at">pch=</span><span class="dv">16</span>, <span class="at">cex=</span><span class="fl">1.4</span>, <span class="at">col=</span>use.cols,</span>
<span id="cb1676-14"><a href="mod-08.html#cb1676-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;PC1&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PC3&quot;</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>))</span>
<span id="cb1676-15"><a href="mod-08.html#cb1676-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1676-16"><a href="mod-08.html#cb1676-16" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">0</span>, <span class="dv">0</span>, vx[,<span class="dv">1</span>], vx[,<span class="dv">3</span>], <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb1676-17"><a href="mod-08.html#cb1676-17" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(vx[,<span class="dv">1</span>], vx[,<span class="dv">3</span>], <span class="fu">rownames</span>(vx), <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb1676-18"><a href="mod-08.html#cb1676-18" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(px[,<span class="dv">2</span>], px[,<span class="dv">3</span>], <span class="at">pch=</span><span class="dv">16</span>, <span class="at">cex=</span><span class="fl">1.4</span>, <span class="at">col=</span>use.cols,</span>
<span id="cb1676-19"><a href="mod-08.html#cb1676-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;PC2&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PC3&quot;</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>))</span>
<span id="cb1676-20"><a href="mod-08.html#cb1676-20" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">0</span>, <span class="dv">0</span>, vx[,<span class="dv">2</span>], vx[,<span class="dv">3</span>], <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb1676-21"><a href="mod-08.html#cb1676-21" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(vx[,<span class="dv">2</span>], vx[,<span class="dv">3</span>], <span class="fu">rownames</span>(vx), <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-757-1.png" width="864" /></p>
</div>
<div id="application-of-pca-pc-regression" class="section level4" number="8.5.1.4">
<h4><span class="header-section-number">8.5.1.4</span> Application of PCA: PC regression</h4>
<p>Because PCs capture information about multiple variables at once, they can be used to represent those variables <em>in other statistical methods</em>. For example, a PC that represents many measurements of body parts or tree species composition or gene expression can be used as a predictor variable in a logistic regression or as a response variable. This practice is sometimes called <strong>PC regression</strong>. The example below uses the <code>iris</code> dataset to illustrate using principal components of flower morphology to predict species identity.</p>
<div class="sourceCode" id="cb1677"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1677-1"><a href="mod-08.html#cb1677-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vegan)</span>
<span id="cb1677-2"><a href="mod-08.html#cb1677-2" aria-hidden="true" tabindex="-1"></a><span class="co"># grab numeric variables</span></span>
<span id="cb1677-3"><a href="mod-08.html#cb1677-3" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]</span>
<span id="cb1677-4"><a href="mod-08.html#cb1677-4" aria-hidden="true" tabindex="-1"></a><span class="co"># standardize each variable</span></span>
<span id="cb1677-5"><a href="mod-08.html#cb1677-5" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">apply</span>(dat, <span class="dv">2</span>, scale)</span>
<span id="cb1677-6"><a href="mod-08.html#cb1677-6" aria-hidden="true" tabindex="-1"></a><span class="co"># fit PCA with vegan::rda()</span></span>
<span id="cb1677-7"><a href="mod-08.html#cb1677-7" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">rda</span>(dat)</span>
<span id="cb1677-8"><a href="mod-08.html#cb1677-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1677-9"><a href="mod-08.html#cb1677-9" aria-hidden="true" tabindex="-1"></a><span class="co"># examine output</span></span>
<span id="cb1677-10"><a href="mod-08.html#cb1677-10" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(p1)</span></code></pre></div>
<pre><code>## 
## Call:
## rda(X = dat) 
## 
## Partitioning of variance:
##               Inertia Proportion
## Total               4          1
## Unconstrained       4          1
## 
## Eigenvalues, and their contribution to the variance 
## 
## Importance of components:
##                          PC1    PC2     PC3      PC4
## Eigenvalue            2.9185 0.9140 0.14676 0.020715
## Proportion Explained  0.7296 0.2285 0.03669 0.005179
## Cumulative Proportion 0.7296 0.9581 0.99482 1.000000
## 
## Scaling 2 for species and site scores
## * Species are scaled proportional to eigenvalues
## * Sites are unscaled: weighted dispersion equal on all dimensions
## * General scaling constant of scores:  4.940963 
## 
## 
## Species scores
## 
##                 PC1      PC2     PC3      PC4
## Sepal.Length  2.199 -0.89142  0.6810  0.09290
## Sepal.Width  -1.137 -2.18073 -0.2313 -0.04392
## Petal.Length  2.450 -0.05785 -0.1345 -0.28497
## Petal.Width   2.384 -0.15811 -0.6003  0.18617
## 
## 
## Site scores (weighted sums of species scores)
## 
##              PC1       PC2       PC3       PC4
## sit1   -0.534807 -0.202559  0.134486  0.067744
## sit2   -0.491417  0.284467  0.247065  0.288729
## sit3   -0.558311  0.144276 -0.046548  0.079541
## sit4   -0.542997  0.252085 -0.096137 -0.184874
## sit5   -0.564359 -0.272948 -0.016574 -0.100692
## sit6   -0.490158 -0.628394 -0.028400  0.018523
## sit7   -0.577155 -0.020105 -0.353282 -0.103082
## sit8   -0.527285 -0.094163  0.093405 -0.068988
## sit9   -0.551323  0.470639 -0.152779 -0.075287
## sit10  -0.515827  0.197911  0.267239 -0.111838
## sit11  -0.511572 -0.440410  0.282946  0.046898
## sit12  -0.549314 -0.056156 -0.098737 -0.374156
## sit13  -0.523885  0.307482  0.243171  0.006797
## sit14  -0.621804  0.405731 -0.190395 -0.053861
## sit15  -0.519231 -0.784896  0.498009  0.545836
## sit16  -0.534220 -1.133542 -0.032147  0.141647
## sit17  -0.521320 -0.626044  0.005628  0.529258
## sit18  -0.517249 -0.206277  0.046563  0.260934
## sit19  -0.448346 -0.592881  0.394218  0.171253
## sit20  -0.553384 -0.475923 -0.139672 -0.105832
## sit21  -0.452066 -0.172526  0.443660  0.030613
## sit22  -0.521184 -0.389955 -0.168353  0.167052
## sit23  -0.655159 -0.193409 -0.349815  0.055075
## sit24  -0.429477 -0.036103 -0.036320  0.423650
## sit25  -0.525943 -0.057918 -0.124258 -0.757207
## sit26  -0.460927  0.263995  0.321868  0.122104
## sit27  -0.484377 -0.102187 -0.090949  0.189708
## sit28  -0.512107 -0.222443  0.217797  0.028802
## sit29  -0.505256 -0.132170  0.285546  0.236180
## sit30  -0.534939  0.142514 -0.072069 -0.303510
## sit31  -0.505388  0.212903  0.078991 -0.135074
## sit32  -0.432529 -0.178788  0.284827  0.672360
## sit33  -0.617518 -0.756842 -0.049736 -0.642551
## sit34  -0.577663 -0.907551  0.087057 -0.135146
## sit35  -0.498269  0.194193  0.179315  0.081352
## sit36  -0.521372  0.086972  0.237411  0.473451
## sit37  -0.482959 -0.279160  0.510263  0.550396
## sit38  -0.596827 -0.249932 -0.020468 -0.382624
## sit39  -0.573755  0.381540 -0.203515 -0.027297
## sit40  -0.512375 -0.113460  0.185222  0.019754
## sit41  -0.539949 -0.186392 -0.036748  0.299875
## sit42  -0.438794  0.986328  0.215078  0.812492
## sit43  -0.603039  0.202168 -0.322000 -0.186685
## sit44  -0.463903 -0.199310 -0.326039  0.496394
## sit45  -0.504665 -0.481991 -0.261624 -0.423377
## sit46  -0.488768  0.300046  0.067324  0.393177
## sit47  -0.563153 -0.472792 -0.060256 -0.426705
## sit48  -0.565430  0.162986 -0.146873 -0.136884
## sit49  -0.526482 -0.421113  0.191129 -0.041844
## sit50  -0.520433 -0.003889  0.161154  0.138390
## sit51   0.260185 -0.364152  0.720933  0.097640
## sit52   0.172705 -0.250912  0.099119  0.013745
## sit53   0.293056 -0.260062  0.583421  0.026414
## sit54   0.096227  0.740313  0.024328  0.184351
## sit55   0.253972  0.087948  0.419400  0.293579
## sit56   0.091788  0.250350 -0.130785 -0.675053
## sit57   0.176292 -0.326194 -0.156879 -0.216869
## sit58  -0.115081  0.781677 -0.262499 -0.113579
## sit59   0.219123 -0.013599  0.627822 -0.083753
## sit60   0.002698  0.436329 -0.567511 -0.079777
## sit61  -0.026023  1.119949  0.049275  0.038572
## sit62   0.104069  0.026709 -0.215962  0.112474
## sit63   0.132741  0.744668  0.806428  0.128185
## sit64   0.169924  0.078582  0.072304 -0.461957
## sit65  -0.007877  0.185248 -0.205282  0.305664
## sit66   0.206727 -0.214812  0.530244  0.294159
## sit67   0.082712  0.082838 -0.516935 -0.536803
## sit68   0.037503  0.334244  0.318073 -0.575452
## sit69   0.289305  0.684545  0.507911  0.633200
## sit70   0.038945  0.549667  0.182014 -0.144991
## sit71   0.174203 -0.167343 -0.649260 -0.233447
## sit72   0.112475  0.176098  0.279019  0.318333
## sit73   0.291450  0.393839  0.387972 -0.027875
## sit74   0.149449  0.175705  0.307394 -0.768643
## sit75   0.165933  0.026758  0.469708  0.121814
## sit76   0.206459 -0.105828  0.497670  0.285111
## sit77   0.296723  0.032600  0.765762  0.111247
## sit78   0.320786 -0.139805  0.274675  0.187320
## sit79   0.156992  0.095336 -0.090423 -0.102141
## sit80  -0.009507  0.446752  0.336540  0.181602
## sit81   0.030887  0.659238  0.157947 -0.026355
## sit82   0.005538  0.663544  0.254377 -0.091862
## sit83   0.057039  0.327982  0.159240  0.066295
## sit84   0.250577  0.267465 -0.110903 -0.515666
## sit85   0.052892  0.121433 -0.700570 -0.714287
## sit86   0.101341 -0.356814 -0.474560 -0.307421
## sit87   0.247656 -0.220292  0.416800  0.104297
## sit88   0.246665  0.583585  0.724840  0.383552
## sit89   0.016433  0.092625 -0.307060 -0.412448
## sit90   0.066943  0.560940 -0.094157  0.024963
## sit91   0.065904  0.472623 -0.099504 -0.758656
## sit92   0.147492 -0.010517  0.021569 -0.413967
## sit93   0.079471  0.417081  0.209976  0.018305
## sit94  -0.085529  0.852066 -0.111439  0.054857
## sit95   0.068149  0.361096 -0.137839 -0.301050
## sit96   0.021575  0.076458 -0.135826 -0.644580
## sit97   0.053775  0.162426 -0.164507 -0.371696
## sit98   0.136114  0.065353  0.286073 -0.055670
## sit99  -0.105716  0.651440 -0.200510  0.560453
## sit100  0.060627  0.252700 -0.096757 -0.164318
## sit101  0.435593 -0.367295 -1.058781 -0.138048
## sit102  0.273433  0.294905 -0.558308 -0.113580
## sit103  0.520772 -0.237154  0.213687  0.165894
## sit104  0.340090  0.019828 -0.172318 -0.660867
## sit105  0.441082 -0.124501 -0.416633 -0.045684
## sit106  0.649852 -0.337752  0.613226 -0.284182
## sit107  0.086671  0.658913 -1.039290 -0.373148
## sit108  0.543719 -0.177257  0.686307 -0.667233
## sit109  0.473877  0.300209  0.414909 -0.242490
## sit110  0.533644 -0.810616 -0.418659  0.293865
## sit111  0.322149 -0.292325 -0.299723  0.302334
## sit112  0.378471  0.177947 -0.024417  0.163504
## sit113  0.444881 -0.176912 -0.027737  0.410403
## sit114  0.297575  0.490444 -0.611056  0.277939
## sit115  0.346583  0.186627 -1.057168  0.772676
## sit116  0.375495 -0.285358 -0.672325  0.537795
## sit117  0.347477 -0.107866 -0.039419 -0.435393
## sit118  0.572975 -1.078844  0.134671 -0.767485
## sit119  0.781818 -0.007503  0.740646  0.126664
## sit120  0.298437  0.720202  0.281741 -0.182703
## sit121  0.481205 -0.384193 -0.247266  0.470770
## sit122  0.230949  0.241270 -0.872095  0.077799
## sit123  0.684278 -0.174546  0.902945 -0.356926
## sit124  0.314842  0.203312  0.005717  0.392307
## sit125  0.401627 -0.427849 -0.314296 -0.172788
## sit126  0.461512 -0.425256  0.442283 -0.612005
## sit127  0.277500  0.133510 -0.136837  0.351555
## sit128  0.241097 -0.027152 -0.355646 -0.024258
## sit129  0.422317  0.079062 -0.285028  0.087139
## sit130  0.440099 -0.237272  0.753629 -0.583630
## sit131  0.575248 -0.109411  0.766458 -0.050239
## sit132  0.544307 -1.108240  0.519674 -0.593330
## sit133  0.439876  0.075343 -0.372952  0.280329
## sit134  0.263105  0.123606  0.193230 -0.522324
## sit135  0.283963  0.342354  0.173469 -1.372029
## sit136  0.660927 -0.361549  0.571731  0.829359
## sit137  0.372231 -0.450913 -0.996072  0.099803
## sit138  0.317926 -0.178255 -0.190479 -0.603829
## sit139  0.218397 -0.007268 -0.438957  0.014683
## sit140  0.437359 -0.285308  0.013345  0.547135
## sit141  0.475796 -0.259044 -0.451074  0.693853
## sit142  0.449105 -0.290983 -0.136981  1.316566
## sit143  0.273433  0.294905 -0.558308 -0.113580
## sit144  0.481876 -0.366071 -0.356097  0.126660
## sit145  0.471861 -0.442722 -0.665990  0.599972
## sit146  0.441718 -0.163290 -0.269880  1.091092
## sit147  0.369474  0.378378  0.027771  0.617201
## sit148  0.359223 -0.113540 -0.189745  0.334038
## sit149  0.324183 -0.426723 -0.982952  0.073239
## sit150  0.226858  0.010267 -0.556295 -0.457110</code></pre>
<div class="sourceCode" id="cb1679"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1679-1"><a href="mod-08.html#cb1679-1" aria-hidden="true" tabindex="-1"></a><span class="co"># make some colors to label species</span></span>
<span id="cb1679-2"><a href="mod-08.html#cb1679-2" aria-hidden="true" tabindex="-1"></a>use.col <span class="ot">&lt;-</span> <span class="fu">rainbow</span>(<span class="dv">3</span>)[<span class="fu">match</span>(iris<span class="sc">$</span>Species,<span class="fu">levels</span>(iris<span class="sc">$</span>Species))]</span>
<span id="cb1679-3"><a href="mod-08.html#cb1679-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1679-4"><a href="mod-08.html#cb1679-4" aria-hidden="true" tabindex="-1"></a><span class="co"># extract scores of samples (px) and biplot vectors (vx)</span></span>
<span id="cb1679-5"><a href="mod-08.html#cb1679-5" aria-hidden="true" tabindex="-1"></a>px <span class="ot">&lt;-</span> <span class="fu">scores</span>(p1, <span class="at">display=</span><span class="st">&quot;sites&quot;</span>)</span>
<span id="cb1679-6"><a href="mod-08.html#cb1679-6" aria-hidden="true" tabindex="-1"></a>vx <span class="ot">&lt;-</span> <span class="fu">scores</span>(p1,<span class="at">display=</span><span class="st">&quot;species&quot;</span>)</span>
<span id="cb1679-7"><a href="mod-08.html#cb1679-7" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb1679-8"><a href="mod-08.html#cb1679-8" aria-hidden="true" tabindex="-1"></a><span class="co"># make a plot of the flowers in PCA space</span></span>
<span id="cb1679-9"><a href="mod-08.html#cb1679-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(px[,<span class="dv">1</span>], px[,<span class="dv">2</span>], <span class="at">col=</span>use.col, <span class="at">pch=</span><span class="dv">16</span>,</span>
<span id="cb1679-10"><a href="mod-08.html#cb1679-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>),</span>
<span id="cb1679-11"><a href="mod-08.html#cb1679-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;PC1&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PC2&quot;</span>)</span>
<span id="cb1679-12"><a href="mod-08.html#cb1679-12" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">0</span>, <span class="dv">0</span>, vx[,<span class="dv">1</span>], vx[,<span class="dv">2</span>], <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb1679-13"><a href="mod-08.html#cb1679-13" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(vx[,<span class="dv">1</span>], vx[,<span class="dv">2</span>], <span class="fu">rownames</span>(vx), <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb1679-14"><a href="mod-08.html#cb1679-14" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">legend=</span><span class="fu">levels</span>(iris<span class="sc">$</span>Species),</span>
<span id="cb1679-15"><a href="mod-08.html#cb1679-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span><span class="fu">rainbow</span>(<span class="dv">3</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-758-1.png" width="672" /></p>
<p>The ordination reveals that 73% of variation is explained by PC1. The figure shows that the species fall out very cleanly along PC1, with is associated with petal morphology. Let’s use PC1 as a predictor for species in a logistic regression.</p>
<div class="sourceCode" id="cb1680"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1680-1"><a href="mod-08.html#cb1680-1" aria-hidden="true" tabindex="-1"></a>dat2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">y=</span>iris<span class="sc">$</span>Species, <span class="at">pc1=</span>px[,<span class="dv">1</span>])</span>
<span id="cb1680-2"><a href="mod-08.html#cb1680-2" aria-hidden="true" tabindex="-1"></a>dat2<span class="sc">$</span>z <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(dat2<span class="sc">$</span>y <span class="sc">==</span> <span class="st">&quot;virginica&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb1680-3"><a href="mod-08.html#cb1680-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1680-4"><a href="mod-08.html#cb1680-4" aria-hidden="true" tabindex="-1"></a>mod1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(z<span class="sc">~</span>pc1, <span class="at">data=</span>dat2, <span class="at">family=</span>binomial)</span>
<span id="cb1680-5"><a href="mod-08.html#cb1680-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod1)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = z ~ pc1, family = binomial, data = dat2)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.83252  -0.10909  -0.00016   0.10887   2.83405  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   -6.023      1.393  -4.323 1.54e-05 ***
## pc1           23.366      5.162   4.526 6.00e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 190.954  on 149  degrees of freedom
## Residual deviance:  50.108  on 148  degrees of freedom
## AIC: 54.108
## 
## Number of Fisher Scoring iterations: 9</code></pre>
<p>The logistic regression results suggest that for every unit increase in PC1, the odds ratio of a flower being <em>Iris virginica</em> increases by 23. That’s a very strong signal. Just for fun, below are the model predictions of probability of being <em>I</em>. <em>virginica</em> and the ROC curve. Both confirm visually what the coefficients table above suggested, that PC1 is a very reliable predictor of <em>Iris</em> species (at least in this dataset).</p>
<div class="sourceCode" id="cb1682"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1682-1"><a href="mod-08.html#cb1682-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb1682-2"><a href="mod-08.html#cb1682-2" aria-hidden="true" tabindex="-1"></a>prx <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">min</span>(dat2<span class="sc">$</span>pc1), <span class="fu">max</span>(dat2<span class="sc">$</span>pc1), <span class="at">length=</span>n)</span>
<span id="cb1682-3"><a href="mod-08.html#cb1682-3" aria-hidden="true" tabindex="-1"></a>dx <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">pc1=</span>prx)</span>
<span id="cb1682-4"><a href="mod-08.html#cb1682-4" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod1, <span class="at">newdata=</span><span class="fu">data.frame</span>(dx),</span>
<span id="cb1682-5"><a href="mod-08.html#cb1682-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">type=</span><span class="st">&quot;link&quot;</span>, <span class="at">se.fit=</span><span class="cn">TRUE</span>)</span>
<span id="cb1682-6"><a href="mod-08.html#cb1682-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1682-7"><a href="mod-08.html#cb1682-7" aria-hidden="true" tabindex="-1"></a>mn <span class="ot">&lt;-</span> <span class="fu">plogis</span>(pred<span class="sc">$</span>fit)</span>
<span id="cb1682-8"><a href="mod-08.html#cb1682-8" aria-hidden="true" tabindex="-1"></a>ll <span class="ot">&lt;-</span> <span class="fu">plogis</span>(<span class="fu">qnorm</span>(<span class="fl">0.025</span>, pred<span class="sc">$</span>fit, pred<span class="sc">$</span>se.fit))</span>
<span id="cb1682-9"><a href="mod-08.html#cb1682-9" aria-hidden="true" tabindex="-1"></a>uu <span class="ot">&lt;-</span> <span class="fu">plogis</span>(<span class="fu">qnorm</span>(<span class="fl">0.975</span>, pred<span class="sc">$</span>fit, pred<span class="sc">$</span>se.fit))</span>
<span id="cb1682-10"><a href="mod-08.html#cb1682-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1682-11"><a href="mod-08.html#cb1682-11" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">mar=</span><span class="fu">c</span>(<span class="fl">5.1</span>, <span class="fl">5.1</span>, <span class="fl">1.1</span>, <span class="fl">1.1</span>),</span>
<span id="cb1682-12"><a href="mod-08.html#cb1682-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">lend=</span><span class="dv">1</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">cex.axis=</span><span class="fl">1.3</span>, <span class="at">cex.lab=</span><span class="fl">1.3</span>,</span>
<span id="cb1682-13"><a href="mod-08.html#cb1682-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">bty=</span><span class="st">&quot;n&quot;</span>)</span>
<span id="cb1682-14"><a href="mod-08.html#cb1682-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prx, mn, <span class="at">type=</span><span class="st">&quot;n&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;PC1&quot;</span>,</span>
<span id="cb1682-15"><a href="mod-08.html#cb1682-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab=</span><span class="fu">expression</span>(<span class="fu">P</span>(<span class="fu">italic</span>(virginica))),</span>
<span id="cb1682-16"><a href="mod-08.html#cb1682-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.1</span>,<span class="fl">1.1</span>))</span>
<span id="cb1682-17"><a href="mod-08.html#cb1682-17" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(prx, ll, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb1682-18"><a href="mod-08.html#cb1682-18" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(prx, uu, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb1682-19"><a href="mod-08.html#cb1682-19" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(prx, mn, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb1682-20"><a href="mod-08.html#cb1682-20" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(dat2<span class="sc">$</span>pc1, <span class="fu">jitter</span>(dat2<span class="sc">$</span>z, <span class="at">amount=</span><span class="fl">0.05</span>), <span class="at">xpd=</span><span class="cn">NA</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-760-1.png" width="672" /></p>
<div class="sourceCode" id="cb1683"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1683-1"><a href="mod-08.html#cb1683-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span></code></pre></div>
<pre><code>## Type &#39;citation(&quot;pROC&quot;)&#39; for a citation.</code></pre>
<pre><code>## 
## Attaching package: &#39;pROC&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     cov, smooth, var</code></pre>
<div class="sourceCode" id="cb1687"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1687-1"><a href="mod-08.html#cb1687-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(mod1, <span class="at">type=</span><span class="st">&quot;response&quot;</span>)</span>
<span id="cb1687-2"><a href="mod-08.html#cb1687-2" aria-hidden="true" tabindex="-1"></a>roc1 <span class="ot">&lt;-</span> <span class="fu">roc</span>(dat2<span class="sc">$</span>z <span class="sc">~</span> p1, <span class="at">plot =</span> <span class="cn">TRUE</span>, <span class="at">print.auc =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## Setting levels: control = 0, case = 1</code></pre>
<pre><code>## Setting direction: controls &lt; cases</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-760-2.png" width="672" /></p>
<div class="sourceCode" id="cb1690"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1690-1"><a href="mod-08.html#cb1690-1" aria-hidden="true" tabindex="-1"></a>roc1</span></code></pre></div>
<pre><code>## 
## Call:
## roc.formula(formula = dat2$z ~ p1, plot = TRUE, print.auc = TRUE)
## 
## Data: p1 in 100 controls (dat2$z 0) &lt; 50 cases (dat2$z 1).
## Area under the curve: 0.9804</code></pre>
<p>Going the other way, modeling PC scores in response to predictor variables, is tricky but it can be done. Usually this is only acceptable when there is a <strong><em>clear</em></strong> relationship between the modeled PC and several of the original variables that went into the PCA. Treating a PC as a <em>dependent variable</em> is an elegant way to get around the problem of having multiple collinear response variables. Conversely, treating a PC as a predictor variable is a way of dealing with multiple collinear predictor variables. Axes from other ordination techniques can be used in this manner, but require <strong><em>careful</em></strong> biological and statistical justification as well as very cautious interpretation.</p>
</div>
</div>
<div id="nmds-and-other-ordination-methods" class="section level3" number="8.5.2">
<h3><span class="header-section-number">8.5.2</span> NMDS and other ordination methods</h3>
<p>PCA and many related techniques are based on linear algebra and eigenvalues. This is fine for datasets where variables are mostly linearly related to each other, or can be transformed to be linearly related. Most of the eigenvalue-based techniques also require data to be (mostly) multivariate normal distributed.</p>
<p>If relationships between variables are non-linear, or if the many other assumptions of eigenvalue-based ordination cannot be met, then the next best option is often a non-parametric ordination technique called <strong>nonmetric multidimensional scaling (NMDS or NMS)</strong>. Unlike PCA, which solves linear algebra problems to extract synthetic gradients (“principal components”), NMDS works by trying iteratively to <strong>arrange the samples into a reduced dimensional space</strong> that preserves the <strong>rank order</strong> of the distance matrix**.</p>
<div id="nmds-simple-explanation" class="section level4" number="8.5.2.1">
<h4><span class="header-section-number">8.5.2.1</span> NMDS simple explanation</h4>
<p>Let’s start with a simple example. Download the dataset <a href="https://greenquanteco.github.io/state_caps.csv">state_caps.csv</a>, put it in your R home directory, and load it into R. This dataset contains the latitudes and longitudes of the state capitals of the US. For simplicity, we will use only the lower 48 states.</p>
<div class="sourceCode" id="cb1692"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1692-1"><a href="mod-08.html#cb1692-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vegan)</span>
<span id="cb1692-2"><a href="mod-08.html#cb1692-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1692-3"><a href="mod-08.html#cb1692-3" aria-hidden="true" tabindex="-1"></a>in.name <span class="ot">&lt;-</span> <span class="st">&quot;state_caps.csv&quot;</span></span>
<span id="cb1692-4"><a href="mod-08.html#cb1692-4" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(in.name, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb1692-5"><a href="mod-08.html#cb1692-5" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> dat[<span class="fu">which</span>(<span class="sc">!</span>dat<span class="sc">$</span>state <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Alaska&quot;</span>, <span class="st">&quot;Hawaii&quot;</span>)),]</span>
<span id="cb1692-6"><a href="mod-08.html#cb1692-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1692-7"><a href="mod-08.html#cb1692-7" aria-hidden="true" tabindex="-1"></a><span class="co"># set rownames so the city names will carry through to the </span></span>
<span id="cb1692-8"><a href="mod-08.html#cb1692-8" aria-hidden="true" tabindex="-1"></a><span class="co"># distance matrix</span></span>
<span id="cb1692-9"><a href="mod-08.html#cb1692-9" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(dat) <span class="ot">&lt;-</span> dat<span class="sc">$</span>cap</span>
<span id="cb1692-10"><a href="mod-08.html#cb1692-10" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> dat[,<span class="fu">c</span>(<span class="st">&quot;long&quot;</span>, <span class="st">&quot;lat&quot;</span>)]</span></code></pre></div>
<p>Use function <code>vegdist()</code> in package <code>vegan</code> to calculate Euclidean distances between the cities<a href="literature-cited.html#fn78" class="footnote-ref" id="fnref78"><sup>78</sup></a>. Then print the object <code>d1</code> to the console and take a look (not shown).</p>
<div class="sourceCode" id="cb1693"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1693-1"><a href="mod-08.html#cb1693-1" aria-hidden="true" tabindex="-1"></a>d1 <span class="ot">&lt;-</span> <span class="fu">vegdist</span>(dat[,<span class="fu">c</span>(<span class="st">&quot;long&quot;</span>, <span class="st">&quot;lat&quot;</span>)], <span class="at">method=</span><span class="st">&quot;euclidean&quot;</span>)</span></code></pre></div>
<p>The distance matrix gives the distance between each pair of cities, identified by row labels.</p>
<p>If you plot latitude vs. longitude, you will get a reasonable map of the continental US (CONUS).</p>
<div class="sourceCode" id="cb1694"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1694-1"><a href="mod-08.html#cb1694-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(dat<span class="sc">$</span>long, dat<span class="sc">$</span>lat)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-763-1.png" width="768" /></p>
<p>Wouldn’t it be neat if we could recover the actual arrangement of capitals shown above just using their distance matrix? It turns out, we can, with NMDS. The main function for NMDS is <code>metaMDS()</code> in package <code>vegan</code>. NMDS involves random sampling, so set the random number seed for reproducibility.</p>
<div class="sourceCode" id="cb1695"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1695-1"><a href="mod-08.html#cb1695-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1695-2"><a href="mod-08.html#cb1695-2" aria-hidden="true" tabindex="-1"></a>n1 <span class="ot">&lt;-</span> <span class="fu">metaMDS</span>(dat, <span class="at">distance=</span><span class="st">&quot;euclidean&quot;</span>)</span></code></pre></div>
<pre><code>## &#39;comm&#39; has negative data: &#39;autotransform&#39;, &#39;noshare&#39; and &#39;wascores&#39; set to FALSE</code></pre>
<pre><code>## Run 0 stress 0 
## Run 1 stress 0.02824041 
## Run 2 stress 9.688201e-05 
## ... Procrustes: rmse 0.0003258308  max resid 0.0008680344 
## ... Similar to previous best
## Run 3 stress 9.741634e-05 
## ... Procrustes: rmse 0.0003391501  max resid 0.0009861631 
## ... Similar to previous best
## Run 4 stress 9.614493e-05 
## ... Procrustes: rmse 0.0003316108  max resid 0.00101616 
## ... Similar to previous best
## Run 5 stress 9.839223e-05 
## ... Procrustes: rmse 0.0003366584  max resid 0.001019179 
## ... Similar to previous best
## Run 6 stress 9.938774e-05 
## ... Procrustes: rmse 0.0003421181  max resid 0.001056077 
## ... Similar to previous best
## Run 7 stress 9.747501e-05 
## ... Procrustes: rmse 0.0003420786  max resid 0.001042044 
## ... Similar to previous best
## Run 8 stress 9.688222e-05 
## ... Procrustes: rmse 0.0003407193  max resid 0.001040716 
## ... Similar to previous best
## Run 9 stress 9.042907e-05 
## ... Procrustes: rmse 0.0003277819  max resid 0.0009954318 
## ... Similar to previous best
## Run 10 stress 9.585724e-05 
## ... Procrustes: rmse 0.0003388215  max resid 0.001045013 
## ... Similar to previous best
## Run 11 stress 9.623688e-05 
## ... Procrustes: rmse 0.0003381601  max resid 0.001029097 
## ... Similar to previous best
## Run 12 stress 0.04810304 
## Run 13 stress 9.271431e-05 
## ... Procrustes: rmse 0.0003274582  max resid 0.000996862 
## ... Similar to previous best
## Run 14 stress 9.821812e-05 
## ... Procrustes: rmse 0.0003434694  max resid 0.001046526 
## ... Similar to previous best
## Run 15 stress 9.886879e-05 
## ... Procrustes: rmse 0.000344009  max resid 0.001069766 
## ... Similar to previous best
## Run 16 stress 9.538052e-05 
## ... Procrustes: rmse 0.0003364742  max resid 0.001031398 
## ... Similar to previous best
## Run 17 stress 0.02824038 
## Run 18 stress 9.633286e-05 
## ... Procrustes: rmse 0.0003317048  max resid 0.000937519 
## ... Similar to previous best
## Run 19 stress 0.02824036 
## Run 20 stress 9.744164e-05 
## ... Procrustes: rmse 0.0003414834  max resid 0.001047844 
## ... Similar to previous best
## *** Solution reached</code></pre>
<pre><code>## Warning in metaMDS(dat, distance = &quot;euclidean&quot;): stress is (nearly) zero: you
## may have insufficient data</code></pre>
<div class="sourceCode" id="cb1699"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1699-1"><a href="mod-08.html#cb1699-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">scores</span>(n1))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-764-1.png" width="768" /></p>
<p>Notice anything odd? The <em>arrangement</em> of the cities, or relative positions, are mostly correct. However, the cities are flipped east to west! This is because NMDS only considers relative position, not absolute position. NMDS positions are arbitrary, so we can rotate or flip the axes to make better sense of them. We’ll flip the first axis (NMDS1) by multiplying it by -1.</p>
<div class="sourceCode" id="cb1700"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1700-1"><a href="mod-08.html#cb1700-1" aria-hidden="true" tabindex="-1"></a>sn <span class="ot">&lt;-</span> <span class="fu">scores</span>(n1)</span>
<span id="cb1700-2"><a href="mod-08.html#cb1700-2" aria-hidden="true" tabindex="-1"></a>sn[,<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">*</span>sn[,<span class="dv">1</span>]</span>
<span id="cb1700-3"><a href="mod-08.html#cb1700-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(sn)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-765-1.png" width="768" /></p>
<p>Much better. The coordinates aren’t quite the same as the original data, but the relative positions of the cities are correct. We can confirm this with a stress plot.</p>
<div class="sourceCode" id="cb1701"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1701-1"><a href="mod-08.html#cb1701-1" aria-hidden="true" tabindex="-1"></a><span class="fu">stressplot</span>(n1)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-766-1.png" width="576" /></p>
<p>This chart shows that the distances between points in the NMDS space (Ordination Distance) are nearly identical to the distances between points in the original data space (Observed Dissimilarity). A good NMDS fit will have nearly all of the points on the red line of equality.</p>
</div>
<div id="nmds-more-complicated-explanation" class="section level4" number="8.5.2.2">
<h4><span class="header-section-number">8.5.2.2</span> NMDS more complicated explanation</h4>
<p>Like PCA, NMDS is a technique for reducing the dimensionality of data. The general approach of NMDS is to start with a cloud of <em>n</em> samples (points) in <em>p</em> dimensions (variables), and try to position the points into &lt;<em>p</em> dimensions in a way that preserves the relative distances between the points. Consider the example below, which shows a 3-d dataset with variables <em>X</em>, <em>Y</em>, and <em>Z</em>.</p>
<div class="sourceCode" id="cb1702"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1702-1"><a href="mod-08.html#cb1702-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1702-2"><a href="mod-08.html#cb1702-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">36</span></span>
<span id="cb1702-3"><a href="mod-08.html#cb1702-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="dv">1</span>, <span class="dv">10</span>)</span>
<span id="cb1702-4"><a href="mod-08.html#cb1702-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="dv">1</span>, <span class="dv">3</span>)</span>
<span id="cb1702-5"><a href="mod-08.html#cb1702-5" aria-hidden="true" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="dv">1</span>, <span class="dv">10</span>)</span></code></pre></div>
<p>The code below was not run for this tutorial, but a screenshot of the result is shown below.</p>
<div class="sourceCode" id="cb1703"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1703-1"><a href="mod-08.html#cb1703-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rgl)</span>
<span id="cb1703-2"><a href="mod-08.html#cb1703-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb1703-3"><a href="mod-08.html#cb1703-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot3d</span>(x, y, z,</span>
<span id="cb1703-4"><a href="mod-08.html#cb1703-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;X&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Y&quot;</span>, <span class="at">zlab=</span><span class="st">&quot;Z&quot;</span>,</span>
<span id="cb1703-5"><a href="mod-08.html#cb1703-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">10</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">10</span>), <span class="at">zlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">10</span>))</span></code></pre></div>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_16.jpg" /></p>
<p>Or more prosaically:</p>
<div class="sourceCode" id="cb1704"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1704-1"><a href="mod-08.html#cb1704-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb1704-2"><a href="mod-08.html#cb1704-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>))</span>
<span id="cb1704-3"><a href="mod-08.html#cb1704-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, z, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>))</span>
<span id="cb1704-4"><a href="mod-08.html#cb1704-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(y,z, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-769-1.png" width="864" /></p>
<p>The scatterplots suggest that most of the variation is tied up in <em>X</em> and <em>Z</em>, with very little in <em>Y</em>. If we wanted to present the data in two dimensions, we could use NMDS to arrange the points in a 2-d space that preserves the relative distances. Data can be passed directly to <code>metaMDS()</code>, in which case it will calculate the distance matrix for you. Alternatively, you can supply a distance matrix. The function will figure out what to do based on what your input.</p>
<p>As always, set the random number seed for reproducibility.</p>
<div class="sourceCode" id="cb1705"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1705-1"><a href="mod-08.html#cb1705-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb1705-2"><a href="mod-08.html#cb1705-2" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">cbind</span>(x,y,z)</span>
<span id="cb1705-3"><a href="mod-08.html#cb1705-3" aria-hidden="true" tabindex="-1"></a>n2 <span class="ot">&lt;-</span> <span class="fu">metaMDS</span>(dat)</span></code></pre></div>
<pre><code>## Wisconsin double standardization
## Run 0 stress 0.02846602 
## Run 1 stress 0.02846602 
## ... Procrustes: rmse 4.316137e-06  max resid 1.726271e-05 
## ... Similar to previous best
## Run 2 stress 0.02846602 
## ... Procrustes: rmse 1.118155e-05  max resid 4.018889e-05 
## ... Similar to previous best
## Run 3 stress 0.02846602 
## ... New best solution
## ... Procrustes: rmse 6.792159e-06  max resid 2.56478e-05 
## ... Similar to previous best
## Run 4 stress 0.02846602 
## ... Procrustes: rmse 7.699264e-06  max resid 2.638313e-05 
## ... Similar to previous best
## Run 5 stress 0.02846602 
## ... Procrustes: rmse 9.363497e-06  max resid 3.897864e-05 
## ... Similar to previous best
## Run 6 stress 0.02846602 
## ... New best solution
## ... Procrustes: rmse 2.322942e-06  max resid 7.365495e-06 
## ... Similar to previous best
## Run 7 stress 0.02846602 
## ... Procrustes: rmse 3.750166e-06  max resid 1.250864e-05 
## ... Similar to previous best
## Run 8 stress 0.02846602 
## ... Procrustes: rmse 6.108855e-06  max resid 2.128185e-05 
## ... Similar to previous best
## Run 9 stress 0.02846602 
## ... Procrustes: rmse 4.354076e-06  max resid 1.548638e-05 
## ... Similar to previous best
## Run 10 stress 0.02846602 
## ... Procrustes: rmse 1.755597e-06  max resid 5.736735e-06 
## ... Similar to previous best
## Run 11 stress 0.02846602 
## ... Procrustes: rmse 5.436306e-06  max resid 2.010142e-05 
## ... Similar to previous best
## Run 12 stress 0.02846602 
## ... Procrustes: rmse 1.012847e-06  max resid 3.324696e-06 
## ... Similar to previous best
## Run 13 stress 0.02846602 
## ... Procrustes: rmse 4.858257e-06  max resid 1.845511e-05 
## ... Similar to previous best
## Run 14 stress 0.11564 
## Run 15 stress 0.11564 
## Run 16 stress 0.02846602 
## ... Procrustes: rmse 3.74378e-06  max resid 1.643431e-05 
## ... Similar to previous best
## Run 17 stress 0.02846602 
## ... Procrustes: rmse 3.719871e-06  max resid 1.260728e-05 
## ... Similar to previous best
## Run 18 stress 0.02846602 
## ... Procrustes: rmse 5.596345e-06  max resid 2.38461e-05 
## ... Similar to previous best
## Run 19 stress 0.11564 
## Run 20 stress 0.11564 
## *** Solution reached</code></pre>
<div class="sourceCode" id="cb1707"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1707-1"><a href="mod-08.html#cb1707-1" aria-hidden="true" tabindex="-1"></a>n2</span></code></pre></div>
<pre><code>## 
## Call:
## metaMDS(comm = dat) 
## 
## global Multidimensional Scaling using monoMDS
## 
## Data:     wisconsin(dat) 
## Distance: bray 
## 
## Dimensions: 2 
## Stress:     0.02846602 
## Stress type 1, weak ties
## Two convergent solutions found after 20 tries
## Scaling: centring, PC rotation, halfchange scaling 
## Species: expanded scores based on &#39;wisconsin(dat)&#39;</code></pre>
<p>The output tells us a lot about the fit. We got a 2-d fit (the default), used the Bray-Curtis distance metric (the default), and variables were centered, scaled, and rotated (also default). The rotation referred to here means that the final arrangement of points was rotated so that NMDS axis 1 captured as much variation as possible (aka: “varimax” rotation; <span class="citation">McCune et al. (<a href="#ref-mccune2002analysis" role="doc-biblioref">2002</a>)</span>).</p>
<p>The <strong>stress</strong> expresses how well the NMDS represented the <strong>rank order of the distance matrix</strong>. Lower stress indicates a more faithful representation. Stress increases as distances between samples are increased or decreased relative to the same distances in the original, full-dimensional space. If you picture the full-dimensional distances as ropes connecting the samples, and the amount of stretching or coiling of the ropes that happens as the samples are squashed into lower-dimensional space as the stress, then you pretty much have the idea.</p>
<p>There is no hard and fast rule, but in practice stress values should be &gt;0 and &lt;0.2. Some authors suggest that NMDS fits with stress <span class="math inline">\(\ge\)</span> 0.2 are suspect and should not be interpreted; other authors use 0.1 as the cutoff. Some authors and software packages scale stress by 100, so the cutoff becomes 20 or 10 instead of 0.2 or 0.1 <span class="citation">(<a href="#ref-mccune2002analysis" role="doc-biblioref">McCune et al. 2002</a>)</span>. Like <em>P</em>-values, stress values are a heuristic for inference and so you should not get too hung up on them. The stress plot and the screeplot are arguably more meaningful evaluations of your NMDS fit.</p>
<p>The stressplot below shows that the NMDS did a very good job representing the distance matrix in the reduced space, because the points are clustered near the line and the <em>R</em><sup>2</sup> values very high.</p>
<div class="sourceCode" id="cb1709"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1709-1"><a href="mod-08.html#cb1709-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb1709-2"><a href="mod-08.html#cb1709-2" aria-hidden="true" tabindex="-1"></a><span class="fu">stressplot</span>(n2)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-771-1.png" width="576" /></p>
<p>The <strong>screeplot</strong> shows how the stress of the ordination changes as more dimensions are added. An NMDS ordination with the same number of dimensions as the original data would have stress 0. Generally, adding dimensions decreases stress, but there is usually a point of diminishing returns.</p>
<p>For the example below, I added a few more dimensions to the dataset <code>dat</code> with no information so that a better screeplot could be constructed. You don’t need to do this to your own data—the only reason it’s being done here is because our dataset only had 3 dimensions to start with. With your data, you should fit NMDS ordinations with more dimensions than you think you need, to see how stress decreases with dimensionality.</p>
<div class="sourceCode" id="cb1710"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1710-1"><a href="mod-08.html#cb1710-1" aria-hidden="true" tabindex="-1"></a><span class="co"># extra dimensions with random numbers (no information)</span></span>
<span id="cb1710-2"><a href="mod-08.html#cb1710-2" aria-hidden="true" tabindex="-1"></a>ext <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(n<span class="sc">*</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="fl">0.1</span>), <span class="at">nrow=</span>n, <span class="at">ncol=</span><span class="dv">2</span>)</span>
<span id="cb1710-3"><a href="mod-08.html#cb1710-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1710-4"><a href="mod-08.html#cb1710-4" aria-hidden="true" tabindex="-1"></a><span class="co"># combine with original data</span></span>
<span id="cb1710-5"><a href="mod-08.html#cb1710-5" aria-hidden="true" tabindex="-1"></a>dat2 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(dat, ext)</span>
<span id="cb1710-6"><a href="mod-08.html#cb1710-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1710-7"><a href="mod-08.html#cb1710-7" aria-hidden="true" tabindex="-1"></a><span class="co"># fit NMDS ordinations in a loop</span></span>
<span id="cb1710-8"><a href="mod-08.html#cb1710-8" aria-hidden="true" tabindex="-1"></a><span class="co"># for each element of nlist, k = number of dimensions</span></span>
<span id="cb1710-9"><a href="mod-08.html#cb1710-9" aria-hidden="true" tabindex="-1"></a>nlist <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="fu">ncol</span>(dat2))</span>
<span id="cb1710-10"><a href="mod-08.html#cb1710-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(nlist)){</span>
<span id="cb1710-11"><a href="mod-08.html#cb1710-11" aria-hidden="true" tabindex="-1"></a>    nlist[[i]] <span class="ot">&lt;-</span> <span class="fu">metaMDS</span>(dat2, <span class="at">distance=</span><span class="st">&quot;euclidean&quot;</span>, <span class="at">k=</span>i)</span>
<span id="cb1710-12"><a href="mod-08.html#cb1710-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1710-13"><a href="mod-08.html#cb1710-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1710-14"><a href="mod-08.html#cb1710-14" aria-hidden="true" tabindex="-1"></a><span class="co"># extract stress values for each NMDS fit</span></span>
<span id="cb1710-15"><a href="mod-08.html#cb1710-15" aria-hidden="true" tabindex="-1"></a>strs <span class="ot">&lt;-</span> <span class="fu">sapply</span>(nlist, <span class="cf">function</span>(x){x<span class="sc">$</span>stress})</span></code></pre></div>
<div class="sourceCode" id="cb1711"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1711-1"><a href="mod-08.html#cb1711-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fancy plot</span></span>
<span id="cb1711-2"><a href="mod-08.html#cb1711-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">cex.lab=</span><span class="fl">1.2</span>, <span class="at">cex.axis=</span><span class="fl">1.2</span>) </span>
<span id="cb1711-3"><a href="mod-08.html#cb1711-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(nlist), strs, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>,</span>
<span id="cb1711-4"><a href="mod-08.html#cb1711-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;Dimensions in NMDS&quot;</span>,</span>
<span id="cb1711-5"><a href="mod-08.html#cb1711-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab=</span><span class="st">&quot;Stress&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-773-1.png" width="672" /></p>
<p>The screeplot shows that the stress decreases much more when going from 1 to 2 dimensions than it does for going from 2 to 3 dimensions. Stress becomes negligible for <span class="math inline">\(\ge\)</span> 3 dimensions, because the original data had 3 dimensions and the two additional dimensions had almost 0 variance. The bend in the curve at <em>k</em> = 2 indicates that 2 is probably the optimal number of dimensions. If you’re not sure how many dimensions to use, examine biplots for both <em>k</em> and try to determine which plot is more interpretable biologically.</p>
<p>We can plot the scores of the samples much in the same way as we did the PCA scores in the previous example. We can also produce a biplot that works much the same way as the PCA biplot. We’ll explore those methods in the next section.</p>
</div>
<div id="nmds-real-data-example" class="section level4" number="8.5.2.3">
<h4><span class="header-section-number">8.5.2.3</span> NMDS real data example</h4>
<p>Load the <code>dune</code> dataset that comes with package <code>vegan</code>. This dataset contains cover class values for 30 species of plants on 20 dune meadow sites in the Netherlands. We’ll also load <code>dune.env</code>, the environmental data that describe each site.</p>
<div class="sourceCode" id="cb1712"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1712-1"><a href="mod-08.html#cb1712-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vegan)</span>
<span id="cb1712-2"><a href="mod-08.html#cb1712-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(dune)</span>
<span id="cb1712-3"><a href="mod-08.html#cb1712-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(dune.env)</span>
<span id="cb1712-4"><a href="mod-08.html#cb1712-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1712-5"><a href="mod-08.html#cb1712-5" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> dune</span>
<span id="cb1712-6"><a href="mod-08.html#cb1712-6" aria-hidden="true" tabindex="-1"></a>env <span class="ot">&lt;-</span> dune.env</span></code></pre></div>
<p>If we are interested in in plant diversity among the sites, we could use multivariate methods to describe variation in plant cover. First, make some histograms of the cover of each plant species.</p>
<div class="sourceCode" id="cb1713"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1713-1"><a href="mod-08.html#cb1713-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">6</span>), <span class="at">mar=</span><span class="fu">c</span>(<span class="fl">4.1</span>, <span class="fl">4.1</span>, <span class="fl">1.1</span>, <span class="fl">1.1</span>))</span>
<span id="cb1713-2"><a href="mod-08.html#cb1713-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">ncol</span>(dat)){<span class="fu">hist</span>(dat[,i], <span class="at">main=</span><span class="st">&quot;&quot;</span>)}</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-775-1.png" width="1344" /></p>
<p>The cover of most species is clearly non-normal. This means that PCA would be difficult to fit. What’s more, the response variable (canopy cover class) isn’t really quantitative. Instead, it is ordinal. For example, category 2 represents greater proportion of plant cover than category 1, but it’s not clear how much more. So, an analysis based on rank order might make more sense than one based on actual values. That suggests using NMDS instead of PCA. Use <code>vegan::metaMDS()</code> to fit the NMDS, using the default Bray-Curtis distance metric.</p>
<div class="sourceCode" id="cb1714"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1714-1"><a href="mod-08.html#cb1714-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">456</span>)</span>
<span id="cb1714-2"><a href="mod-08.html#cb1714-2" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">metaMDS</span>(dat)</span></code></pre></div>
<pre><code>## Run 0 stress 0.1192678 
## Run 1 stress 0.1183186 
## ... New best solution
## ... Procrustes: rmse 0.02027121  max resid 0.06496598 
## Run 2 stress 0.1900911 
## Run 3 stress 0.1192679 
## Run 4 stress 0.19015 
## Run 5 stress 0.1192678 
## Run 6 stress 0.1183186 
## ... New best solution
## ... Procrustes: rmse 9.438674e-06  max resid 3.090521e-05 
## ... Similar to previous best
## Run 7 stress 0.1183186 
## ... Procrustes: rmse 2.811111e-06  max resid 7.842694e-06 
## ... Similar to previous best
## Run 8 stress 0.1192679 
## Run 9 stress 0.1192678 
## Run 10 stress 0.1192678 
## Run 11 stress 0.1812933 
## Run 12 stress 0.1889647 
## Run 13 stress 0.1192679 
## Run 14 stress 0.1192678 
## Run 15 stress 0.1183186 
## ... Procrustes: rmse 1.256982e-05  max resid 3.657271e-05 
## ... Similar to previous best
## Run 16 stress 0.1192679 
## Run 17 stress 0.1192678 
## Run 18 stress 0.1192678 
## Run 19 stress 0.1192678 
## Run 20 stress 0.192224 
## *** Solution reached</code></pre>
<div class="sourceCode" id="cb1716"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1716-1"><a href="mod-08.html#cb1716-1" aria-hidden="true" tabindex="-1"></a>p1</span></code></pre></div>
<pre><code>## 
## Call:
## metaMDS(comm = dat) 
## 
## global Multidimensional Scaling using monoMDS
## 
## Data:     dat 
## Distance: bray 
## 
## Dimensions: 2 
## Stress:     0.1183186 
## Stress type 1, weak ties
## Two convergent solutions found after 20 tries
## Scaling: centring, PC rotation, halfchange scaling 
## Species: expanded scores based on &#39;dat&#39;</code></pre>
<p>The NMDS fit has stress = 0.118, which is not too bad. Let’s take a look at the ordination.</p>
<div class="sourceCode" id="cb1718"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1718-1"><a href="mod-08.html#cb1718-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p1)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-777-1.png" width="672" /></p>
<p>The default NMDS biplot is not very informative, so lets’ build the plot manually. While we’re at it, let’s use the environmental dataset to assign some category labels.</p>
<div class="sourceCode" id="cb1719"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1719-1"><a href="mod-08.html#cb1719-1" aria-hidden="true" tabindex="-1"></a><span class="co"># management regimes</span></span>
<span id="cb1719-2"><a href="mod-08.html#cb1719-2" aria-hidden="true" tabindex="-1"></a>mans <span class="ot">&lt;-</span> <span class="fu">sort</span>(<span class="fu">unique</span>(env<span class="sc">$</span>Management))</span>
<span id="cb1719-3"><a href="mod-08.html#cb1719-3" aria-hidden="true" tabindex="-1"></a>nman <span class="ot">&lt;-</span> <span class="fu">length</span>(mans)</span>
<span id="cb1719-4"><a href="mod-08.html#cb1719-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1719-5"><a href="mod-08.html#cb1719-5" aria-hidden="true" tabindex="-1"></a><span class="co"># land uses</span></span>
<span id="cb1719-6"><a href="mod-08.html#cb1719-6" aria-hidden="true" tabindex="-1"></a>uses <span class="ot">&lt;-</span> <span class="fu">sort</span>(<span class="fu">unique</span>(env<span class="sc">$</span>Use))</span>
<span id="cb1719-7"><a href="mod-08.html#cb1719-7" aria-hidden="true" tabindex="-1"></a>nuse <span class="ot">&lt;-</span> <span class="fu">length</span>(uses)</span>
<span id="cb1719-8"><a href="mod-08.html#cb1719-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1719-9"><a href="mod-08.html#cb1719-9" aria-hidden="true" tabindex="-1"></a><span class="co"># colors and symbols</span></span>
<span id="cb1719-10"><a href="mod-08.html#cb1719-10" aria-hidden="true" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;purple&quot;</span>, <span class="st">&quot;red&quot;</span>)</span>
<span id="cb1719-11"><a href="mod-08.html#cb1719-11" aria-hidden="true" tabindex="-1"></a>pchs <span class="ot">&lt;-</span> <span class="dv">15</span><span class="sc">:</span><span class="dv">18</span></span>
<span id="cb1719-12"><a href="mod-08.html#cb1719-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1719-13"><a href="mod-08.html#cb1719-13" aria-hidden="true" tabindex="-1"></a>env<span class="sc">$</span>col <span class="ot">&lt;-</span> cols[<span class="fu">match</span>(env<span class="sc">$</span>Use, uses)]</span>
<span id="cb1719-14"><a href="mod-08.html#cb1719-14" aria-hidden="true" tabindex="-1"></a>env<span class="sc">$</span>pch <span class="ot">&lt;-</span> pchs[<span class="fu">match</span>(env<span class="sc">$</span>Management, mans)]</span>
<span id="cb1719-15"><a href="mod-08.html#cb1719-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1719-16"><a href="mod-08.html#cb1719-16" aria-hidden="true" tabindex="-1"></a><span class="co"># get site and species scores</span></span>
<span id="cb1719-17"><a href="mod-08.html#cb1719-17" aria-hidden="true" tabindex="-1"></a>px <span class="ot">&lt;-</span> <span class="fu">scores</span>(p1)</span>
<span id="cb1719-18"><a href="mod-08.html#cb1719-18" aria-hidden="true" tabindex="-1"></a>vx <span class="ot">&lt;-</span> <span class="fu">scores</span>(p1, <span class="at">display=</span><span class="st">&quot;species&quot;</span>)</span>
<span id="cb1719-19"><a href="mod-08.html#cb1719-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1719-20"><a href="mod-08.html#cb1719-20" aria-hidden="true" tabindex="-1"></a><span class="co"># fancy plot</span></span>
<span id="cb1719-21"><a href="mod-08.html#cb1719-21" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">mar=</span><span class="fu">c</span>(<span class="fl">5.1</span>, <span class="fl">5.1</span>, <span class="fl">1.1</span>, <span class="fl">1.1</span>), </span>
<span id="cb1719-22"><a href="mod-08.html#cb1719-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">bty=</span><span class="st">&quot;n&quot;</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">lend=</span><span class="dv">1</span>,</span>
<span id="cb1719-23"><a href="mod-08.html#cb1719-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">cex.axis=</span><span class="fl">1.3</span>, <span class="at">cex.lab=</span><span class="fl">1.3</span>)</span>
<span id="cb1719-24"><a href="mod-08.html#cb1719-24" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(px, <span class="at">pch=</span>env<span class="sc">$</span>pch, <span class="at">col=</span>env<span class="sc">$</span>col, <span class="at">cex=</span><span class="fl">1.3</span>,</span>
<span id="cb1719-25"><a href="mod-08.html#cb1719-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>))</span>
<span id="cb1719-26"><a href="mod-08.html#cb1719-26" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">0</span>, <span class="dv">0</span>, vx[,<span class="dv">1</span>], vx[,<span class="dv">2</span>])</span>
<span id="cb1719-27"><a href="mod-08.html#cb1719-27" aria-hidden="true" tabindex="-1"></a>mult <span class="ot">&lt;-</span> <span class="fl">1.1</span></span>
<span id="cb1719-28"><a href="mod-08.html#cb1719-28" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(mult<span class="sc">*</span>vx[,<span class="dv">1</span>], mult<span class="sc">*</span>vx[,<span class="dv">2</span>], <span class="fu">rownames</span>(vx))</span>
<span id="cb1719-29"><a href="mod-08.html#cb1719-29" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="at">legend=</span>mans, <span class="at">pch=</span>pchs, <span class="at">cex=</span><span class="fl">1.3</span>)</span>
<span id="cb1719-30"><a href="mod-08.html#cb1719-30" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomleft&quot;</span>, <span class="at">legend=</span>uses, <span class="at">col=</span>cols, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">cex=</span><span class="fl">1.3</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-778-1.png" width="768" /></p>
<p>There’s a lot of information in that figure, so let’s break it down:</p>
<ul>
<li>Points show samples (sites).</li>
<li>Proximity of two points reflects their dissimilarity in terms of the plant variables (closer = more similar).</li>
<li>Point color encodes land use (hayfield, pasture, or both).</li>
<li>Point shape encodes land management: BF (Biological farming), HF (Hobby farming), NM (Nature Conservation Management), and SF (Standard Farming).</li>
<li>Vectors show how the species are associated with the ordination space. Species cover increases in the direction of the vector. For example, species “Juncarti” increases to the right and decreases to the left.</li>
<li>Magnitude of each vector indicates the strength of the association. Vectors that are parallel to one of the NMDS axes are particularly interesting because they describe important gradients among the sites.</li>
</ul>
<p>The figure is a bit of a mess, so we should try some different representations to help us make sense of it.
Code one factor at a time:</p>
<div class="sourceCode" id="cb1720"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1720-1"><a href="mod-08.html#cb1720-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb1720-2"><a href="mod-08.html#cb1720-2" aria-hidden="true" tabindex="-1"></a>cols1 <span class="ot">&lt;-</span> <span class="fu">rainbow</span>(nuse)</span>
<span id="cb1720-3"><a href="mod-08.html#cb1720-3" aria-hidden="true" tabindex="-1"></a>cols1x <span class="ot">&lt;-</span> cols1[<span class="fu">match</span>(env<span class="sc">$</span>Use, uses)]</span>
<span id="cb1720-4"><a href="mod-08.html#cb1720-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(px, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>cols1x, <span class="at">cex=</span><span class="fl">1.3</span>,</span>
<span id="cb1720-5"><a href="mod-08.html#cb1720-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>))</span>
<span id="cb1720-6"><a href="mod-08.html#cb1720-6" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="at">legend=</span>uses,</span>
<span id="cb1720-7"><a href="mod-08.html#cb1720-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>cols1, <span class="at">cex=</span><span class="fl">1.3</span>)</span>
<span id="cb1720-8"><a href="mod-08.html#cb1720-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1720-9"><a href="mod-08.html#cb1720-9" aria-hidden="true" tabindex="-1"></a>cols2 <span class="ot">&lt;-</span> <span class="fu">rainbow</span>(nman)</span>
<span id="cb1720-10"><a href="mod-08.html#cb1720-10" aria-hidden="true" tabindex="-1"></a>cols2x <span class="ot">&lt;-</span> cols2[<span class="fu">match</span>(env<span class="sc">$</span>Management, mans)]</span>
<span id="cb1720-11"><a href="mod-08.html#cb1720-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1720-12"><a href="mod-08.html#cb1720-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(px, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>cols2x, <span class="at">cex=</span><span class="fl">1.3</span>,</span>
<span id="cb1720-13"><a href="mod-08.html#cb1720-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>))</span>
<span id="cb1720-14"><a href="mod-08.html#cb1720-14" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="at">legend=</span>mans,</span>
<span id="cb1720-15"><a href="mod-08.html#cb1720-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>cols2, <span class="at">cex=</span><span class="fl">1.3</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-779-1.png" width="960" /></p>
<p>When only one factor is plotted, it’s a little easier to see the potential grouping by management style in the right panel. Styles SF, HF, and NM fall out mostly along NMDS2, but BF does not separate cleanly from the others. Let’s investigate the differences related to management styles.</p>
<p>We can add ellipses to help illustrate group centers (aka: “centroids”, or average positions in NMDS space) and the 95% CI of the centroids.</p>
<div class="sourceCode" id="cb1721"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1721-1"><a href="mod-08.html#cb1721-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define some colors</span></span>
<span id="cb1721-2"><a href="mod-08.html#cb1721-2" aria-hidden="true" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">rainbow</span>(nman)</span>
<span id="cb1721-3"><a href="mod-08.html#cb1721-3" aria-hidden="true" tabindex="-1"></a>colsx <span class="ot">&lt;-</span> cols2[<span class="fu">match</span>(env<span class="sc">$</span>Management, mans)]</span>
<span id="cb1721-4"><a href="mod-08.html#cb1721-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1721-5"><a href="mod-08.html#cb1721-5" aria-hidden="true" tabindex="-1"></a><span class="co"># make plot</span></span>
<span id="cb1721-6"><a href="mod-08.html#cb1721-6" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb1721-7"><a href="mod-08.html#cb1721-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(px, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>colsx, <span class="at">cex=</span><span class="fl">1.3</span>,</span>
<span id="cb1721-8"><a href="mod-08.html#cb1721-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>))</span>
<span id="cb1721-9"><a href="mod-08.html#cb1721-9" aria-hidden="true" tabindex="-1"></a><span class="co"># add ellipse</span></span>
<span id="cb1721-10"><a href="mod-08.html#cb1721-10" aria-hidden="true" tabindex="-1"></a><span class="fu">ordiellipse</span>(p1, env<span class="sc">$</span>Management, </span>
<span id="cb1721-11"><a href="mod-08.html#cb1721-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">kind=</span><span class="st">&quot;se&quot;</span>, <span class="at">conf=</span><span class="fl">0.95</span>,</span>
<span id="cb1721-12"><a href="mod-08.html#cb1721-12" aria-hidden="true" tabindex="-1"></a>            <span class="at">draw=</span><span class="st">&quot;polygon&quot;</span>, <span class="at">col=</span>cols, <span class="at">border=</span><span class="cn">NA</span>)</span>
<span id="cb1721-13"><a href="mod-08.html#cb1721-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1721-14"><a href="mod-08.html#cb1721-14" aria-hidden="true" tabindex="-1"></a><span class="co"># plot group labels with white box behind at centroids</span></span>
<span id="cb1721-15"><a href="mod-08.html#cb1721-15" aria-hidden="true" tabindex="-1"></a>centx <span class="ot">&lt;-</span> <span class="fu">aggregate</span>(p1<span class="sc">$</span>points[,<span class="dv">1</span>],</span>
<span id="cb1721-16"><a href="mod-08.html#cb1721-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">by=</span><span class="fu">list</span>(env<span class="sc">$</span>Management), <span class="at">FUN=</span>mean)<span class="sc">$</span>x</span>
<span id="cb1721-17"><a href="mod-08.html#cb1721-17" aria-hidden="true" tabindex="-1"></a>centy <span class="ot">&lt;-</span> <span class="fu">aggregate</span>(p1<span class="sc">$</span>points[,<span class="dv">2</span>],</span>
<span id="cb1721-18"><a href="mod-08.html#cb1721-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">by=</span><span class="fu">list</span>(env<span class="sc">$</span>Management), <span class="at">FUN=</span>mean)<span class="sc">$</span>x</span>
<span id="cb1721-19"><a href="mod-08.html#cb1721-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1721-20"><a href="mod-08.html#cb1721-20" aria-hidden="true" tabindex="-1"></a>box.len <span class="ot">&lt;-</span> <span class="fl">0.1</span> <span class="co"># fiddle with this to get boxes right size</span></span>
<span id="cb1721-21"><a href="mod-08.html#cb1721-21" aria-hidden="true" tabindex="-1"></a><span class="fu">rect</span>(centx<span class="sc">-</span>box.len, centy<span class="sc">-</span>box.len,</span>
<span id="cb1721-22"><a href="mod-08.html#cb1721-22" aria-hidden="true" tabindex="-1"></a>    centx<span class="sc">+</span>box.len, centy<span class="sc">+</span>box.len, </span>
<span id="cb1721-23"><a href="mod-08.html#cb1721-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span><span class="st">&quot;white&quot;</span>, <span class="at">border=</span><span class="st">&quot;black&quot;</span>)</span>
<span id="cb1721-24"><a href="mod-08.html#cb1721-24" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(centx, centy, mans, <span class="at">cex=</span><span class="fl">1.3</span>,</span>
<span id="cb1721-25"><a href="mod-08.html#cb1721-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">col=</span>cols, <span class="at">font=</span><span class="dv">2</span>, <span class="at">adj=</span><span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.45</span>))</span>
<span id="cb1721-26"><a href="mod-08.html#cb1721-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1721-27"><a href="mod-08.html#cb1721-27" aria-hidden="true" tabindex="-1"></a><span class="co"># add points again to make sure they show up</span></span>
<span id="cb1721-28"><a href="mod-08.html#cb1721-28" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(px, <span class="at">pch=</span><span class="dv">21</span>, <span class="at">bg=</span>colsx, <span class="at">fg=</span><span class="st">&quot;black&quot;</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">cex=</span><span class="fl">1.4</span>)</span>
<span id="cb1721-29"><a href="mod-08.html#cb1721-29" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="at">legend=</span>mans,</span>
<span id="cb1721-30"><a href="mod-08.html#cb1721-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">pch=</span><span class="dv">21</span>, <span class="at">pt.bg=</span>cols, <span class="at">col=</span><span class="st">&quot;black&quot;</span>, <span class="at">pt.lwd=</span><span class="dv">2</span>, <span class="at">cex=</span><span class="fl">1.3</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-780-1.png" width="672" /></p>
<p>The default colors produced by <code>rainbow()</code> can be horrendous, but you get the idea. There are better ways to get color palettes that you can explore. The figure shows that it is quite likely that at least some of the management groups differ from each other in terms of their plant cover. We can test this directly with MRPP.</p>
<div class="sourceCode" id="cb1722"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1722-1"><a href="mod-08.html#cb1722-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mrpp</span>(px, env<span class="sc">$</span>Management)</span></code></pre></div>
<pre><code>## 
## Call:
## mrpp(dat = px, grouping = env$Management) 
## 
## Dissimilarity index: euclidean 
## Weights for groups:  n 
## 
## Class means and counts:
## 
##       BF     HF     NM    SF    
## delta 0.5279 0.5845 1.055 0.8339
## n     3      5      6     6     
## 
## Chance corrected within-group agreement A: 0.2216 
## Based on observed delta 0.792 and expected delta 1.017 
## 
## Significance of delta: 0.004 
## Permutation: free
## Number of permutations: 999</code></pre>
<p>The MRPP shows significant separation between the management groups, but the relatively low <em>A</em> indicates that there is still a lot of the positioning left unexplained.</p>
<p>We can also use NMDS to test for relationships between the NMDS coordinates and continuous variables using <code>envfit()</code> (from the <code>vegan</code> package). Note that only columns 1, 2, and 5 are used in the routine because those are the columns that contain quantitative (or ordinal) potential predictors.</p>
<div class="sourceCode" id="cb1724"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1724-1"><a href="mod-08.html#cb1724-1" aria-hidden="true" tabindex="-1"></a>ef <span class="ot">&lt;-</span> <span class="fu">envfit</span>(p1, env[,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">5</span>)])</span>
<span id="cb1724-2"><a href="mod-08.html#cb1724-2" aria-hidden="true" tabindex="-1"></a>ef</span></code></pre></div>
<pre><code>## 
## ***VECTORS
## 
##      NMDS1   NMDS2     r2 Pr(&gt;r)  
## A1 0.96474 0.26322 0.3649  0.014 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## Permutation: free
## Number of permutations: 999
## 
## ***FACTORS:
## 
## Centroids:
##             NMDS1   NMDS2
## Moisture1 -0.5101 -0.0403
## Moisture2 -0.3938  0.0139
## Moisture4  0.2765 -0.4033
## Moisture5  0.6561  0.1476
## Manure0    0.2958  0.5790
## Manure1   -0.2482 -0.0215
## Manure2   -0.3079 -0.1866
## Manure3    0.3101 -0.2470
## Manure4   -0.3463 -0.5583
## 
## Goodness of fit:
##              r2 Pr(&gt;r)   
## Moisture 0.5014  0.002 **
## Manure   0.4247  0.018 * 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## Permutation: free
## Number of permutations: 999</code></pre>
<p>The output shows that all three of A1 soil horizon thickness (<code>A1</code>), moisture category, and manure category were significantly related to the NMDS configuration. The plots below show some ways to illustrate these relationships. First, we can add vectors representing continuous variables to the ordination. These vectors are exactly like biplot arrows for variables that went into the ordination, and are interpreted the same way . If you include both ordinated variables and other variables fitted with <code>envfit()</code>, you should make them different colors.</p>
<div class="sourceCode" id="cb1726"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1726-1"><a href="mod-08.html#cb1726-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get coordinates of vectors (matrix)</span></span>
<span id="cb1726-2"><a href="mod-08.html#cb1726-2" aria-hidden="true" tabindex="-1"></a>ef.vec <span class="ot">&lt;-</span> ef<span class="sc">$</span>vectors<span class="sc">$</span>arrows</span>
<span id="cb1726-3"><a href="mod-08.html#cb1726-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1726-4"><a href="mod-08.html#cb1726-4" aria-hidden="true" tabindex="-1"></a><span class="co"># plot points</span></span>
<span id="cb1726-5"><a href="mod-08.html#cb1726-5" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb1726-6"><a href="mod-08.html#cb1726-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(px, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">cex=</span><span class="fl">1.3</span>,</span>
<span id="cb1726-7"><a href="mod-08.html#cb1726-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>))</span>
<span id="cb1726-8"><a href="mod-08.html#cb1726-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1726-9"><a href="mod-08.html#cb1726-9" aria-hidden="true" tabindex="-1"></a><span class="co"># add envfit vector</span></span>
<span id="cb1726-10"><a href="mod-08.html#cb1726-10" aria-hidden="true" tabindex="-1"></a><span class="fu">segments</span>(<span class="dv">0</span>, <span class="dv">0</span>, ef.vec[<span class="dv">1</span>,<span class="dv">1</span>], ef.vec[<span class="dv">1</span>,<span class="dv">2</span>], <span class="at">col=</span><span class="st">&quot;red&quot;</span>, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb1726-11"><a href="mod-08.html#cb1726-11" aria-hidden="true" tabindex="-1"></a><span class="co"># multiplier to move label outwards (should be &gt;1)</span></span>
<span id="cb1726-12"><a href="mod-08.html#cb1726-12" aria-hidden="true" tabindex="-1"></a>mult <span class="ot">&lt;-</span> <span class="fl">1.2</span></span>
<span id="cb1726-13"><a href="mod-08.html#cb1726-13" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(mult<span class="sc">*</span>ef.vec[<span class="dv">1</span>,<span class="dv">1</span>], mult<span class="sc">*</span>ef.vec[<span class="dv">1</span>,<span class="dv">2</span>],</span>
<span id="cb1726-14"><a href="mod-08.html#cb1726-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rownames</span>(ef.vec)[<span class="dv">1</span>], <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-783-1.png" width="672" /></p>
<div class="sourceCode" id="cb1727"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1727-1"><a href="mod-08.html#cb1727-1" aria-hidden="true" tabindex="-1"></a><span class="co"># not run:</span></span>
<span id="cb1727-2"><a href="mod-08.html#cb1727-2" aria-hidden="true" tabindex="-1"></a><span class="co"># if more than one continuous envfit to plot:</span></span>
<span id="cb1727-3"><a href="mod-08.html#cb1727-3" aria-hidden="true" tabindex="-1"></a><span class="co">#mult &lt;- 1.2</span></span>
<span id="cb1727-4"><a href="mod-08.html#cb1727-4" aria-hidden="true" tabindex="-1"></a><span class="co">#for(i in 1:nrow(ef.vec)){</span></span>
<span id="cb1727-5"><a href="mod-08.html#cb1727-5" aria-hidden="true" tabindex="-1"></a><span class="co">#    segments(0, 0, ef.vec[i,1], ef.vec[i,2],</span></span>
<span id="cb1727-6"><a href="mod-08.html#cb1727-6" aria-hidden="true" tabindex="-1"></a><span class="co">#        col=&quot;red&quot;, lwd=2)</span></span>
<span id="cb1727-7"><a href="mod-08.html#cb1727-7" aria-hidden="true" tabindex="-1"></a><span class="co">#    text(mult*ef.vec[i,1], mult*ef.vec[i,2],</span></span>
<span id="cb1727-8"><a href="mod-08.html#cb1727-8" aria-hidden="true" tabindex="-1"></a><span class="co">#        rownames(ef.vec)[i], col=&quot;red&quot;)</span></span>
<span id="cb1727-9"><a href="mod-08.html#cb1727-9" aria-hidden="true" tabindex="-1"></a><span class="co">#}</span></span></code></pre></div>
<p>Factors that define groups, like the farming types above, can be encoded in the points by shape and/or color, and their uncertainty expressed with ellipses. Factors that are ordered, like Moisture and Manure, can be added to the plot as arrows. Adding arrows to connect centroids of the levels of an ordered factor is also a great way to show changes over time or space. For example, you could use season or year as an ordered factor to show changes over time; or, use latitude or elevation intervals as an ordered factor. Even if one of these variables is treated continuously, showing arrows by ordered groups (levels) can help capture nonmonotonic relationships that would be masked by a single <code>envfit()</code> vector. The figure below illustrates the difference between treating a continuous predictor, time, as an ordered factor vs. as a continuous variable.</p>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_17.jpg" /></p>
<p>The code below shows how to extract the coordinates for the arrows showing levels of an ordered factor.</p>
<div class="sourceCode" id="cb1728"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1728-1"><a href="mod-08.html#cb1728-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get matrix of level centroids (has all factors)</span></span>
<span id="cb1728-2"><a href="mod-08.html#cb1728-2" aria-hidden="true" tabindex="-1"></a>ef.fac <span class="ot">&lt;-</span> ef<span class="sc">$</span>factors<span class="sc">$</span>centroids</span>
<span id="cb1728-3"><a href="mod-08.html#cb1728-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1728-4"><a href="mod-08.html#cb1728-4" aria-hidden="true" tabindex="-1"></a><span class="co"># isolate moisture and manure rows of matrix</span></span>
<span id="cb1728-5"><a href="mod-08.html#cb1728-5" aria-hidden="true" tabindex="-1"></a>ef.moi <span class="ot">&lt;-</span> ef.fac[<span class="fu">grep</span>(<span class="st">&quot;Moist&quot;</span>, <span class="fu">rownames</span>(ef.fac)),]</span>
<span id="cb1728-6"><a href="mod-08.html#cb1728-6" aria-hidden="true" tabindex="-1"></a>ef.man <span class="ot">&lt;-</span> ef.fac[<span class="fu">grep</span>(<span class="st">&quot;Manure&quot;</span>, <span class="fu">rownames</span>(ef.fac)),]</span>
<span id="cb1728-7"><a href="mod-08.html#cb1728-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1728-8"><a href="mod-08.html#cb1728-8" aria-hidden="true" tabindex="-1"></a><span class="co"># number of levels of each factor</span></span>
<span id="cb1728-9"><a href="mod-08.html#cb1728-9" aria-hidden="true" tabindex="-1"></a>nmois <span class="ot">&lt;-</span> <span class="fu">nrow</span>(ef.moi)</span>
<span id="cb1728-10"><a href="mod-08.html#cb1728-10" aria-hidden="true" tabindex="-1"></a>nmanu <span class="ot">&lt;-</span> <span class="fu">nrow</span>(ef.man)</span>
<span id="cb1728-11"><a href="mod-08.html#cb1728-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1728-12"><a href="mod-08.html#cb1728-12" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb1728-13"><a href="mod-08.html#cb1728-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(px, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">cex=</span><span class="fl">1.3</span>,</span>
<span id="cb1728-14"><a href="mod-08.html#cb1728-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>))</span>
<span id="cb1728-15"><a href="mod-08.html#cb1728-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1728-16"><a href="mod-08.html#cb1728-16" aria-hidden="true" tabindex="-1"></a><span class="co"># add arrows</span></span>
<span id="cb1728-17"><a href="mod-08.html#cb1728-17" aria-hidden="true" tabindex="-1"></a><span class="co"># notice how arrows are specified from the matrix as </span></span>
<span id="cb1728-18"><a href="mod-08.html#cb1728-18" aria-hidden="true" tabindex="-1"></a><span class="co"># beginning x, beginning y, ending x, and ending y, and</span></span>
<span id="cb1728-19"><a href="mod-08.html#cb1728-19" aria-hidden="true" tabindex="-1"></a><span class="co"># how bracket notation is used.</span></span>
<span id="cb1728-20"><a href="mod-08.html#cb1728-20" aria-hidden="true" tabindex="-1"></a><span class="fu">arrows</span>(ef.moi[<span class="sc">-</span>nmois,<span class="dv">1</span>], ef.moi[<span class="sc">-</span>nmois,<span class="dv">2</span>],</span>
<span id="cb1728-21"><a href="mod-08.html#cb1728-21" aria-hidden="true" tabindex="-1"></a>       ef.moi[<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>], ef.moi[<span class="sc">-</span><span class="dv">1</span>, <span class="dv">2</span>], <span class="at">col=</span><span class="st">&quot;red&quot;</span>,</span>
<span id="cb1728-22"><a href="mod-08.html#cb1728-22" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">length=</span><span class="fl">0.15</span>)</span>
<span id="cb1728-23"><a href="mod-08.html#cb1728-23" aria-hidden="true" tabindex="-1"></a><span class="fu">arrows</span>(ef.man[<span class="sc">-</span>nmanu ,<span class="dv">1</span>], ef.man[<span class="sc">-</span>nmanu ,<span class="dv">2</span>],</span>
<span id="cb1728-24"><a href="mod-08.html#cb1728-24" aria-hidden="true" tabindex="-1"></a>       ef.man[<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>], ef.man[<span class="sc">-</span><span class="dv">1</span>, <span class="dv">2</span>], <span class="at">col=</span><span class="st">&quot;blue&quot;</span>,</span>
<span id="cb1728-25"><a href="mod-08.html#cb1728-25" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">length=</span><span class="fl">0.15</span>)</span>
<span id="cb1728-26"><a href="mod-08.html#cb1728-26" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, </span>
<span id="cb1728-27"><a href="mod-08.html#cb1728-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;Moisture gradient&quot;</span>, <span class="st">&quot;Manure gradient&quot;</span>),</span>
<span id="cb1728-28"><a href="mod-08.html#cb1728-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>), <span class="at">bty=</span><span class="st">&quot;n&quot;</span>, <span class="at">cex=</span><span class="fl">1.3</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-784-1.png" width="672" /></p>
</div>
<div id="hypothesis-testing-using-nmds" class="section level4" number="8.5.2.4">
<h4><span class="header-section-number">8.5.2.4</span> Hypothesis testing using NMDS</h4>
<p>NMDS ordinations can also be used as the basis for hypothesis tests about the magnitude and direction of multivariate trends in experiments. If control and treated samples (or before and after samples) can be matched in pairs or groups, then the paths from the control/before to the treated/after samples can be thought of as the multivariate “response” to whatever the treatment was <span class="citation">(<a href="#ref-mccune2002analysis" role="doc-biblioref">McCune et al. 2002</a>)</span>. This is because differences in position in NMDS space represent differences in terms of the original variables. The example below uses simulated data to illustrate the method.</p>
<ul>
<li><strong>Left panel:</strong> NMDS ordination of samples. Arrows show change from “before” to “after”. Color of arrows signifies control treatment (black) or treated samples (red).</li>
<li><strong>Center panel:</strong> “Change vectors” translated so that they emanate from the origin. Magnitude of vector indicates magnitude of change from before to after treatment. Direction of vector indicates direction of change.</li>
<li><strong>Right panel:</strong> Change vectors translated to origin and scaled to unit length. Position of end points on unit circle indicate direction of change. In ecology these are also called “composition vectors” because they indicate changes in species composition regardless of magnitude of change.</li>
</ul>
<p><img src="C:/Users/ngreen62/OneDrive%20-%20Kennesaw%20State%20University/biol%206490/_stat/fig/08_18.jpg" /></p>
<p>The positions of the vector endpoints in the center panel can be used to test hypotheses about the overall change in the response variable matrix in response to treatment. An MRPP or other multivariate test such as PERMANOVA can be used to compare the locations of treatment groups in NMDS space. Differences in location in the center plot reflect both <em>magnitude</em> and <em>direction</em> of change.</p>
<p>Similarly, the positions of the composition vectors in the right panel can be used to test hypotheses about changes in the response variable matrix in response to treatment. Unlike the center panel, the differences in position in the right panel reflect <em>direction of change</em> only.</p>
</div>
</div>
<div id="other-ordination-techniques" class="section level3" number="8.5.3">
<h3><span class="header-section-number">8.5.3</span> Other ordination techniques</h3>
<p>PCA and NMDS were explored in detail because they are two of the most commonly used and applicable ordination techniques for biologists. There are other techniques out there that you may find useful but are beyond the scope of the course.</p>
<p><strong>Principal coordinates analysis (PCoA)</strong> is a variation of PCA that can use any kind of distance metric. In one sense PCA uses the Euclidean distance metric because of its reliance on least squares. PCoA can use any distance metric, which may be desirable for data that do not meet the linearity and normality assumptions of PCA. PCoA works by converting distances into the elements of the crossproducts matrix <strong>S</strong>, which basically “pretends” that non-Euclidean distances are Euclidean.</p>
<p><strong>Canonical ordination</strong> techniques simultaneously analyze two data matrices. Canonical ordination methods can be symmetric or asymmetric. In <strong>asymmetric</strong> methods, there is a response dataset and a predictor dataset. Reversing the roles of the matrices will change the outcome of the analysis. In contrast, <strong>symmetric</strong> methods treat both matrices the same. That is, in a symmetric ordination analysis, neither matrix is considered the “response” or “predictor” dataset. Reversing the roles of the matrices will not change the outputs.</p>
<div id="canonical-asymmetric-methods" class="section level4" number="8.5.3.1">
<h4><span class="header-section-number">8.5.3.1</span> Canonical asymmetric methods</h4>
<p>Canonical asymmetric methods produce ordinations of a response matrix <strong>Y</strong> that are constrained to be linearly related to a second set of variables, the predictor matrix <strong>X</strong>.</p>
<p><strong>Redundancy analysis (RDA)</strong> is an extension of multiple regression that models multivariate rather than univariate response values. Each ordination axis in RDA is called a “canonical axis” and is similar to a principal component. Each canonical axis in the response matrix <strong>Y</strong> is maximally related to a linear combination of variables in the predictor matrix <strong>X</strong>. RDA preserves the Euclidean distances among samples; this is a consequence of the relationship between RDA and multiple linear regression.</p>
<p><strong>Canonical correspondence analysis (CCorA)</strong> is similar to RDA, but preserves a different distance metric (<span class="math inline">\(\chi^{2}\)</span> or “chi-squared”) among the samples. CCorA may thus be more appropriate than RDA when data are nonnormal or when relationships are nonlinear.</p>
<p><strong>Linear discriminant analysis (LDA)</strong> identifies linear combinations of variables in a predictor matrix X that classify observations in a response matrix Y. LDA can be thought of loosely as a multivariate analogue to multiple logistic or multinomial regression. Classification trees may present a more robust alternative to LDA in many situations.</p>
</div>
<div id="canonical-symmetric-methods" class="section level4" number="8.5.3.2">
<h4><span class="header-section-number">8.5.3.2</span> Canonical symmetric methods</h4>
<p><strong>Canonical correlation analysis (CCA)</strong> is a constrained ordination technique where the ordination of one matrix is informed by multiple regression on another matrix. Given two data matrices <strong>A</strong> and <strong>B</strong>, with correlations among variables in <strong>A</strong> and <strong>B</strong>, CCA fits an ordination for both <strong>A</strong> and <strong>B</strong> where the canonical axes of each ordination are correlated with variables in the other matrix. In other words, CCA finds gradients in one matrix and tries to explain them in terms of information from another matrix. CCA is a powerful tool for exploratory analysis but can be confusing to fit and interpret.</p>
<p><strong>Co-inertia analysis (CoIA)</strong> and <strong>Procrustes analysis (Proc)</strong> both seek ordinations of two data matrices <strong>A</strong> and <strong>B</strong> that represent relationships in both <strong>A</strong> and <strong>B</strong> simultaneously. CoIA and Proc work very differently but answer a similar question: how can samples be arranged in a reduced dimension space that preserves distances in terms of two sets of variables?</p>
<p>These techniques are described by <span class="citation">Legendre and Legendre (<a href="#ref-legendre2012numerical" role="doc-biblioref">2012</a>)</span> and <span class="citation">McCune et al. (<a href="#ref-mccune2002analysis" role="doc-biblioref">2002</a>)</span>. The former reference has a more thorough mathematical treatment; the latter is more introductory. Both are excellent. Several newer references <span class="citation">(<a href="#ref-legendre2012numerical" role="doc-biblioref">Legendre and Legendre 2012</a>, <a href="#ref-borcard2018" role="doc-biblioref">Borcard et al. 2018</a>)</span> include R code for implementing the methods.</p>

</div>
</div>
</div>
</div>
<h3>Literature Cited</h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-anderson2001" class="csl-entry">
Anderson, M. J. 2001. <a href="https://doi.org/10.1111/j.1442-9993.2001.01070.pp.x">A new method for non-parametric multivariate analysis of variance</a>. Austral Ecology 26:32–46.
</div>
<div id="ref-borcard2018" class="csl-entry">
Borcard, D., F. Gillet, and P. Legendre. 2018. Numerical ecology with <span>R</span>. Springer, New York.
</div>
<div id="ref-clarke1993" class="csl-entry">
Clarke, K. R. 1993. <a href="https://doi.org/10.1111/j.1442-9993.1993.tb00438.x">Non-parametric multivariate analyses of changes in community structure</a>. Australian journal of ecology 18:117–143.
</div>
<div id="ref-clarke2006" class="csl-entry">
Clarke, K. R., P. J. Somerfield, and M. G. Chapman. 2006. <a href="https://doi.org/10.1016/j.jembe.2005.12.017">On resemblance measures for ecological studies, including taxonomic dissimilarities and a zero-adjusted bray-curtis coefficient for denuded assemblages</a>. Journal of Experimental Marine Biology and Ecology 330:55–80.
</div>
<div id="ref-hill1979" class="csl-entry">
Hill, M. O. 1979. A <span>FORTRAN</span> program for arranging multivariate data in an ordered two-way table by classification of the individuals and attributes. <span>TWINSPAN</span>.
</div>
<div id="ref-hutcheon2002" class="csl-entry">
Hutcheon, J. M., J. A. W. Kirsch, and T. G. Jr. 2002. <a href="https://doi.org/10.1159/000065938">A comparative analysis of brain size in relation to foraging ecology and phylogeny in the <span>C</span>hiroptera</a>. Brain, behavior and evolution 60:165–180.
</div>
<div id="ref-legendre2012numerical" class="csl-entry">
Legendre, P., and L. Legendre. 2012. Numerical ecology. Elsevier, Amsterdam.
</div>
<div id="ref-ludwig1988statistical" class="csl-entry">
Ludwig, J. A., J. F. Reynolds, L. QUARTET, and J. Reynolds. 1988. Statistical ecology: A primer in methods and computing. John Wiley &amp; Sons.
</div>
<div id="ref-mantel1967detection" class="csl-entry">
Mantel, N. 1967. <a href="https://cancerres.aacrjournals.org/content/27/2_Part_1/209">The detection of disease clustering and a generalized regression approach</a>. Cancer research 27:209–220.
</div>
<div id="ref-mccune2002analysis" class="csl-entry">
McCune, B., J. B. Grace, and D. L. Urban. 2002. Analysis of ecological communities. MjM software design Gleneden Beach, Oregon, USA.
</div>
<div id="ref-rolecek2009" class="csl-entry">
Roleček, J., L. Tichý, D. Zelený, and M. Chytrý. 2009. <a href="https://doi.org/10.1111/j.1654-1103.2009.01062.x">Modified <span>TWINSPAN</span> classification in which the hierarchy respects cluster heterogeneity</a>. Journal of Vegetation Science 20:596–602.
</div>
<div id="ref-ward1963" class="csl-entry">
Ward, J. H. 1963. <a href="https://doi.org/10.1080/01621459.1963.10500845">Hierarchical grouping to optimize an objective function</a>. Journal of the American Statistical Association 58:236–244.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="mod-07.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mod-09.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
