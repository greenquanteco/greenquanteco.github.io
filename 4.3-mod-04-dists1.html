<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.3 Statistical distributions | Applied Biological Data Analysis</title>
  <meta name="description" content="Helping biologists to become more informed users of R and statistical methods." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="4.3 Statistical distributions | Applied Biological Data Analysis" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://greenquanteco.github.io/index.html" />
  <meta property="og:image" content="https://greenquanteco.github.io/index.html/C:/Users/ngreen62/OneDrive - Kennesaw State University/ksu/website/lab_logo_02.jpg" />
  <meta property="og:description" content="Helping biologists to become more informed users of R and statistical methods." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.3 Statistical distributions | Applied Biological Data Analysis" />
  
  <meta name="twitter:description" content="Helping biologists to become more informed users of R and statistical methods." />
  <meta name="twitter:image" content="https://greenquanteco.github.io/index.html/C:/Users/ngreen62/OneDrive - Kennesaw State University/ksu/website/lab_logo_02.jpg" />

<meta name="author" content="Nick Green, Kennesaw State University" />


<meta name="date" content="2022-01-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="4.2-mod-04-vis.html"/>
<link rel="next" href="4.4-mod-04-dists2.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="license-and-permissions.html"><a href="license-and-permissions.html"><i class="fa fa-check"></i>License and permissions</a></li>
<li class="chapter" data-level="" data-path="course-description.html"><a href="course-description.html"><i class="fa fa-check"></i>Course description</a></li>
<li class="chapter" data-level="" data-path="course-objectives.html"><a href="course-objectives.html"><i class="fa fa-check"></i>Course objectives</a></li>
<li class="chapter" data-level="" data-path="course-requirements.html"><a href="course-requirements.html"><i class="fa fa-check"></i>Course requirements</a></li>
<li class="chapter" data-level="" data-path="recommended-reading.html"><a href="recommended-reading.html"><i class="fa fa-check"></i>Recommended reading</a></li>
<li class="chapter" data-level="" data-path="course-organization.html"><a href="course-organization.html"><i class="fa fa-check"></i>Course organization</a></li>
<li class="chapter" data-level="" data-path="about-the-author.html"><a href="about-the-author.html"><i class="fa fa-check"></i>About the author</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="1-mod-01.html"><a href="1-mod-01.html"><i class="fa fa-check"></i><b>1</b> Statistics in modern biology</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1.1-overview.html"><a href="1.1-overview.html"><i class="fa fa-check"></i><b>1.1</b> Overview</a></li>
<li class="chapter" data-level="1.2" data-path="1.2-statistics-in-modern-biology.html"><a href="1.2-statistics-in-modern-biology.html"><i class="fa fa-check"></i><b>1.2</b> Statistics in modern biology</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="1.2-statistics-in-modern-biology.html"><a href="1.2-statistics-in-modern-biology.html#the-scientific-method"><i class="fa fa-check"></i><b>1.2.1</b> The scientific method</a></li>
<li class="chapter" data-level="1.2.2" data-path="1.2-statistics-in-modern-biology.html"><a href="1.2-statistics-in-modern-biology.html#example-data-analysis"><i class="fa fa-check"></i><b>1.2.2</b> Example data analysis</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1.3-misuses-of-statistics.html"><a href="1.3-misuses-of-statistics.html"><i class="fa fa-check"></i><b>1.3</b> Misuses of statistics</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="1.3-misuses-of-statistics.html"><a href="1.3-misuses-of-statistics.html#proving-the-trivial-and-meaningless-hypotheses"><i class="fa fa-check"></i><b>1.3.1</b> “Proving” the trivial and meaningless hypotheses</a></li>
<li class="chapter" data-level="1.3.2" data-path="1.3-misuses-of-statistics.html"><a href="1.3-misuses-of-statistics.html#inappropriate-methods"><i class="fa fa-check"></i><b>1.3.2</b> Inappropriate methods</a></li>
<li class="chapter" data-level="1.3.3" data-path="1.3-misuses-of-statistics.html"><a href="1.3-misuses-of-statistics.html#p-hacking-and-data-dredging"><i class="fa fa-check"></i><b>1.3.3</b> <em>P</em>-hacking and data dredging</a></li>
<li class="chapter" data-level="1.3.4" data-path="1.3-misuses-of-statistics.html"><a href="1.3-misuses-of-statistics.html#inadequate-sample-sizes-and-pseudoreplication"><i class="fa fa-check"></i><b>1.3.4</b> Inadequate sample sizes and pseudoreplication</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1.4-p-values-and-null-hypothesis-significance-testing-nhst.html"><a href="1.4-p-values-and-null-hypothesis-significance-testing-nhst.html"><i class="fa fa-check"></i><b>1.4</b> <em>P</em>-values and null hypothesis significance testing (NHST)</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="1.4-p-values-and-null-hypothesis-significance-testing-nhst.html"><a href="1.4-p-values-and-null-hypothesis-significance-testing-nhst.html#definition"><i class="fa fa-check"></i><b>1.4.1</b> Definition</a></li>
<li class="chapter" data-level="1.4.2" data-path="1.4-p-values-and-null-hypothesis-significance-testing-nhst.html"><a href="1.4-p-values-and-null-hypothesis-significance-testing-nhst.html#history-and-status-of-p-values"><i class="fa fa-check"></i><b>1.4.2</b> History and status of <em>P</em>-values</a></li>
<li class="chapter" data-level="1.4.3" data-path="1.4-p-values-and-null-hypothesis-significance-testing-nhst.html"><a href="1.4-p-values-and-null-hypothesis-significance-testing-nhst.html#where-p-values-come-from"><i class="fa fa-check"></i><b>1.4.3</b> Where <em>P</em>-values come from</a></li>
<li class="chapter" data-level="1.4.4" data-path="1.4-p-values-and-null-hypothesis-significance-testing-nhst.html"><a href="1.4-p-values-and-null-hypothesis-significance-testing-nhst.html#what-p-values-mean-and-do-not-mean"><i class="fa fa-check"></i><b>1.4.4</b> What <em>P</em>-values mean and do not mean</a></li>
<li class="chapter" data-level="1.4.5" data-path="1.4-p-values-and-null-hypothesis-significance-testing-nhst.html"><a href="1.4-p-values-and-null-hypothesis-significance-testing-nhst.html#do-you-need-a-p-value"><i class="fa fa-check"></i><b>1.4.5</b> Do you need a <em>P</em>-value?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="1.5-alternatives-to-nhst.html"><a href="1.5-alternatives-to-nhst.html"><i class="fa fa-check"></i><b>1.5</b> Alternatives to NHST</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="1.5-alternatives-to-nhst.html"><a href="1.5-alternatives-to-nhst.html#bayesian-inference"><i class="fa fa-check"></i><b>1.5.1</b> Bayesian inference</a></li>
<li class="chapter" data-level="1.5.2" data-path="1.5-alternatives-to-nhst.html"><a href="1.5-alternatives-to-nhst.html#information-theoretic-methods"><i class="fa fa-check"></i><b>1.5.2</b> Information-theoretic methods</a></li>
<li class="chapter" data-level="1.5.3" data-path="1.5-alternatives-to-nhst.html"><a href="1.5-alternatives-to-nhst.html#machine-learning"><i class="fa fa-check"></i><b>1.5.3</b> Machine learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-mod-02.html"><a href="2-mod-02.html"><i class="fa fa-check"></i><b>2</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2.1-getting-started-with-r.html"><a href="2.1-getting-started-with-r.html"><i class="fa fa-check"></i><b>2.1</b> Getting started with R</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="2.1-getting-started-with-r.html"><a href="2.1-getting-started-with-r.html#what-is-r"><i class="fa fa-check"></i><b>2.1.1</b> What is R?</a></li>
<li class="chapter" data-level="2.1.2" data-path="2.1-getting-started-with-r.html"><a href="2.1-getting-started-with-r.html#advantages-of-r"><i class="fa fa-check"></i><b>2.1.2</b> Advantages of R</a></li>
<li class="chapter" data-level="2.1.3" data-path="2.1-getting-started-with-r.html"><a href="2.1-getting-started-with-r.html#disadvantages-of-r"><i class="fa fa-check"></i><b>2.1.3</b> Disadvantages of R</a></li>
<li class="chapter" data-level="2.1.4" data-path="2.1-getting-started-with-r.html"><a href="2.1-getting-started-with-r.html#base-r-and-vs.-tidyverse"><i class="fa fa-check"></i><b>2.1.4</b> Base R and (vs.?) <code>tidyverse</code></a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="2.2-download-and-install-r-and-rstudio.html"><a href="2.2-download-and-install-r-and-rstudio.html"><i class="fa fa-check"></i><b>2.2</b> Download and install R (and RStudio)</a></li>
<li class="chapter" data-level="2.3" data-path="2.3-using-r.html"><a href="2.3-using-r.html"><i class="fa fa-check"></i><b>2.3</b> Using R</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="2.3-using-r.html"><a href="2.3-using-r.html#using-the-base-r-gui"><i class="fa fa-check"></i><b>2.3.1</b> Using the base R GUI</a></li>
<li class="chapter" data-level="2.3.2" data-path="2.3-using-r.html"><a href="2.3-using-r.html#using-r-in-rstudio"><i class="fa fa-check"></i><b>2.3.2</b> Using R in RStudio</a></li>
<li class="chapter" data-level="2.3.3" data-path="2.3-using-r.html"><a href="2.3-using-r.html#using-r-with-other-programs"><i class="fa fa-check"></i><b>2.3.3</b> Using R with other programs</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="2.4-mod-02-first.html"><a href="2.4-mod-02-first.html"><i class="fa fa-check"></i><b>2.4</b> A first R session</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="2.4-mod-02-first.html"><a href="2.4-mod-02-first.html#import-data"><i class="fa fa-check"></i><b>2.4.1</b> Import data</a></li>
<li class="chapter" data-level="2.4.2" data-path="2.4-mod-02-first.html"><a href="2.4-mod-02-first.html#explore-and-visualize-data"><i class="fa fa-check"></i><b>2.4.2</b> Explore and visualize data</a></li>
<li class="chapter" data-level="2.4.3" data-path="2.4-mod-02-first.html"><a href="2.4-mod-02-first.html#transform-data"><i class="fa fa-check"></i><b>2.4.3</b> Transform data</a></li>
<li class="chapter" data-level="2.4.4" data-path="2.4-mod-02-first.html"><a href="2.4-mod-02-first.html#analyze-data"><i class="fa fa-check"></i><b>2.4.4</b> Analyze data</a></li>
<li class="chapter" data-level="2.4.5" data-path="2.4-mod-02-first.html"><a href="2.4-mod-02-first.html#write-out-results"><i class="fa fa-check"></i><b>2.4.5</b> Write out results</a></li>
<li class="chapter" data-level="2.4.6" data-path="2.4-mod-02-first.html"><a href="2.4-mod-02-first.html#save-your-work"><i class="fa fa-check"></i><b>2.4.6</b> Save your work?</a></li>
<li class="chapter" data-level="2.4.7" data-path="2.4-mod-02-first.html"><a href="2.4-mod-02-first.html#whats-next"><i class="fa fa-check"></i><b>2.4.7</b> What’s next?</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="2.5-write-and-execute-commands-in-the-r-console.html"><a href="2.5-write-and-execute-commands-in-the-r-console.html"><i class="fa fa-check"></i><b>2.5</b> Write and execute commands in the R console</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="2.5-write-and-execute-commands-in-the-r-console.html"><a href="2.5-write-and-execute-commands-in-the-r-console.html#r-commandsbasics"><i class="fa fa-check"></i><b>2.5.1</b> R commands–basics</a></li>
<li class="chapter" data-level="2.5.2" data-path="2.5-write-and-execute-commands-in-the-r-console.html"><a href="2.5-write-and-execute-commands-in-the-r-console.html#elements-of-r-code"><i class="fa fa-check"></i><b>2.5.2</b> Elements of R code</a></li>
<li class="chapter" data-level="2.5.3" data-path="2.5-write-and-execute-commands-in-the-r-console.html"><a href="2.5-write-and-execute-commands-in-the-r-console.html#the-r-workspace"><i class="fa fa-check"></i><b>2.5.3</b> The R workspace</a></li>
<li class="chapter" data-level="2.5.4" data-path="2.5-write-and-execute-commands-in-the-r-console.html"><a href="2.5-write-and-execute-commands-in-the-r-console.html#r-code-basics-assignment-and-operators"><i class="fa fa-check"></i><b>2.5.4</b> R code basics: assignment and operators</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="2.6-mod-02-struct.html"><a href="2.6-mod-02-struct.html"><i class="fa fa-check"></i><b>2.6</b> Basic R data structures</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="2.6-mod-02-struct.html"><a href="2.6-mod-02-struct.html#vectors"><i class="fa fa-check"></i><b>2.6.1</b> Vectors</a></li>
<li class="chapter" data-level="2.6.2" data-path="2.6-mod-02-struct.html"><a href="2.6-mod-02-struct.html#data-frames"><i class="fa fa-check"></i><b>2.6.2</b> Data frames</a></li>
<li class="chapter" data-level="2.6.3" data-path="2.6-mod-02-struct.html"><a href="2.6-mod-02-struct.html#matrices-and-arrays"><i class="fa fa-check"></i><b>2.6.3</b> Matrices and arrays</a></li>
<li class="chapter" data-level="2.6.4" data-path="2.6-mod-02-struct.html"><a href="2.6-mod-02-struct.html#lists"><i class="fa fa-check"></i><b>2.6.4</b> Lists</a></li>
<li class="chapter" data-level="2.6.5" data-path="2.6-mod-02-struct.html"><a href="2.6-mod-02-struct.html#s4-objects"><i class="fa fa-check"></i><b>2.6.5</b> S4 objects</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="2.7-r-data-types.html"><a href="2.7-r-data-types.html"><i class="fa fa-check"></i><b>2.7</b> R data types</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="2.7-r-data-types.html"><a href="2.7-r-data-types.html#character-type"><i class="fa fa-check"></i><b>2.7.1</b> Character type</a></li>
<li class="chapter" data-level="2.7.2" data-path="2.7-r-data-types.html"><a href="2.7-r-data-types.html#numeric-type"><i class="fa fa-check"></i><b>2.7.2</b> Numeric type</a></li>
<li class="chapter" data-level="2.7.3" data-path="2.7-r-data-types.html"><a href="2.7-r-data-types.html#integer-type"><i class="fa fa-check"></i><b>2.7.3</b> Integer type</a></li>
<li class="chapter" data-level="2.7.4" data-path="2.7-r-data-types.html"><a href="2.7-r-data-types.html#logical-type"><i class="fa fa-check"></i><b>2.7.4</b> Logical type</a></li>
<li class="chapter" data-level="2.7.5" data-path="2.7-r-data-types.html"><a href="2.7-r-data-types.html#special-values"><i class="fa fa-check"></i><b>2.7.5</b> Special values</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="2.8-manage-r-code-as-scripts-.r-files.html"><a href="2.8-manage-r-code-as-scripts-.r-files.html"><i class="fa fa-check"></i><b>2.8</b> Manage R code as scripts (.r files)</a></li>
<li class="chapter" data-level="2.9" data-path="2.9-manage-and-use-r-packages.html"><a href="2.9-manage-and-use-r-packages.html"><i class="fa fa-check"></i><b>2.9</b> Manage and use R packages</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="2.9-manage-and-use-r-packages.html"><a href="2.9-manage-and-use-r-packages.html#your-r-library"><i class="fa fa-check"></i><b>2.9.1</b> Your R library</a></li>
<li class="chapter" data-level="2.9.2" data-path="2.9-manage-and-use-r-packages.html"><a href="2.9-manage-and-use-r-packages.html#installing-packages-using-the-r-gui"><i class="fa fa-check"></i><b>2.9.2</b> Installing packages using the R GUI</a></li>
<li class="chapter" data-level="2.9.3" data-path="2.9-manage-and-use-r-packages.html"><a href="2.9-manage-and-use-r-packages.html#installing-packages-in-rstudio"><i class="fa fa-check"></i><b>2.9.3</b> Installing packages in RStudio</a></li>
<li class="chapter" data-level="2.9.4" data-path="2.9-manage-and-use-r-packages.html"><a href="2.9-manage-and-use-r-packages.html#installing-packages-using-the-r-console"><i class="fa fa-check"></i><b>2.9.4</b> Installing packages using the R console</a></li>
<li class="chapter" data-level="2.9.5" data-path="2.9-manage-and-use-r-packages.html"><a href="2.9-manage-and-use-r-packages.html#working-with-packages-in-r"><i class="fa fa-check"></i><b>2.9.5</b> Working with packages in R</a></li>
<li class="chapter" data-level="2.9.6" data-path="2.9-manage-and-use-r-packages.html"><a href="2.9-manage-and-use-r-packages.html#package-dependencies"><i class="fa fa-check"></i><b>2.9.6</b> Package dependencies</a></li>
<li class="chapter" data-level="2.9.7" data-path="2.9-manage-and-use-r-packages.html"><a href="2.9-manage-and-use-r-packages.html#citing-packages"><i class="fa fa-check"></i><b>2.9.7</b> Citing packages</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="2.10-r-documentation.html"><a href="2.10-r-documentation.html"><i class="fa fa-check"></i><b>2.10</b> R documentation</a>
<ul>
<li class="chapter" data-level="2.10.1" data-path="2.10-r-documentation.html"><a href="2.10-r-documentation.html#documentation-help-files"><i class="fa fa-check"></i><b>2.10.1</b> Documentation (help) files</a></li>
<li class="chapter" data-level="2.10.2" data-path="2.10-r-documentation.html"><a href="2.10-r-documentation.html#r-vignettes"><i class="fa fa-check"></i><b>2.10.2</b> R vignettes</a></li>
<li class="chapter" data-level="2.10.3" data-path="2.10-r-documentation.html"><a href="2.10-r-documentation.html#official-r-project-resources"><i class="fa fa-check"></i><b>2.10.3</b> Official R Project resources</a></li>
<li class="chapter" data-level="2.10.4" data-path="2.10-r-documentation.html"><a href="2.10-r-documentation.html#unofficial-online-resources"><i class="fa fa-check"></i><b>2.10.4</b> Unofficial online resources</a></li>
<li class="chapter" data-level="2.10.5" data-path="2.10-r-documentation.html"><a href="2.10-r-documentation.html#r-books"><i class="fa fa-check"></i><b>2.10.5</b> R books</a></li>
<li class="chapter" data-level="2.10.6" data-path="2.10-r-documentation.html"><a href="2.10-r-documentation.html#two-reminders"><i class="fa fa-check"></i><b>2.10.6</b> Two reminders</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-mod-03.html"><a href="3-mod-03.html"><i class="fa fa-check"></i><b>3</b> Data manipulation with R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3.1-mod-03-inout.html"><a href="3.1-mod-03-inout.html"><i class="fa fa-check"></i><b>3.1</b> Data import and export</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="3.1-mod-03-inout.html"><a href="3.1-mod-03-inout.html#importing-data-preliminaries"><i class="fa fa-check"></i><b>3.1.1</b> Importing data: preliminaries</a></li>
<li class="chapter" data-level="3.1.2" data-path="3.1-mod-03-inout.html"><a href="3.1-mod-03-inout.html#importing-data-from-text-files-with-read.csv-and-read.table"><i class="fa fa-check"></i><b>3.1.2</b> Importing data from text files with <code>read.csv()</code> and <code>read.table()</code></a></li>
<li class="chapter" data-level="3.1.3" data-path="3.1-mod-03-inout.html"><a href="3.1-mod-03-inout.html#importing-data-from-saved-workspaces"><i class="fa fa-check"></i><b>3.1.3</b> Importing data from saved workspaces</a></li>
<li class="chapter" data-level="3.1.4" data-path="3.1-mod-03-inout.html"><a href="3.1-mod-03-inout.html#importing-data-special-cases"><i class="fa fa-check"></i><b>3.1.4</b> Importing data: special cases:</a></li>
<li class="chapter" data-level="3.1.5" data-path="3.1-mod-03-inout.html"><a href="3.1-mod-03-inout.html#export-data-from-r"><i class="fa fa-check"></i><b>3.1.5</b> Export data from R</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="3.2-making-values-in-r.html"><a href="3.2-making-values-in-r.html"><i class="fa fa-check"></i><b>3.2</b> Making values in R</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="3.2-making-values-in-r.html"><a href="3.2-making-values-in-r.html#producing-arbitrary-values-with-c"><i class="fa fa-check"></i><b>3.2.1</b> Producing arbitrary values with <code>c()</code></a></li>
<li class="chapter" data-level="3.2.2" data-path="3.2-making-values-in-r.html"><a href="3.2-making-values-in-r.html#generating-regular-values"><i class="fa fa-check"></i><b>3.2.2</b> Generating regular values</a></li>
<li class="chapter" data-level="3.2.3" data-path="3.2-making-values-in-r.html"><a href="3.2-making-values-in-r.html#generating-random-values"><i class="fa fa-check"></i><b>3.2.3</b> Generating random values</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3.3-selecting-data-with.html"><a href="3.3-selecting-data-with.html"><i class="fa fa-check"></i><b>3.3</b> Selecting data with <code>[]</code></a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="3.3-selecting-data-with.html"><a href="3.3-selecting-data-with.html#mod-03-brackets"><i class="fa fa-check"></i><b>3.3.1</b> Basics of brackets</a></li>
<li class="chapter" data-level="3.3.2" data-path="3.3-selecting-data-with.html"><a href="3.3-selecting-data-with.html#extracting-and-selecting-data-with-logical-tests"><i class="fa fa-check"></i><b>3.3.2</b> Extracting and selecting data with logical tests</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3.4-managing-dates-and-characters.html"><a href="3.4-managing-dates-and-characters.html"><i class="fa fa-check"></i><b>3.4</b> Managing dates and characters</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="3.4-managing-dates-and-characters.html"><a href="3.4-managing-dates-and-characters.html#temporal-data-and-dates"><i class="fa fa-check"></i><b>3.4.1</b> Temporal data and dates</a></li>
<li class="chapter" data-level="3.4.2" data-path="3.4-managing-dates-and-characters.html"><a href="3.4-managing-dates-and-characters.html#character-data-text"><i class="fa fa-check"></i><b>3.4.2</b> Character data (text)</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3.5-mod-03-dataframe.html"><a href="3.5-mod-03-dataframe.html"><i class="fa fa-check"></i><b>3.5</b> Data frame management</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="3.5-mod-03-dataframe.html"><a href="3.5-mod-03-dataframe.html#data-frame-structure"><i class="fa fa-check"></i><b>3.5.1</b> Data frame structure</a></li>
<li class="chapter" data-level="3.5.2" data-path="3.5-mod-03-dataframe.html"><a href="3.5-mod-03-dataframe.html#common-data-frame-operations"><i class="fa fa-check"></i><b>3.5.2</b> Common data frame operations</a></li>
<li class="chapter" data-level="3.5.3" data-path="3.5-mod-03-dataframe.html"><a href="3.5-mod-03-dataframe.html#other-data-frame-operations"><i class="fa fa-check"></i><b>3.5.3</b> Other data frame operations</a></li>
<li class="chapter" data-level="3.5.4" data-path="3.5-mod-03-dataframe.html"><a href="3.5-mod-03-dataframe.html#mod-03-reshape"><i class="fa fa-check"></i><b>3.5.4</b> Reshaping data frames</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-mod-04.html"><a href="4-mod-04.html"><i class="fa fa-check"></i><b>4</b> Exploratory data analysis</a>
<ul>
<li class="chapter" data-level="4.1" data-path="4.1-descriptive-and-summary-statistics.html"><a href="4.1-descriptive-and-summary-statistics.html"><i class="fa fa-check"></i><b>4.1</b> Descriptive and summary statistics</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="4.1-descriptive-and-summary-statistics.html"><a href="4.1-descriptive-and-summary-statistics.html#basic-summary-statistics"><i class="fa fa-check"></i><b>4.1.1</b> Basic summary statistics</a></li>
<li class="chapter" data-level="4.1.2" data-path="4.1-descriptive-and-summary-statistics.html"><a href="4.1-descriptive-and-summary-statistics.html#summarizing-data-with-the-apply-family"><i class="fa fa-check"></i><b>4.1.2</b> Summarizing data with the <code>apply()</code> family</a></li>
<li class="chapter" data-level="4.1.3" data-path="4.1-descriptive-and-summary-statistics.html"><a href="4.1-descriptive-and-summary-statistics.html#mod-04-tabagg"><i class="fa fa-check"></i><b>4.1.3</b> Tabulation and aggregation</a></li>
<li class="chapter" data-level="4.1.4" data-path="4.1-descriptive-and-summary-statistics.html"><a href="4.1-descriptive-and-summary-statistics.html#aggregation-aka-pivot-tables"><i class="fa fa-check"></i><b>4.1.4</b> Aggregation (aka: pivot tables)</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4.2-mod-04-vis.html"><a href="4.2-mod-04-vis.html"><i class="fa fa-check"></i><b>4.2</b> Visualizing data distributions</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="4.2-mod-04-vis.html"><a href="4.2-mod-04-vis.html#boxplots-aka-box-and-whisker-plots"><i class="fa fa-check"></i><b>4.2.1</b> Boxplots (aka: box-and-whisker plots)</a></li>
<li class="chapter" data-level="4.2.2" data-path="4.2-mod-04-vis.html"><a href="4.2-mod-04-vis.html#histograms"><i class="fa fa-check"></i><b>4.2.2</b> Histograms</a></li>
<li class="chapter" data-level="4.2.3" data-path="4.2-mod-04-vis.html"><a href="4.2-mod-04-vis.html#kernel-density-plots"><i class="fa fa-check"></i><b>4.2.3</b> Kernel density plots</a></li>
<li class="chapter" data-level="4.2.4" data-path="4.2-mod-04-vis.html"><a href="4.2-mod-04-vis.html#empirical-cumulative-distribution-plots-ecdf"><i class="fa fa-check"></i><b>4.2.4</b> Empirical cumulative distribution plots (ECDF)</a></li>
<li class="chapter" data-level="4.2.5" data-path="4.2-mod-04-vis.html"><a href="4.2-mod-04-vis.html#quantile-quantile-qq-plots"><i class="fa fa-check"></i><b>4.2.5</b> Quantile-quantile (QQ) plots</a></li>
<li class="chapter" data-level="4.2.6" data-path="4.2-mod-04-vis.html"><a href="4.2-mod-04-vis.html#how-should-i-plot-my-data"><i class="fa fa-check"></i><b>4.2.6</b> How should I plot my data?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4.3-mod-04-dists1.html"><a href="4.3-mod-04-dists1.html"><i class="fa fa-check"></i><b>4.3</b> Statistical distributions</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="4.3-mod-04-dists1.html"><a href="4.3-mod-04-dists1.html#probability-distributions"><i class="fa fa-check"></i><b>4.3.1</b> Probability distributions</a></li>
<li class="chapter" data-level="4.3.2" data-path="4.3-mod-04-dists1.html"><a href="4.3-mod-04-dists1.html#probability-distributions-in-r"><i class="fa fa-check"></i><b>4.3.2</b> Probability distributions in R</a></li>
<li class="chapter" data-level="4.3.3" data-path="4.3-mod-04-dists1.html"><a href="4.3-mod-04-dists1.html#discrete-distributions"><i class="fa fa-check"></i><b>4.3.3</b> Discrete distributions</a></li>
<li class="chapter" data-level="4.3.4" data-path="4.3-mod-04-dists1.html"><a href="4.3-mod-04-dists1.html#continuous-distributions"><i class="fa fa-check"></i><b>4.3.4</b> Continuous distributions</a></li>
<li class="chapter" data-level="4.3.5" data-path="4.3-mod-04-dists1.html"><a href="4.3-mod-04-dists1.html#distributions-summary"><i class="fa fa-check"></i><b>4.3.5</b> Distributions summary</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="4.4-mod-04-dists2.html"><a href="4.4-mod-04-dists2.html"><i class="fa fa-check"></i><b>4.4</b> Fitting and testing distributions</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="4.4-mod-04-dists2.html"><a href="4.4-mod-04-dists2.html#estimating-distributional-parameters"><i class="fa fa-check"></i><b>4.4.1</b> Estimating distributional parameters</a></li>
<li class="chapter" data-level="4.4.2" data-path="4.4-mod-04-dists2.html"><a href="4.4-mod-04-dists2.html#graphical-methods-for-examining-distributions"><i class="fa fa-check"></i><b>4.4.2</b> Graphical methods for examining distributions</a></li>
<li class="chapter" data-level="4.4.3" data-path="4.4-mod-04-dists2.html"><a href="4.4-mod-04-dists2.html#formal-tests-for-distributions"><i class="fa fa-check"></i><b>4.4.3</b> Formal tests for distributions</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="4.5-mod-04-trans.html"><a href="4.5-mod-04-trans.html"><i class="fa fa-check"></i><b>4.5</b> Data transformations</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="4.5-mod-04-trans.html"><a href="4.5-mod-04-trans.html#why-transform"><i class="fa fa-check"></i><b>4.5.1</b> Why transform?</a></li>
<li class="chapter" data-level="4.5.2" data-path="4.5-mod-04-trans.html"><a href="4.5-mod-04-trans.html#transforms-vs.-link-functions"><i class="fa fa-check"></i><b>4.5.2</b> Transforms vs. link functions</a></li>
<li class="chapter" data-level="4.5.3" data-path="4.5-mod-04-trans.html"><a href="4.5-mod-04-trans.html#log-transformation"><i class="fa fa-check"></i><b>4.5.3</b> Log transformation</a></li>
<li class="chapter" data-level="4.5.4" data-path="4.5-mod-04-trans.html"><a href="4.5-mod-04-trans.html#rank-transformation"><i class="fa fa-check"></i><b>4.5.4</b> Rank transformation</a></li>
<li class="chapter" data-level="4.5.5" data-path="4.5-mod-04-trans.html"><a href="4.5-mod-04-trans.html#other-transforms-less-common"><i class="fa fa-check"></i><b>4.5.5</b> Other transforms (less common)</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="4.6-multivariate-data-exploration.html"><a href="4.6-multivariate-data-exploration.html"><i class="fa fa-check"></i><b>4.6</b> Multivariate data exploration</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="4.6-multivariate-data-exploration.html"><a href="4.6-multivariate-data-exploration.html#scatterplots-for-two-variables"><i class="fa fa-check"></i><b>4.6.1</b> Scatterplots for two variables</a></li>
<li class="chapter" data-level="4.6.2" data-path="4.6-multivariate-data-exploration.html"><a href="4.6-multivariate-data-exploration.html#mod-04-smat"><i class="fa fa-check"></i><b>4.6.2</b> Scatterplot matrices for many variables</a></li>
<li class="chapter" data-level="4.6.3" data-path="4.6-multivariate-data-exploration.html"><a href="4.6-multivariate-data-exploration.html#lattice-plots-for-hierarchical-data"><i class="fa fa-check"></i><b>4.6.3</b> Lattice plots for hierarchical data</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="4.7-ordination-brief-introduction.html"><a href="4.7-ordination-brief-introduction.html"><i class="fa fa-check"></i><b>4.7</b> Ordination (brief introduction)</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="4.7-ordination-brief-introduction.html"><a href="4.7-ordination-brief-introduction.html#principal-components-analysis-pca"><i class="fa fa-check"></i><b>4.7.1</b> Principal components analysis (PCA)</a></li>
<li class="chapter" data-level="4.7.2" data-path="4.7-ordination-brief-introduction.html"><a href="4.7-ordination-brief-introduction.html#nonmetric-multidimensional-scaling-nmds"><i class="fa fa-check"></i><b>4.7.2</b> Nonmetric multidimensional scaling (NMDS)</a></li>
<li class="chapter" data-level="4.7.3" data-path="4.7-ordination-brief-introduction.html"><a href="4.7-ordination-brief-introduction.html#plotting-ordinations"><i class="fa fa-check"></i><b>4.7.3</b> Plotting ordinations</a></li>
<li class="chapter" data-level="4.7.4" data-path="4.7-ordination-brief-introduction.html"><a href="4.7-ordination-brief-introduction.html#ordination-wrap-up-for-now"><i class="fa fa-check"></i><b>4.7.4</b> Ordination wrap-up (for now)</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="4.8-mod-04-prob.html"><a href="4.8-mod-04-prob.html"><i class="fa fa-check"></i><b>4.8</b> Common statistical problems</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="4.8-mod-04-prob.html"><a href="4.8-mod-04-prob.html#outliers-and-erroneous-values"><i class="fa fa-check"></i><b>4.8.1</b> Outliers and erroneous values</a></li>
<li class="chapter" data-level="4.8.2" data-path="4.8-mod-04-prob.html"><a href="4.8-mod-04-prob.html#autocorrelation"><i class="fa fa-check"></i><b>4.8.2</b> Autocorrelation</a></li>
<li class="chapter" data-level="4.8.3" data-path="4.8-mod-04-prob.html"><a href="4.8-mod-04-prob.html#mod-04-multicol"><i class="fa fa-check"></i><b>4.8.3</b> Collinearity</a></li>
<li class="chapter" data-level="4.8.4" data-path="4.8-mod-04-prob.html"><a href="4.8-mod-04-prob.html#missing-data"><i class="fa fa-check"></i><b>4.8.4</b> Missing data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-mod-05.html"><a href="5-mod-05.html"><i class="fa fa-check"></i><b>5</b> Generalized linear models (GLM)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5.1-mod-05-lm.html"><a href="5.1-mod-05-lm.html"><i class="fa fa-check"></i><b>5.1</b> Prelude with linear models</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="5.1-mod-05-lm.html"><a href="5.1-mod-05-lm.html#assumptions-of-linear-models"><i class="fa fa-check"></i><b>5.1.1</b> Assumptions of linear models</a></li>
<li class="chapter" data-level="5.1.2" data-path="5.1-mod-05-lm.html"><a href="5.1-mod-05-lm.html#linear-regression-in-r"><i class="fa fa-check"></i><b>5.1.2</b> Linear regression in R</a></li>
<li class="chapter" data-level="5.1.3" data-path="5.1-mod-05-lm.html"><a href="5.1-mod-05-lm.html#multiple-linear-regression"><i class="fa fa-check"></i><b>5.1.3</b> Multiple linear regression</a></li>
<li class="chapter" data-level="5.1.4" data-path="5.1-mod-05-lm.html"><a href="5.1-mod-05-lm.html#mod-05-anova"><i class="fa fa-check"></i><b>5.1.4</b> ANOVA and ANCOVA with <code>lm()</code></a></li>
<li class="chapter" data-level="5.1.5" data-path="5.1-mod-05-lm.html"><a href="5.1-mod-05-lm.html#variations-on-linear-models"><i class="fa fa-check"></i><b>5.1.5</b> Variations on linear models</a></li>
<li class="chapter" data-level="5.1.6" data-path="5.1-mod-05-lm.html"><a href="5.1-mod-05-lm.html#example-linear-regression-workflow"><i class="fa fa-check"></i><b>5.1.6</b> Example linear regression workflow</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5.2-mod-05-basic.html"><a href="5.2-mod-05-basic.html"><i class="fa fa-check"></i><b>5.2</b> GLM basics</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="5.2-mod-05-basic.html"><a href="5.2-mod-05-basic.html#example-glms"><i class="fa fa-check"></i><b>5.2.1</b> Example GLMS</a></li>
<li class="chapter" data-level="5.2.2" data-path="5.2-mod-05-basic.html"><a href="5.2-mod-05-basic.html#glm-families"><i class="fa fa-check"></i><b>5.2.2</b> GLM families</a></li>
<li class="chapter" data-level="5.2.3" data-path="5.2-mod-05-basic.html"><a href="5.2-mod-05-basic.html#glm-link-functions"><i class="fa fa-check"></i><b>5.2.3</b> GLM link functions</a></li>
<li class="chapter" data-level="5.2.4" data-path="5.2-mod-05-basic.html"><a href="5.2-mod-05-basic.html#deviance-and-other-glm-diagnostics"><i class="fa fa-check"></i><b>5.2.4</b> Deviance and other GLM diagnostics</a></li>
<li class="chapter" data-level="5.2.5" data-path="5.2-mod-05-basic.html"><a href="5.2-mod-05-basic.html#to-pseudo-r2-or-not-to-pseudo-r2"><i class="fa fa-check"></i><b>5.2.5</b> To pseudo-<em>R</em><sup>2</sup> or not to pseudo-<em>R</em><sup>2</sup>?</a></li>
<li class="chapter" data-level="5.2.6" data-path="5.2-mod-05-basic.html"><a href="5.2-mod-05-basic.html#common-glms"><i class="fa fa-check"></i><b>5.2.6</b> Common GLMs</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="5.3-mod-05-loglin.html"><a href="5.3-mod-05-loglin.html"><i class="fa fa-check"></i><b>5.3</b> Log-linear models</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="5.3-mod-05-loglin.html"><a href="5.3-mod-05-loglin.html#mod-05-loglin-examp"><i class="fa fa-check"></i><b>5.3.1</b> Example with simulated data</a></li>
<li class="chapter" data-level="5.3.2" data-path="5.3-mod-05-loglin.html"><a href="5.3-mod-05-loglin.html#example-with-real-data"><i class="fa fa-check"></i><b>5.3.2</b> Example with real data</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="5.4-mod-05-poisson.html"><a href="5.4-mod-05-poisson.html"><i class="fa fa-check"></i><b>5.4</b> Poisson GLM for counts</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="5.4-mod-05-poisson.html"><a href="5.4-mod-05-poisson.html#example-with-simulated-data"><i class="fa fa-check"></i><b>5.4.1</b> Example with simulated data</a></li>
<li class="chapter" data-level="5.4.2" data-path="5.4-mod-05-poisson.html"><a href="5.4-mod-05-poisson.html#example-with-real-data-1"><i class="fa fa-check"></i><b>5.4.2</b> Example with real data</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="5.5-mod-05-quasi.html"><a href="5.5-mod-05-quasi.html"><i class="fa fa-check"></i><b>5.5</b> Quasi-Poisson and negative binomial GLM</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="5.5-mod-05-quasi.html"><a href="5.5-mod-05-quasi.html#example-with-simulated-data-1"><i class="fa fa-check"></i><b>5.5.1</b> Example with simulated data</a></li>
<li class="chapter" data-level="5.5.2" data-path="5.5-mod-05-quasi.html"><a href="5.5-mod-05-quasi.html#example-with-real-data-2"><i class="fa fa-check"></i><b>5.5.2</b> Example with real data</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="5.6-mod-05-logistic.html"><a href="5.6-mod-05-logistic.html"><i class="fa fa-check"></i><b>5.6</b> Logistic regression for binary outcomes</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="5.6-mod-05-logistic.html"><a href="5.6-mod-05-logistic.html#example-with-simulated-data-2"><i class="fa fa-check"></i><b>5.6.1</b> Example with simulated data</a></li>
<li class="chapter" data-level="5.6.2" data-path="5.6-mod-05-logistic.html"><a href="5.6-mod-05-logistic.html#example-with-real-data-3"><i class="fa fa-check"></i><b>5.6.2</b> Example with real data</a></li>
<li class="chapter" data-level="5.6.3" data-path="5.6-mod-05-logistic.html"><a href="5.6-mod-05-logistic.html#mod-05-auc"><i class="fa fa-check"></i><b>5.6.3</b> Logistic GLM diagnostics: AUC and ROC</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="5.7-mod-05-binom.html"><a href="5.7-mod-05-binom.html"><i class="fa fa-check"></i><b>5.7</b> Binomial GLM for proportional data</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="5.7-mod-05-binom.html"><a href="5.7-mod-05-binom.html#binomial-glm"><i class="fa fa-check"></i><b>5.7.1</b> Binomial GLM</a></li>
<li class="chapter" data-level="5.7.2" data-path="5.7-mod-05-binom.html"><a href="5.7-mod-05-binom.html#example-with-simulated-data-3"><i class="fa fa-check"></i><b>5.7.2</b> Example with simulated data</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="5.8-mod-05-gamma.html"><a href="5.8-mod-05-gamma.html"><i class="fa fa-check"></i><b>5.8</b> Gamma models for overdispersed data</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="5.8-mod-05-gamma.html"><a href="5.8-mod-05-gamma.html#example-with-simulated-data-4"><i class="fa fa-check"></i><b>5.8.1</b> Example with simulated data</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="5.9-mod-05-beyond.html"><a href="5.9-mod-05-beyond.html"><i class="fa fa-check"></i><b>5.9</b> Beyond GLM: Overview of GAM and GEE</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="5.9-mod-05-beyond.html"><a href="5.9-mod-05-beyond.html#mod-05-gam"><i class="fa fa-check"></i><b>5.9.1</b> Generalized additive models (GAM)</a></li>
<li class="chapter" data-level="5.9.2" data-path="5.9-mod-05-beyond.html"><a href="5.9-mod-05-beyond.html#mod-05-gee"><i class="fa fa-check"></i><b>5.9.2</b> Generalized estimating equations (GEE)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-mod-06.html"><a href="6-mod-06.html"><i class="fa fa-check"></i><b>6</b> Nonlinear models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="6.1-background.html"><a href="6.1-background.html"><i class="fa fa-check"></i><b>6.1</b> Background</a></li>
<li class="chapter" data-level="6.2" data-path="6.2-mod-06-intro.html"><a href="6.2-mod-06-intro.html"><i class="fa fa-check"></i><b>6.2</b> Nonlinear least squares (NLS)</a></li>
<li class="chapter" data-level="6.3" data-path="6.3-mod-06-micmen.html"><a href="6.3-mod-06-micmen.html"><i class="fa fa-check"></i><b>6.3</b> Michaelis-Menten curves</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="6.3-mod-06-micmen.html"><a href="6.3-mod-06-micmen.html#mod-06-micmen-sim"><i class="fa fa-check"></i><b>6.3.1</b> Example with simulated data</a></li>
<li class="chapter" data-level="6.3.2" data-path="6.3-mod-06-micmen.html"><a href="6.3-mod-06-micmen.html#example-with-real-data-4"><i class="fa fa-check"></i><b>6.3.2</b> Example with real data</a></li>
<li class="chapter" data-level="6.3.3" data-path="6.3-mod-06-micmen.html"><a href="6.3-mod-06-micmen.html#alternative-strategies-for-the-analysis"><i class="fa fa-check"></i><b>6.3.3</b> Alternative strategies for the analysis</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="6.4-mod-06-grow.html"><a href="6.4-mod-06-grow.html"><i class="fa fa-check"></i><b>6.4</b> Biological growth curves</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="6.4-mod-06-grow.html"><a href="6.4-mod-06-grow.html#gompertz-and-von-bertalanffy-curves"><i class="fa fa-check"></i><b>6.4.1</b> Gompertz and von Bertalanffy curves</a></li>
<li class="chapter" data-level="6.4.2" data-path="6.4-mod-06-grow.html"><a href="6.4-mod-06-grow.html#example-with-real-data-5"><i class="fa fa-check"></i><b>6.4.2</b> Example with real data</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="6.5-dose-response-curves.html"><a href="6.5-dose-response-curves.html"><i class="fa fa-check"></i><b>6.5</b> Dose response curves</a></li>
<li class="chapter" data-level="6.6" data-path="6.6-alternatives-to-nls.html"><a href="6.6-alternatives-to-nls.html"><i class="fa fa-check"></i><b>6.6</b> Alternatives to NLS</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="6.6-alternatives-to-nls.html"><a href="6.6-alternatives-to-nls.html#generalized-nonlinear-models"><i class="fa fa-check"></i><b>6.6.1</b> Generalized nonlinear models</a></li>
<li class="chapter" data-level="6.6.2" data-path="6.6-alternatives-to-nls.html"><a href="6.6-alternatives-to-nls.html#quantile-regression"><i class="fa fa-check"></i><b>6.6.2</b> Quantile regression</a></li>
<li class="chapter" data-level="6.6.3" data-path="6.6-alternatives-to-nls.html"><a href="6.6-alternatives-to-nls.html#mod-06-gam"><i class="fa fa-check"></i><b>6.6.3</b> Generalized additive models (GAM)</a></li>
<li class="chapter" data-level="6.6.4" data-path="6.6-alternatives-to-nls.html"><a href="6.6-alternatives-to-nls.html#classification-and-regression-trees-cart"><i class="fa fa-check"></i><b>6.6.4</b> Classification and regression trees (CART)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="7-mod-07.html"><a href="7-mod-07.html"><i class="fa fa-check"></i><b>7</b> Mixed models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="7.1-prelude-glm.html"><a href="7.1-prelude-glm.html"><i class="fa fa-check"></i><b>7.1</b> Prelude (GLM)</a></li>
<li class="chapter" data-level="7.2" data-path="7.2-mod-07-lmm.html"><a href="7.2-mod-07-lmm.html"><i class="fa fa-check"></i><b>7.2</b> Linear mixed models (LMM)</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="7.2-mod-07-lmm.html"><a href="7.2-mod-07-lmm.html#formal-definition-and-example"><i class="fa fa-check"></i><b>7.2.1</b> Formal definition and example</a></li>
<li class="chapter" data-level="7.2.2" data-path="7.2-mod-07-lmm.html"><a href="7.2-mod-07-lmm.html#example-with-simulated-data-5"><i class="fa fa-check"></i><b>7.2.2</b> Example with simulated data</a></li>
<li class="chapter" data-level="7.2.3" data-path="7.2-mod-07-lmm.html"><a href="7.2-mod-07-lmm.html#p-values-in-lmm"><i class="fa fa-check"></i><b>7.2.3</b> <em>P</em>-values in LMM</a></li>
<li class="chapter" data-level="7.2.4" data-path="7.2-mod-07-lmm.html"><a href="7.2-mod-07-lmm.html#specifying-random-effects"><i class="fa fa-check"></i><b>7.2.4</b> Specifying random effects</a></li>
<li class="chapter" data-level="7.2.5" data-path="7.2-mod-07-lmm.html"><a href="7.2-mod-07-lmm.html#lmm-example-with-real-data"><i class="fa fa-check"></i><b>7.2.5</b> LMM example with real data</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="7.3-mod-07-glmm.html"><a href="7.3-mod-07-glmm.html"><i class="fa fa-check"></i><b>7.3</b> Generalized linear mixed models (GLMM)</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="7.3-mod-07-glmm.html"><a href="7.3-mod-07-glmm.html#definition-1"><i class="fa fa-check"></i><b>7.3.1</b> Definition</a></li>
<li class="chapter" data-level="7.3.2" data-path="7.3-mod-07-glmm.html"><a href="7.3-mod-07-glmm.html#glmm-on-simulated-data"><i class="fa fa-check"></i><b>7.3.2</b> GLMM on simulated data</a></li>
<li class="chapter" data-level="7.3.3" data-path="7.3-mod-07-glmm.html"><a href="7.3-mod-07-glmm.html#glmm-on-real-data"><i class="fa fa-check"></i><b>7.3.3</b> GLMM on real data</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="7.4-mod-07-nlme.html"><a href="7.4-mod-07-nlme.html"><i class="fa fa-check"></i><b>7.4</b> Nonlinear mixed models (NLME)</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="7.4-mod-07-nlme.html"><a href="7.4-mod-07-nlme.html#definition-and-background"><i class="fa fa-check"></i><b>7.4.1</b> Definition and background</a></li>
<li class="chapter" data-level="7.4.2" data-path="7.4-mod-07-nlme.html"><a href="7.4-mod-07-nlme.html#nlme-on-simulated-data"><i class="fa fa-check"></i><b>7.4.2</b> NLME on simulated data</a></li>
<li class="chapter" data-level="7.4.3" data-path="7.4-mod-07-nlme.html"><a href="7.4-mod-07-nlme.html#nlme-on-real-data"><i class="fa fa-check"></i><b>7.4.3</b> NLME on real data</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="7.5-mod-07-gamm.html"><a href="7.5-mod-07-gamm.html"><i class="fa fa-check"></i><b>7.5</b> (Generalized) additive mixed models (AMM/GAMM)</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="7.5-mod-07-gamm.html"><a href="7.5-mod-07-gamm.html#example-gamm-with-real-data"><i class="fa fa-check"></i><b>7.5.1</b> Example GAMM with real data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="8-mod-08.html"><a href="8-mod-08.html"><i class="fa fa-check"></i><b>8</b> Multivariate data analysis</a>
<ul>
<li class="chapter" data-level="8.1" data-path="8.1-multivariate-data.html"><a href="8.1-multivariate-data.html"><i class="fa fa-check"></i><b>8.1</b> Multivariate data</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="8.1-multivariate-data.html"><a href="8.1-multivariate-data.html#univariate-vs.-multivariate-data"><i class="fa fa-check"></i><b>8.1.1</b> Univariate vs. multivariate data</a></li>
<li class="chapter" data-level="8.1.2" data-path="8.1-multivariate-data.html"><a href="8.1-multivariate-data.html#components-of-multivariate-data"><i class="fa fa-check"></i><b>8.1.2</b> Components of multivariate data</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="8.2-mod-08-dist.html"><a href="8.2-mod-08-dist.html"><i class="fa fa-check"></i><b>8.2</b> Distance metrics: biological (dis)similarity</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="8.2-mod-08-dist.html"><a href="8.2-mod-08-dist.html#euclidean-distance"><i class="fa fa-check"></i><b>8.2.1</b> Euclidean distance</a></li>
<li class="chapter" data-level="8.2.2" data-path="8.2-mod-08-dist.html"><a href="8.2-mod-08-dist.html#bray-curtis-and-other-distance-metrics"><i class="fa fa-check"></i><b>8.2.2</b> Bray-Curtis and other distance metrics</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="8.3-clustering.html"><a href="8.3-clustering.html"><i class="fa fa-check"></i><b>8.3</b> Clustering</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="8.3-clustering.html"><a href="8.3-clustering.html#k-means-clustering"><i class="fa fa-check"></i><b>8.3.1</b> <em>K</em>-means clustering</a></li>
<li class="chapter" data-level="8.3.2" data-path="8.3-clustering.html"><a href="8.3-clustering.html#hierarchical-agglomerative-clustering"><i class="fa fa-check"></i><b>8.3.2</b> Hierarchical agglomerative clustering</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="8.4-mod-08-sims.html"><a href="8.4-mod-08-sims.html"><i class="fa fa-check"></i><b>8.4</b> Analyzing dissimilarity</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="8.4-mod-08-sims.html"><a href="8.4-mod-08-sims.html#mantel-tests-distance-vs.-distance"><i class="fa fa-check"></i><b>8.4.1</b> Mantel tests: distance vs. distance</a></li>
<li class="chapter" data-level="8.4.2" data-path="8.4-mod-08-sims.html"><a href="8.4-mod-08-sims.html#comparing-dissimilarity-between-groups"><i class="fa fa-check"></i><b>8.4.2</b> Comparing dissimilarity between groups</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="8.5-mod-08-ord.html"><a href="8.5-mod-08-ord.html"><i class="fa fa-check"></i><b>8.5</b> Ordination</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="8.5-mod-08-ord.html"><a href="8.5-mod-08-ord.html#principal-components-analysis-pca-1"><i class="fa fa-check"></i><b>8.5.1</b> Principal components analysis (PCA)</a></li>
<li class="chapter" data-level="8.5.2" data-path="8.5-mod-08-ord.html"><a href="8.5-mod-08-ord.html#nmds-and-other-ordination-methods"><i class="fa fa-check"></i><b>8.5.2</b> NMDS and other ordination methods</a></li>
<li class="chapter" data-level="8.5.3" data-path="8.5-mod-08-ord.html"><a href="8.5-mod-08-ord.html#other-ordination-techniques"><i class="fa fa-check"></i><b>8.5.3</b> Other ordination techniques</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="9-mod-09.html"><a href="9-mod-09.html"><i class="fa fa-check"></i><b>9</b> Planning your analysis (what test?)</a>
<ul>
<li class="chapter" data-level="9.1" data-path="9.1-how-to-use-this-guide.html"><a href="9.1-how-to-use-this-guide.html"><i class="fa fa-check"></i><b>9.1</b> How to use this guide</a></li>
<li class="chapter" data-level="9.2" data-path="9.2-what-question-are-you-trying-to-answer.html"><a href="9.2-what-question-are-you-trying-to-answer.html"><i class="fa fa-check"></i><b>9.2</b> What question are you trying to answer?</a></li>
<li class="chapter" data-level="9.3" data-path="9.3-testing-for-a-difference-in-mean-or-location.html"><a href="9.3-testing-for-a-difference-in-mean-or-location.html"><i class="fa fa-check"></i><b>9.3</b> Testing for a difference in mean or location</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="9.3-testing-for-a-difference-in-mean-or-location.html"><a href="9.3-testing-for-a-difference-in-mean-or-location.html#additional-considerations"><i class="fa fa-check"></i><b>9.3.1</b> Additional considerations</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="9.4-testing-for-a-continuous-relationship-between-two-or-more-variables.html"><a href="9.4-testing-for-a-continuous-relationship-between-two-or-more-variables.html"><i class="fa fa-check"></i><b>9.4</b> Testing for a continuous relationship between two or more variables</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="9.4-testing-for-a-continuous-relationship-between-two-or-more-variables.html"><a href="9.4-testing-for-a-continuous-relationship-between-two-or-more-variables.html#additional-considerations-1"><i class="fa fa-check"></i><b>9.4.1</b> Additional considerations</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="9.5-classifying-observations.html"><a href="9.5-classifying-observations.html"><i class="fa fa-check"></i><b>9.5</b> Classifying observations</a></li>
<li class="chapter" data-level="9.6" data-path="9.6-conclusions.html"><a href="9.6-conclusions.html"><i class="fa fa-check"></i><b>9.6</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="literature-cited.html"><a href="literature-cited.html"><i class="fa fa-check"></i>Literature Cited</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied Biological Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mod-04-dists1" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Statistical distributions</h2>
<p>All data contain some element of randomness. Understanding the nature and consequences of that randomness is what motivates much of modern statistics. <strong>Probability distributions</strong> are the mathematical constructs that describe randomness in statistics. This page describes some probability distributions commonly encountered in biology (and a few that aren’t common). The emphasis here is on practical understanding of what a the distributions imply about data–not on the theoretical underpinnings or mathematical details. If you want or need a rigorous introduction to probability theory, this is probably not the right place.</p>
<div id="probability-distributions" class="section level3" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Probability distributions</h3>
<p>All data contain some element of randomness. Understanding the nature and consequences of that randomness is what motivates much of modern statistics. Consider the figures below:</p>
<p><img src="_main_files/figure-html/unnamed-chunk-319-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Both scatterplots show a linear relationship between <em>X</em> and <em>Y</em>. But what is different about the plot on the right? Variation. Both plots show the same relationship (<span class="math inline">\(Y=22+1.4X\)</span>), but they differ in that the variation about the expected value (the red line) is much greater in the right plot than the left plot. Consequently, <em>X</em> appears to explain much more variation in <em>Y</em> in the left plot than in the right plot. The next figure shows that the <strong>residual variation</strong>, or difference between the expected and observed values, is much greater in the right panel. Each of these differences between the observed value of <em>Y</em> (<span class="math inline">\(Y_i\)</span>) and the expected value of <em>Y</em> (<span class="math inline">\(E(Y_i)\)</span>), or <span class="math inline">\(Y_i-E(Y_i)\)</span>, is called a <strong>residual</strong>.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-320-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Residuals are an important part of statistical analysis for two reasons. First, most statistical models make assumptions about the distribution of residuals. Second, the total magnitude of the residuals (usually expressed as sum of squared residuals) is useful for calculating many measures of how well a model fits the data. The residuals of a statistical model are the differences between the observed values and the values predicted by the model. The residual for observation <em>i</em> in variable <em>Y</em>, <span class="math inline">\(R_i\)</span>, is calculated as:</p>
<p><span class="math display">\[R_i=Y_i-E\left[Y_i\right]\]</span></p>
<p>where <span class="math inline">\(E(Y_i)\)</span> is the <strong>expected value</strong> of <span class="math inline">\(Y_i\)</span>. This means that when an observation has a greater value than predicted, the residual is positive; similarly, when an observation is smaller than expected, the residual is negative. In many statistical methods, residuals are squared so that (1) positive and negative residuals do not cancel out; and (2) larger residuals carry more weight.</p>
<p>The figures below show the distributions of residuals for the example linear regressions above. Notice that the left dataset has a much smaller distribution of residuals than the right dataset. This is because of the much tighter fit of the left dataset’s Y values to the predicted curve.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-321-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Notice also that both distributions of residuals have a similar shape, despite the difference in width. This shape is actually very important: the <strong>normal distribution</strong>. If the residuals were not distributed this way (i.e., did not follow a normal distribution), then we would be in trouble for two reasons. First, the data were generated using a normal distribution for residuals, so something would have had to have gone wrong with our statistical test; and second, the linear regression model used to analyze the data assumes that residuals are normally distributed. If they are not, then the test is not going to produce valid estimates of statistical significance or model parameters.</p>
<p>The example above is an example of the importance of thinking about statistical distributions when analyzing data. So just what is a statistical distribution? Distributions are mathematical functions that define the probabilities of random outcomes. Here <strong>random</strong> means that there is some element of chance in what we observe. This randomness is not completely unpredictable. While the outcome of specific observations might be unknowable, we can make predictions about long run frequencies or averages of lots of observations. In other words, single observations are not predictable, but the properties of sets of observations are. Such properties might include the number of times a specific outcome occurs (e.g., number of times a flipped coin comes up heads) or some summary of observations (e.g., the mean tail length of chipmunks). Another term for this kind of randomness that follows a pattern is <strong>stochastic</strong>.</p>
<p><strong>Another example: coin flips</strong></p>
<p>Consider flipping a coin. A fair coin will come up “heads” 50% of the time, and “tails” the other 50%. If you flip a coin once, the probability of getting heads is 50%. But what about if you flip the coin 10 times? How many heads should you get? 5 is a reasonable guess. The table below shows the possible outcomes to 10 coin flips:</p>
<table>
<thead>
<tr class="header">
<th align="center">Heads</th>
<th align="center">Tails</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0</td>
<td align="center">10</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">9</td>
</tr>
<tr class="odd">
<td align="center">2</td>
<td align="center">8</td>
</tr>
<tr class="even">
<td align="center">3</td>
<td align="center">7</td>
</tr>
<tr class="odd">
<td align="center">4</td>
<td align="center">6</td>
</tr>
<tr class="even">
<td align="center">5</td>
<td align="center">5</td>
</tr>
<tr class="odd">
<td align="center">6</td>
<td align="center">4</td>
</tr>
<tr class="even">
<td align="center">7</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">8</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">9</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">10</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
<p>This table shows that 5 heads is only one of 11 possibilities! So, is the probability of 5 heads 1 in 11 (<span class="math inline">\(\approx\)</span> 0.091)? Of course not, because not all outcomes are equally likely.</p>
<p>One of the reasons statistics is so fun is that we can often use simulation to discover patterns. The R code below will simulate the effects of flipping 1 coin 10 times. Run this code a few times and see what happens.</p>
<div class="sourceCode" id="cb885"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb885-1"><a href="4.3-mod-04-dists1.html#cb885-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">1</span>,<span class="dv">10</span>,<span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## [1] 4</code></pre>
<p>A typical run of results might be something like <code>4 5 5 4 3 5 6 6 5 5 4 6</code>. We can repeat this line many times and graph the results:</p>
<div class="sourceCode" id="cb887"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb887-1"><a href="4.3-mod-04-dists1.html#cb887-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">20</span>)</span>
<span id="cb887-2"><a href="4.3-mod-04-dists1.html#cb887-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>){x[i] <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">1</span>,<span class="dv">10</span>,<span class="fl">0.5</span>)}</span>
<span id="cb887-3"><a href="4.3-mod-04-dists1.html#cb887-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">table</span>(x))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-323-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>There is actually a faster way, by requesting 20 draws of 10 flips each all at once:</p>
<div class="sourceCode" id="cb888"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb888-1"><a href="4.3-mod-04-dists1.html#cb888-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">20</span>,<span class="dv">10</span>,<span class="fl">0.5</span>)</span>
<span id="cb888-2"><a href="4.3-mod-04-dists1.html#cb888-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">table</span>(x))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-324-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Is 5 the most likely value? What about if we get a larger sample?</p>
<div class="sourceCode" id="cb889"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb889-1"><a href="4.3-mod-04-dists1.html#cb889-1" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="fu">rbinom</span>(<span class="dv">10</span>,<span class="dv">10</span>,<span class="fl">0.5</span>))</span>
<span id="cb889-2"><a href="4.3-mod-04-dists1.html#cb889-2" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="fu">rbinom</span>(<span class="dv">100</span>,<span class="dv">10</span>,<span class="fl">0.5</span>))</span>
<span id="cb889-3"><a href="4.3-mod-04-dists1.html#cb889-3" aria-hidden="true" tabindex="-1"></a>x3 <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="fu">rbinom</span>(<span class="dv">1000</span>,<span class="dv">10</span>,<span class="fl">0.5</span>))</span>
<span id="cb889-4"><a href="4.3-mod-04-dists1.html#cb889-4" aria-hidden="true" tabindex="-1"></a>x4 <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="fu">rbinom</span>(<span class="dv">10000</span>,<span class="dv">10</span>,<span class="fl">0.5</span>))</span>
<span id="cb889-5"><a href="4.3-mod-04-dists1.html#cb889-5" aria-hidden="true" tabindex="-1"></a>x5 <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="fu">rbinom</span>(<span class="dv">100000</span>,<span class="dv">10</span>,<span class="fl">0.5</span>))</span>
<span id="cb889-6"><a href="4.3-mod-04-dists1.html#cb889-6" aria-hidden="true" tabindex="-1"></a>x6 <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="fu">rbinom</span>(<span class="dv">1000000</span>,<span class="dv">10</span>,<span class="fl">0.5</span>))</span>
<span id="cb889-7"><a href="4.3-mod-04-dists1.html#cb889-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb889-8"><a href="4.3-mod-04-dists1.html#cb889-8" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))</span>
<span id="cb889-9"><a href="4.3-mod-04-dists1.html#cb889-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x1, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">main=</span><span class="st">&quot;n = 10&quot;</span>)</span>
<span id="cb889-10"><a href="4.3-mod-04-dists1.html#cb889-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x2, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">main=</span><span class="st">&quot;n = 100&quot;</span>)</span>
<span id="cb889-11"><a href="4.3-mod-04-dists1.html#cb889-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x3, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">main=</span><span class="st">&quot;n = 1000&quot;</span>)</span>
<span id="cb889-12"><a href="4.3-mod-04-dists1.html#cb889-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x4, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">main=</span><span class="st">&quot;n = 10000&quot;</span>)</span>
<span id="cb889-13"><a href="4.3-mod-04-dists1.html#cb889-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x5, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">main=</span><span class="st">&quot;n = 100000&quot;</span>)</span>
<span id="cb889-14"><a href="4.3-mod-04-dists1.html#cb889-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x6, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">main=</span><span class="st">&quot;n = 1000000&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-325-1.png" width="864" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb890"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb890-1"><a href="4.3-mod-04-dists1.html#cb890-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reset graphical parameters</span></span>
<span id="cb890-2"><a href="4.3-mod-04-dists1.html#cb890-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span></code></pre></div>
<p>You may have guessed by now that the properties of a set of coin flips—such as what number of heads to expect—are described by some kind of mathematical idea. This idea is called a statistical distribution. This particular distribution is the <strong>binomial distribution</strong>, which describes the outcome of any random process with a binary outcome. The name “binomial” is descriptive: “bi” for two, and “nomial” for names or states. Can you think of a biological situation where the binomial distribution might apply?</p>
<p>The sections below describe some distributions commonly encountered in biology, and what kinds of processes give rise to them. It is important to be able to relate biological phenomena to statistical distributions, because the underlying nature of the randomness in some process can affect how we analyze that process statistically. Note that in this class we will focus on the practical applications of these distributions, rather than their mathematical derivations.</p>
</div>
<div id="probability-distributions-in-r" class="section level3" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Probability distributions in R</h3>
<p>Every distribution supported in R has four functions associated with it: <code>r__()</code>, <code>q__()</code>, <code>d__()</code>, and <code>p__()</code> , where <code>__</code> is the name of the distribution (or an abbreviation thereof). These 4 functions calculate different values defined by the distribution:</p>
<ul>
<li><code>r__()</code> draws <strong>random numbers</strong> from the distribution.</li>
<li><code>p__()</code> calculates the <strong>cumulative distribution function (CDF)</strong> at a given value. The reverse of <code>q__()</code>.</li>
<li><code>d__()</code> calculates the <strong>probability density function (PDF)</strong>; i.e., the height of the density curve, or first derivative of the CDF.</li>
<li><code>q__()</code> calculates the <strong>value at a given quantile</strong>. The reverse of <code>p__()</code>.</li>
</ul>
<p>The figure below shows these functions in relation to the PDF and CDF for a normal distribution.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-326-1.png" width="864" style="display: block; margin: auto;" /></p>
</div>
<div id="discrete-distributions" class="section level3" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Discrete distributions</h3>
<p><strong>Discrete distributions</strong> can take on integer values only. Because of this, many discrete distributions are related in some way to <strong>count data</strong>. Count data result from, well, counting things. Count data can also describe the number of times something happened.</p>
<div id="bernoulli-distribution" class="section level4" number="4.3.3.1">
<h4><span class="header-section-number">4.3.3.1</span> Bernoulli distribution</h4>
<p>The simplest discrete distribution is the <strong>Bernoulli distribution</strong>. It describes the outcome of a single random event with probability <em>p</em>. Thus, the Bernoulli distribution takes the value 1 with probability <em>p</em> or the value 0 with probability <span class="math inline">\(q=(1-p)\)</span>. Any opportunity for the event to happen is also called a <strong>Bernoulli trial</strong>, and the process that it describes a <strong>Bernoulli process</strong>. The probability <em>p</em> can take on any value in the interval [0, 1].</p>
<p>For convenience we usually consider a Bernoulli distribution to take the value of 0 or 1, but really it could represent any binary outcome. For example, <em>yes vs. no</em>, <em>dead vs. alive</em>, <em>&lt; 3 vs. <span class="math inline">\(\ge\)</span> 3</em>, etc., are all outcomes that could be modeled as Bernoulli variables. By convention, the event that occurs with probability <em>p</em> is considered a <strong>success</strong> and has the numerical value 1; the even that occurs with probability 1-<em>p</em> is considered a <strong>failure</strong> and takes the numerical value 0. This is how Bernoulli variables are represented in most statistical packages, including R.</p>
<p>The Bernoulli distribution is rarely used on its own in an analysis<a href="literature-cited.html#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a>. Instead, it’s useful to think of the Bernoulli distribution as a special case of, or a building block of, more complicated distributions such as the binomial distribution. For example, a single observation of a binomially-distributed variable could be thought of as a Bernoulli distribution.</p>
<p>The Bernoulli distribution is a special case of the binomial distribution, and so it is accessed in R using the functions associated with the binomial. With the <code>size</code> argument set to 1, the binomial distribution <em>is</em> the Bernoulli distribution.</p>
<div class="sourceCode" id="cb891"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb891-1"><a href="4.3-mod-04-dists1.html#cb891-1" aria-hidden="true" tabindex="-1"></a><span class="co"># flip one fair coin</span></span>
<span id="cb891-2"><a href="4.3-mod-04-dists1.html#cb891-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode" id="cb893"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb893-1"><a href="4.3-mod-04-dists1.html#cb893-1" aria-hidden="true" tabindex="-1"></a><span class="co"># flip 10 fair coins</span></span>
<span id="cb893-2"><a href="4.3-mod-04-dists1.html#cb893-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">10</span>, <span class="dv">1</span>, <span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>##  [1] 1 1 0 1 1 0 1 0 1 1</code></pre>
<div class="sourceCode" id="cb895"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb895-1"><a href="4.3-mod-04-dists1.html#cb895-1" aria-hidden="true" tabindex="-1"></a><span class="co"># flip 10 coins with a 70% chance of heads</span></span>
<span id="cb895-2"><a href="4.3-mod-04-dists1.html#cb895-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">10</span>, <span class="dv">1</span>, <span class="fl">0.7</span>)</span></code></pre></div>
<pre><code>##  [1] 0 1 1 0 1 1 0 0 0 1</code></pre>
</div>
<div id="binomial-distribution" class="section level4" number="4.3.3.2">
<h4><span class="header-section-number">4.3.3.2</span> Binomial distribution</h4>
<p>The binomial distribution describes the <strong>number of successes</strong> in a set of independent Bernoulli trials. Each trial has probability of success <em>p</em>, and there are <em>n</em> trials. The values <em>n</em> and <em>p</em> are the <strong>parameters</strong> of the binomial distribution–the values that describe its behavior. The coin flipping example above is an example of a binomial distribution. Biological examples of binomial processes might be the number of fish that die in an experiment, or the number of plants that flower in a season.</p>
<p>Because it is so simple, thinking about the binomial distribution is a good warm up for learning about the characteristics of probability distributions. One of the most important characteristics is the <strong>expected value</strong> of the distribution. This is the value that most likely to occur, or the <strong>central tendency</strong> of values. There are several kinds of expected value, but they are all related to the most common or central value. The expected value, or mean, of a binomial distribution <em>X</em> is</p>
<p><span class="math display">\[E\left(X\right)=\mu=np\]</span></p>
<p>This is the answer to the question earlier about how many heads to expect if a fair coin is flipped 10 times:</p>
<p><span class="math display">\[E(heads)=n(flips)p(heads)\]</span></p>
<p>If a variable comes from a binomial process, we can make other inferences about it. For example, we can estimate its variance as:</p>
<p><span class="math display">\[Var\left(X\right)=\sigma^2=np(1-p)=npq\]</span></p>
<p>We can also estimate the probability of any number of successes <em>k</em> as:</p>
<p><span class="math display">\[P\left(k\right)=\left(\begin{matrix}n\\k\\\end{matrix}\right)p^k\left(1-p\right)^{n-k}\]</span></p>
<p>The first term (<em>n</em> over <em>k</em>) is known as the <strong>binomial coefficient</strong> and is calculated as:</p>
<p><span class="math display">\[\left(\begin{matrix}n\\k\\\end{matrix}\right)=\frac{n!}{k!\left(n-k\right)!}\]</span></p>
<p>This term represents the number of ways of seeing <em>k</em> successes in <em>n</em> trials. For example, a set of 4 trials could have 2 successes in 6 ways: HHTT, HTHT, THHT, HTTH, THTH, and TTHH.</p>
<p>When <em>n</em> is small, the binomial distribution can be quite skewed (i.e., asymmetric) because the distribution has a hard lower bound of 0. Note that the expression for <span class="math inline">\(P(k)\)</span> is what is calculated by function <code>dbinom()</code> below, and related to what is calculated by function <code>pbinom()</code>. For large <em>n</em>, the binomial distribution can be approximated by a normal distribution (see below) with mean = <em>np</em> and variance = <em>npq</em>.</p>
<div id="binomial-distribution-in-r" class="section level5" number="4.3.3.2.1">
<h5><span class="header-section-number">4.3.3.2.1</span> Binomial distribution in R</h5>
<p>R uses a family of 4 functions to work with each probability distribution. The binomial and Bernoulli distributions are accessed using the <code>_binom</code> group of functions: <code>dbinom()</code>, <code>pbinom()</code>, <code>qbinom()</code>, and <code>rbinom()</code>. Each function calculates or returns something different about the binomial distribution:</p>
<ul>
<li><code>dbinom()</code>: Calculates probability mass function at <em>x</em> for binomial distribution given <em>n</em> and <em>p</em>. Answers the question “What is the probability of <em>x</em> successes in <em>n</em> trials with probability <em>p</em>?”</li>
<li><code>pbinom()</code>: Calculates integral of the probability mass function for a binomial distribution given <em>n</em> and <em>p</em>, from 0 up to <em>x</em>. In other words, given some binomial distribution, at what quantile of that distribution should some value fall? The reverse of <code>qbinom()</code>. Answers the question “What is the probably of at least <em>x</em> successes in <em>n</em> trials with probability <em>p</em>?”</li>
<li><code>qbinom()</code>: Calculates the value at specified quantile of a binomial distribution. Essentially the reverse of <code>pbinom()</code>.</li>
<li><code>rbinom()</code>: Draws random numbers from the binomial distribution defined by <em>n</em> and <em>p</em> (or from the Bernoulli distribution if <em>n</em> = 1).</li>
</ul>
<p>Let’s explore the binomial distribution using these functions. In the plots produced in the two examples, notice how the variance of each distribution (x1, x2, etc.) depends on both n and p. The variance in these plots is shown by the width of the distribution.</p>
<div class="sourceCode" id="cb897"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb897-1"><a href="4.3-mod-04-dists1.html#cb897-1" aria-hidden="true" tabindex="-1"></a><span class="co"># N = 100, P various</span></span>
<span id="cb897-2"><a href="4.3-mod-04-dists1.html#cb897-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb897-3"><a href="4.3-mod-04-dists1.html#cb897-3" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">100</span></span>
<span id="cb897-4"><a href="4.3-mod-04-dists1.html#cb897-4" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(X, N, <span class="fl">0.2</span>)</span>
<span id="cb897-5"><a href="4.3-mod-04-dists1.html#cb897-5" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(X, N, <span class="fl">0.4</span>)</span>
<span id="cb897-6"><a href="4.3-mod-04-dists1.html#cb897-6" aria-hidden="true" tabindex="-1"></a>x3 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(X, N, <span class="fl">0.6</span>)</span>
<span id="cb897-7"><a href="4.3-mod-04-dists1.html#cb897-7" aria-hidden="true" tabindex="-1"></a>x4 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(X, N, <span class="fl">0.8</span>)</span>
<span id="cb897-8"><a href="4.3-mod-04-dists1.html#cb897-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb897-9"><a href="4.3-mod-04-dists1.html#cb897-9" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb897-10"><a href="4.3-mod-04-dists1.html#cb897-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(X, x1, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">xlab=</span><span class="st">&quot;X&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PMF&quot;</span>)</span>
<span id="cb897-11"><a href="4.3-mod-04-dists1.html#cb897-11" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(X, x2, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb897-12"><a href="4.3-mod-04-dists1.html#cb897-12" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(X, x3, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span>
<span id="cb897-13"><a href="4.3-mod-04-dists1.html#cb897-13" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(X, x4, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-328-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Here is a plot showing the effect of varying <em>n</em>.</p>
<div class="sourceCode" id="cb898"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb898-1"><a href="4.3-mod-04-dists1.html#cb898-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P = 0.5, N various</span></span>
<span id="cb898-2"><a href="4.3-mod-04-dists1.html#cb898-2" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb898-3"><a href="4.3-mod-04-dists1.html#cb898-3" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, <span class="dv">20</span>, P)</span>
<span id="cb898-4"><a href="4.3-mod-04-dists1.html#cb898-4" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, <span class="dv">40</span>, P)</span>
<span id="cb898-5"><a href="4.3-mod-04-dists1.html#cb898-5" aria-hidden="true" tabindex="-1"></a>x3 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, <span class="dv">60</span>, P)</span>
<span id="cb898-6"><a href="4.3-mod-04-dists1.html#cb898-6" aria-hidden="true" tabindex="-1"></a>x4 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, <span class="dv">80</span>, P)</span>
<span id="cb898-7"><a href="4.3-mod-04-dists1.html#cb898-7" aria-hidden="true" tabindex="-1"></a>x5 <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, <span class="dv">100</span>, P)</span>
<span id="cb898-8"><a href="4.3-mod-04-dists1.html#cb898-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb898-9"><a href="4.3-mod-04-dists1.html#cb898-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, x1, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">xlab=</span><span class="st">&quot;X&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PMF&quot;</span>)</span>
<span id="cb898-10"><a href="4.3-mod-04-dists1.html#cb898-10" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, x2, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb898-11"><a href="4.3-mod-04-dists1.html#cb898-11" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, x3, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span>
<span id="cb898-12"><a href="4.3-mod-04-dists1.html#cb898-12" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, x4, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb898-13"><a href="4.3-mod-04-dists1.html#cb898-13" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">100</span>, x5, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span><span class="st">&quot;purple&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-329-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>In these plots, the height of the points is called the <strong>probability mass function (PMF)</strong>. For discrete distributions like the binomial, the PMF of any value is the probability that the distribution takes on that value. The sum of the PMF for all integers from 0 to <em>n</em> (inclusive) must be equal to 1. You can verify this by calculating the sum of any of the vectors of densities above.</p>
<p>The function <code>pbinom()</code> sums the PMF from 0 up to and including some value. In other words, it calculates the <strong>cumulative distribution function (CDF)</strong>. This answers the question “where in the distribution is value <em>x</em>?”; put another way, “at what quantile of the distribution does value <em>x</em> lie?”. Yet another way to ask this is, “What is the probability of at least <em>X</em> successes?”.</p>
<p>Consider a binomial distribution with <em>n</em> = 10 and <em>p</em> = 0.5. What is the probability that the distribution takes a value <span class="math inline">\(\le\)</span> 7? We can calculate this as the sum of the PMF for 0 through 7.</p>
<div class="sourceCode" id="cb899"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb899-1"><a href="4.3-mod-04-dists1.html#cb899-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the distribution to see it</span></span>
<span id="cb899-2"><a href="4.3-mod-04-dists1.html#cb899-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb899-3"><a href="4.3-mod-04-dists1.html#cb899-3" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb899-4"><a href="4.3-mod-04-dists1.html#cb899-4" aria-hidden="true" tabindex="-1"></a>xd <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">10</span>, N, P)</span>
<span id="cb899-5"><a href="4.3-mod-04-dists1.html#cb899-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">10</span>, xd, <span class="at">type=</span><span class="st">&quot;h&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;X&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PMF&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-330-1.png" width="576" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb900"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb900-1"><a href="4.3-mod-04-dists1.html#cb900-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate p(x&lt;=7)</span></span>
<span id="cb900-2"><a href="4.3-mod-04-dists1.html#cb900-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(xd[<span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>]) <span class="co"># indices 1:8 correspond to values 0:7</span></span></code></pre></div>
<pre><code>## [1] 0.9453125</code></pre>
<div class="sourceCode" id="cb902"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb902-1"><a href="4.3-mod-04-dists1.html#cb902-1" aria-hidden="true" tabindex="-1"></a><span class="co"># same value:</span></span>
<span id="cb902-2"><a href="4.3-mod-04-dists1.html#cb902-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="dv">7</span>, N, P)</span></code></pre></div>
<pre><code>## [1] 0.9453125</code></pre>
<p>Or, we could want to know the probability that the distribution takes on a value &gt; 6. This would be the complement of the sum up to and including 6.</p>
<div class="sourceCode" id="cb904"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb904-1"><a href="4.3-mod-04-dists1.html#cb904-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">sum</span>(xd[<span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>])</span></code></pre></div>
<pre><code>## [1] 0.171875</code></pre>
<div class="sourceCode" id="cb906"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb906-1"><a href="4.3-mod-04-dists1.html#cb906-1" aria-hidden="true" tabindex="-1"></a><span class="co"># same value:</span></span>
<span id="cb906-2"><a href="4.3-mod-04-dists1.html#cb906-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">pbinom</span>(<span class="dv">6</span>,N,P)</span></code></pre></div>
<pre><code>## [1] 0.171875</code></pre>
<p>If the last two calculations seem familiar, that’s because this is exactly how <em>P</em> values for statistical tests are calculated (e.g., using <code>pf()</code> to get the probability from an <em>F</em> distribution for an ANOVA).</p>
<p>The function <code>qbinom()</code> is basically the reverse of function <code>pbinom()</code>. Rather than calculate the quantile at which a value falls in the distribution, <code>qbinom()</code> calculates the value at which a quantile falls. For example, what value do we expect to find at the 60th percentile of a distribution? Put another way, how many successes should 60% of experiments have, on average? The example below shows how <code>qbinom()</code> and <code>pbinom()</code> are reversible.</p>
<div class="sourceCode" id="cb908"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb908-1"><a href="4.3-mod-04-dists1.html#cb908-1" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb908-2"><a href="4.3-mod-04-dists1.html#cb908-2" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb908-3"><a href="4.3-mod-04-dists1.html#cb908-3" aria-hidden="true" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="dv">6</span>, N, P)</span></code></pre></div>
<pre><code>## [1] 0.828125</code></pre>
<div class="sourceCode" id="cb910"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb910-1"><a href="4.3-mod-04-dists1.html#cb910-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qbinom</span>(<span class="fl">0.828125</span>, N, P)</span></code></pre></div>
<pre><code>## [1] 6</code></pre>
<p>Finally, <code>rbinom()</code> draws random values from the binomial or Bernoulli distributions. The syntax of this function can be a little confusing. The first argument, <code>n</code>, is the <em>number of random draws</em> that you want. The second argument, <code>size</code>, is the <em>number of values in each draw</em>; that is, the parameter <em>n</em> of the binomial distribution. Compare these results, all with <em>p</em> = 0.5:</p>
<div class="sourceCode" id="cb912"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb912-1"><a href="4.3-mod-04-dists1.html#cb912-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1 draw of 1 trial</span></span>
<span id="cb912-2"><a href="4.3-mod-04-dists1.html#cb912-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode" id="cb914"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb914-1"><a href="4.3-mod-04-dists1.html#cb914-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1 draw of 10 trials</span></span>
<span id="cb914-2"><a href="4.3-mod-04-dists1.html#cb914-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## [1] 8</code></pre>
<div class="sourceCode" id="cb916"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb916-1"><a href="4.3-mod-04-dists1.html#cb916-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 10 draws of 1 trial per draw </span></span>
<span id="cb916-2"><a href="4.3-mod-04-dists1.html#cb916-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">10</span>, <span class="dv">1</span>, <span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>##  [1] 0 0 1 0 1 1 1 0 1 0</code></pre>
<div class="sourceCode" id="cb918"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb918-1"><a href="4.3-mod-04-dists1.html#cb918-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 10 draws of 10 trials per draw</span></span>
<span id="cb918-2"><a href="4.3-mod-04-dists1.html#cb918-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rbinom</span>(<span class="dv">10</span>, <span class="dv">10</span>, <span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>##  [1] 3 5 5 7 3 5 5 5 4 3</code></pre>
<p>Result 1 shows a Bernoulli distribution with <em>n</em> = 1. Result 2 shows a single value from a binomial distribution with <em>n</em> = 10. Result 3 shows 10 results from Bernoulli distributions. Notice that if you add up the values in result 3, you get a result like Result 2. Finally, Result 4 shows 10 draws from a binomial distribution, which itself has <em>n</em> = 10. The take home message is that the first argument to <code>rbinom()</code> is not a parameter of the binomial distribution. It is instead the number of draws from the distribution that you want. The <code>size</code> parameter is the argument that helps define the distribution.<a href="literature-cited.html#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a></p>
</div>
</div>
<div id="poisson-distribution" class="section level4" number="4.3.3.3">
<h4><span class="header-section-number">4.3.3.3</span> Poisson distribution</h4>
<p>The <strong>Poisson distribution</strong> is widely used in biology to model <strong>count data</strong>. If your data result from some sort of count or abundance per time interval, spatial extent, or unit of effort, then the Poisson distribution should be one of the first things to try in the analysis. The Poisson distribution has one parameter, <span class="math inline">\(\lambda\)</span> (“lambda”), which represents the <strong>expected number</strong> of objects counted in a sample (objects being trees, fish, cells, mutations, kangaroos, etc.). This parameter is also the <strong>variance</strong> of the distribution.</p>
<p>Like the binomial distribution, the Poisson distribution is discrete, meaning that it can only take on integer values. Unlike the binomial distribution, which is bounded by 0 and n, the Poisson distribution is bounded by 0 and <span class="math inline">\(+\infty\)</span>. However, values <span class="math inline">\(\gg \lambda\)</span> are highly improbable. If there is a well-defined upper bound for your count, then you might consider them to come from a binomial distribution instead of a Poisson. For example, if you are counting the number of fish in a toxicity trial that survive, the greatest possible count is the number of fish in the trial. On the other hand, if your counts have no <em>a priori</em> upper bound, then use the Poisson.</p>
<p>The expected value and the variance of the Poisson distribution are both <span class="math inline">\(\lambda\)</span>:</p>
<p><span class="math display">\[E\left(X\right)=Var\left(X\right)=\lambda\]</span></p>
<div id="poisson-distribution-in-r" class="section level5" number="4.3.3.3.1">
<h5><span class="header-section-number">4.3.3.3.1</span> Poisson distribution in R</h5>
<p>The Poisson distribution is accessed using the <code>_pois</code> group of functions, where the space could be <code>d</code>, <code>p</code>, <code>q</code>, or <code>r</code>. These functions calculate or returns something different:</p>
<ul>
<li><code>dpois()</code>: Calculates <strong>probability mass function (PMF)</strong> at <em>x</em> for Poisson distribution given <span class="math inline">\(\lambda\)</span>. Answers the question, “what is the probability of observing a count of <em>x</em> given <span class="math inline">\(\lambda\)</span>?”</li>
<li><code>ppois()</code>: Calculates CDF, or integral of PMF, from 0 up to <em>x</em> given <span class="math inline">\(\lambda\)</span>. In other words, given some Poisson distribution, at what quantile of that distribution should some value fall? The reverse of <code>qpois()</code>.</li>
<li><code>qpois()</code>: Calculates the value at specified quantile of a Poisson distribution. The reverse of <code>ppois()</code>.</li>
<li><code>rpois()</code>: Draws random numbers from the Poisson distribution defined by <span class="math inline">\(\lambda\)</span>.</li>
</ul>
<p>Something important to keep in mind about the Poisson distribution is that it only makes sense for discrete counts, not for continuous measurements that are rounded. For example, if you are measuring leaf lengths and round every length to the nearest mm, it might be tempting to use a Poisson distribution to analyze the data because all of the values are integers. But that would be incorrect, because leaf lengths could theoretically take on any positive value. Furthermore, treating rounded continuous values as discrete leads to the awkward issue that changing measurement units can change dimensionless statistics.</p>
<p>For example, the <strong>coefficient of variation (CV)</strong> is the ratio of a distribution’s SD to its mean. Thus, it is unitless and should be independent of units. The CV of a Poisson distribution <em>X</em> is:</p>
<p><span class="math display">\[CV\left(X\right)=\frac{\sqrt\lambda}{\lambda}\]</span></p>
<p>So, if you measured 20 leaves and found a mean length of 17 cm, the CV would thus be <span class="math inline">\(\approx\)</span> 0.242 or 24%. But if you convert the measurements to mm, the CV would be about 0.077, or 7.7%! (In fact, if you change <span class="math inline">\(\lambda\)</span> by some factor <em>a</em>, then the CV will be scaled by <span class="math inline">\(\sqrt a/a\)</span>).</p>
<p>The figure below shows the effect of varying <span class="math inline">\(\lambda\)</span> on a Poisson distribution.</p>
<div class="sourceCode" id="cb920"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb920-1"><a href="4.3-mod-04-dists1.html#cb920-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">40</span></span>
<span id="cb920-2"><a href="4.3-mod-04-dists1.html#cb920-2" aria-hidden="true" tabindex="-1"></a>lams <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>)</span>
<span id="cb920-3"><a href="4.3-mod-04-dists1.html#cb920-3" aria-hidden="true" tabindex="-1"></a>nlams <span class="ot">&lt;-</span> <span class="fu">length</span>(lams)</span>
<span id="cb920-4"><a href="4.3-mod-04-dists1.html#cb920-4" aria-hidden="true" tabindex="-1"></a>dlist <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&quot;list&quot;</span>, nlams)</span>
<span id="cb920-5"><a href="4.3-mod-04-dists1.html#cb920-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nlams){dlist[[i]] <span class="ot">&lt;-</span> <span class="fu">dpois</span>(x, lams[i])}</span>
<span id="cb920-6"><a href="4.3-mod-04-dists1.html#cb920-6" aria-hidden="true" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">rainbow</span>(nlams)</span>
<span id="cb920-7"><a href="4.3-mod-04-dists1.html#cb920-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb920-8"><a href="4.3-mod-04-dists1.html#cb920-8" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">mar=</span><span class="fu">c</span>(<span class="fl">5.1</span>, <span class="fl">5.1</span>, <span class="fl">1.1</span>, <span class="fl">1.1</span>),</span>
<span id="cb920-9"><a href="4.3-mod-04-dists1.html#cb920-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">las=</span><span class="dv">1</span>, <span class="at">bty=</span><span class="st">&quot;n&quot;</span>, <span class="at">lend=</span><span class="dv">1</span>,</span>
<span id="cb920-10"><a href="4.3-mod-04-dists1.html#cb920-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">cex.lab=</span><span class="fl">1.3</span>, <span class="at">cex.axis=</span><span class="fl">1.3</span>)</span>
<span id="cb920-11"><a href="4.3-mod-04-dists1.html#cb920-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, dlist[[<span class="dv">1</span>]], <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="fu">max</span>(<span class="fu">sapply</span>(dlist, max))),</span>
<span id="cb920-12"><a href="4.3-mod-04-dists1.html#cb920-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">type=</span><span class="st">&quot;n&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PMF&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Value (x)&quot;</span>)</span>
<span id="cb920-13"><a href="4.3-mod-04-dists1.html#cb920-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nlams){</span>
<span id="cb920-14"><a href="4.3-mod-04-dists1.html#cb920-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">points</span>(x, dlist[[i]], <span class="at">pch=</span><span class="dv">16</span>, <span class="at">cex=</span><span class="fl">1.3</span>,</span>
<span id="cb920-15"><a href="4.3-mod-04-dists1.html#cb920-15" aria-hidden="true" tabindex="-1"></a>        <span class="at">col=</span>cols[i])</span>
<span id="cb920-16"><a href="4.3-mod-04-dists1.html#cb920-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb920-17"><a href="4.3-mod-04-dists1.html#cb920-17" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend=</span>lams,</span>
<span id="cb920-18"><a href="4.3-mod-04-dists1.html#cb920-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">pch=</span><span class="dv">16</span>, <span class="at">pt.cex=</span><span class="fl">1.3</span>, <span class="at">col=</span>cols, <span class="at">bty=</span><span class="st">&quot;n&quot;</span>, <span class="at">cex=</span><span class="fl">1.3</span>,</span>
<span id="cb920-19"><a href="4.3-mod-04-dists1.html#cb920-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">title=</span><span class="fu">expression</span>(lambda))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-334-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="negative-binomial-distribution" class="section level4" number="4.3.3.4">
<h4><span class="header-section-number">4.3.3.4</span> Negative binomial distribution</h4>
<p>The <strong>negative binomial distribution</strong> has two common definitions. The original defintion is as the number of failures that occur in a series of Bernoulli trials until some predetermined number of successes is observed. For example, when flipping a fair coin, how many times should you expect to see tails before you observe 8 heads? The second definition is as an alternative to the Poisson distribution when variance is not equal to the mean<a href="literature-cited.html#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a>. This makes the negative binomial a bit of an odd duck in biological data analysis because it is defined in terms of one distribution, but used as an alternate version of another. The traditional definition of the negative binomial distribution is what names the negative binomial.</p>
<p>Biologists often use the second definition as an <strong>overdispersed</strong> alternative to the Poisson distribution. Overdispersed means that a distribution has a variance greater than expected given other parameters. This is <em>very common</em> in biological count data. For example, a bird species might have low abundance (0 to 4) at most sites in a study, but very high abundance (30 to 40) at a handful of sites. In that case using the Poisson distribution would not be appropriate because doing so would imply that the variance <span class="math inline">\(\lambda\)</span> was greater than the mean (also <span class="math inline">\(\lambda\)</span>); in other words, that <span class="math inline">\(\lambda &gt; \lambda\)</span>.</p>
<p>The version of the negative binomial that biologists use is parameterized by its mean <span class="math inline">\(\mu\)</span> and its overdispersion <em>k</em>. This definition views the negative binomial as a Poisson distribution with parameter <span class="math inline">\(\lambda\)</span>, where <span class="math inline">\(\lambda\)</span> itself is a random variable that follows a Gamma distribution (see below). For this reason, some authors refer to the negative binomial as a <strong>Gamma-Poisson mixture distribution</strong>. A mixture distribution is exactly what it sounds like: a distribution that is formed by “mixing” or combining two distributions. Usually this manifests as having one or more parameters of one distribution vary as another distribution.</p>
<p>The overdispersion parameter <em>k</em> is called <strong>size</strong> in the R functions that work with the negative binomial. Counterintuitively, the overdispersion in a negative binomial distribution gets larger as <em>k</em> becomes smaller. This is seen in the expression for the variance of a negative binomial distribution:</p>
<p><span class="math display">\[Var\left(X\right)=\mu+\frac{\mu^2}{k}\]</span></p>
<p>As <em>k</em> becomes large, the ratio <span class="math inline">\(\mu^2/k\)</span> becomes small, and thus <span class="math inline">\(Var(x)\)</span> approaches <span class="math inline">\(\mu\)</span>. This means that a negative binomial distribution with large <em>k</em> approximates a Poisson distribution. As <em>k</em> approaches 0, the ratio <span class="math inline">\(\mu^2/k\)</span> becomes larger, and thus <span class="math inline">\(Var(x)\)</span> increases to be much larger than <span class="math inline">\(\mu\)</span>.</p>
<div id="negative-binomial-distribution-in-r" class="section level5" number="4.3.3.4.1">
<h5><span class="header-section-number">4.3.3.4.1</span> Negative binomial distribution in R</h5>
<p>The negative binomial distribution is accessed using the <code>_nbinom</code> group of functions, where the space could be <code>d</code>, <code>p</code>, <code>q</code>, or <code>r</code>. These functions calculate or returns something different:</p>
<ul>
<li><code>dnbinom()</code>: Calculates PMF at <em>x</em>. Answers the question, “what is the probability of observing a count of <em>x</em>?”</li>
<li><code>pnbinom()</code>: Calculates CDF, or integral of PMF, from 0 up to <em>x</em>. In other words, given some negative binomial distribution, at what quantile of that distribution should some value fall? The reverse of <code>qnbinom()</code>.</li>
<li><code>qnbinom()</code>: Calculates the value at specified quantile of a Poisson distribution. The reverse of <code>pnbinom()</code>.</li>
<li><code>rnbinom()</code>: Draws random numbers from the negative binomial distribution.</li>
</ul>
<p>The R functions for the negative binomial distribution can work with either parameterization (waiting time or mean with overdispersion). Some of the argument names are used for both methods. If you are working with the negative binomial distribution in R you <em>need to name your arguments to make sure you get the version of the negative binomial that you want</em>.</p>
<p>The figure below show the effect of different overdispersion parameters. Notice that as <em>k</em> increases, the distribution looks more and more like a Poisson distribution with <span class="math inline">\(\lambda = 10\)</span>. As <em>k</em> gets smaller, the distribution gets more and more concentrated near 0, and more and more right-skewed.</p>
<div class="sourceCode" id="cb921"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb921-1"><a href="4.3-mod-04-dists1.html#cb921-1" aria-hidden="true" tabindex="-1"></a>xp <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">30</span></span>
<span id="cb921-2"><a href="4.3-mod-04-dists1.html#cb921-2" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">&lt;-</span> <span class="fu">dpois</span>(xp, <span class="dv">10</span>)</span>
<span id="cb921-3"><a href="4.3-mod-04-dists1.html#cb921-3" aria-hidden="true" tabindex="-1"></a>y2 <span class="ot">&lt;-</span> <span class="fu">dnbinom</span>(xp, <span class="at">size=</span><span class="fl">0.2</span>, <span class="at">mu=</span><span class="dv">10</span>)</span>
<span id="cb921-4"><a href="4.3-mod-04-dists1.html#cb921-4" aria-hidden="true" tabindex="-1"></a>y3 <span class="ot">&lt;-</span> <span class="fu">dnbinom</span>(xp, <span class="at">size=</span><span class="fl">0.5</span>, <span class="at">mu=</span><span class="dv">10</span>)</span>
<span id="cb921-5"><a href="4.3-mod-04-dists1.html#cb921-5" aria-hidden="true" tabindex="-1"></a>y4 <span class="ot">&lt;-</span> <span class="fu">dnbinom</span>(xp, <span class="at">size=</span><span class="dv">1</span>, <span class="at">mu=</span><span class="dv">10</span>)</span>
<span id="cb921-6"><a href="4.3-mod-04-dists1.html#cb921-6" aria-hidden="true" tabindex="-1"></a>y5 <span class="ot">&lt;-</span> <span class="fu">dnbinom</span>(xp, <span class="at">size=</span><span class="dv">10</span>, <span class="at">mu=</span><span class="dv">10</span>)</span>
<span id="cb921-7"><a href="4.3-mod-04-dists1.html#cb921-7" aria-hidden="true" tabindex="-1"></a>y6 <span class="ot">&lt;-</span> <span class="fu">dnbinom</span>(xp, <span class="at">size=</span><span class="dv">50</span>, <span class="at">mu=</span><span class="dv">10</span>)</span>
<span id="cb921-8"><a href="4.3-mod-04-dists1.html#cb921-8" aria-hidden="true" tabindex="-1"></a>y7 <span class="ot">&lt;-</span> <span class="fu">dnbinom</span>(xp, <span class="at">size=</span><span class="dv">100</span>, <span class="at">mu=</span><span class="dv">10</span>)</span>
<span id="cb921-9"><a href="4.3-mod-04-dists1.html#cb921-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb921-10"><a href="4.3-mod-04-dists1.html#cb921-10" aria-hidden="true" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">rainbow</span>(<span class="dv">6</span>)</span>
<span id="cb921-11"><a href="4.3-mod-04-dists1.html#cb921-11" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">mar=</span><span class="fu">c</span>(<span class="fl">5.1</span>, <span class="fl">5.1</span>, <span class="fl">1.1</span>, <span class="fl">1.1</span>),</span>
<span id="cb921-12"><a href="4.3-mod-04-dists1.html#cb921-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">las=</span><span class="dv">1</span>, <span class="at">bty=</span><span class="st">&quot;n&quot;</span>, <span class="at">lend=</span><span class="dv">1</span>,</span>
<span id="cb921-13"><a href="4.3-mod-04-dists1.html#cb921-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">cex.lab=</span><span class="fl">1.3</span>, <span class="at">cex.axis=</span><span class="fl">1.3</span>)</span>
<span id="cb921-14"><a href="4.3-mod-04-dists1.html#cb921-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(xp, y1, <span class="at">pch=</span><span class="dv">17</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="at">xlab=</span><span class="st">&quot;X&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PMF&quot;</span>)</span>
<span id="cb921-15"><a href="4.3-mod-04-dists1.html#cb921-15" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(xp, y2, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>cols[<span class="dv">1</span>])</span>
<span id="cb921-16"><a href="4.3-mod-04-dists1.html#cb921-16" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(xp, y3, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>cols[<span class="dv">2</span>])</span>
<span id="cb921-17"><a href="4.3-mod-04-dists1.html#cb921-17" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(xp, y4, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>cols[<span class="dv">3</span>])</span>
<span id="cb921-18"><a href="4.3-mod-04-dists1.html#cb921-18" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(xp, y5, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>cols[<span class="dv">4</span>])</span>
<span id="cb921-19"><a href="4.3-mod-04-dists1.html#cb921-19" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(xp, y6, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>cols[<span class="dv">5</span>])</span>
<span id="cb921-20"><a href="4.3-mod-04-dists1.html#cb921-20" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(xp, y7, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span>cols[<span class="dv">6</span>])</span>
<span id="cb921-21"><a href="4.3-mod-04-dists1.html#cb921-21" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, </span>
<span id="cb921-22"><a href="4.3-mod-04-dists1.html#cb921-22" aria-hidden="true" tabindex="-1"></a><span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;Poisson&quot;</span>, <span class="st">&quot;k=0.2&quot;</span>, <span class="st">&quot;k=0.5&quot;</span>, <span class="st">&quot;k=1&quot;</span>, <span class="st">&quot;k=10&quot;</span>, </span>
<span id="cb921-23"><a href="4.3-mod-04-dists1.html#cb921-23" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;k=50&quot;</span>, <span class="st">&quot;k=100&quot;</span>),</span>
<span id="cb921-24"><a href="4.3-mod-04-dists1.html#cb921-24" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch=</span><span class="fu">c</span>(<span class="dv">17</span>, <span class="fu">rep</span>(<span class="dv">16</span>,<span class="dv">6</span>)), <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;black&quot;</span>, cols))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-335-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="geometric-distribution" class="section level4" number="4.3.3.5">
<h4><span class="header-section-number">4.3.3.5</span> Geometric distribution</h4>
<p>The <strong>geometric distribution</strong> describes the number of Bernoulli trials that are seen before observing a single failure. It is thus related to the binomial and negative binomial. In fact, the geometric distribution is a special case of the negative binomial, with the number of successes = 1.</p>
<p>The geometric distribution arises in biology when modeling waiting times or life spans. For example, the number of years that an individual organism lives, if it has a constant probability of surviving each year. Or, the number of generations until a mutation in a cell line occurs, if mutations occur at a constant rate per generation.</p>
<p>Imagine a fish that has a 5% chance of dying each year; i.e., a 95% annual survival rate. How long should we expect this fish to live, on average?</p>
<div class="sourceCode" id="cb922"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb922-1"><a href="4.3-mod-04-dists1.html#cb922-1" aria-hidden="true" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fl">0.05</span></span>
<span id="cb922-2"><a href="4.3-mod-04-dists1.html#cb922-2" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">100</span></span>
<span id="cb922-3"><a href="4.3-mod-04-dists1.html#cb922-3" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">dgeom</span>(X, P)</span>
<span id="cb922-4"><a href="4.3-mod-04-dists1.html#cb922-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(X,Y)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-336-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>The figure shows that the probability of living to any given age falls off quickly at first, then more gradually as time goes on. What is the mean life expectancy?</p>
<div class="sourceCode" id="cb923"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb923-1"><a href="4.3-mod-04-dists1.html#cb923-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qgeom</span>(<span class="fl">0.5</span>, P)</span></code></pre></div>
<pre><code>## [1] 13</code></pre>
<p>What range of life expectancies can we expect for 95% of the population?</p>
<div class="sourceCode" id="cb925"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb925-1"><a href="4.3-mod-04-dists1.html#cb925-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qgeom</span>(<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>), P)</span></code></pre></div>
<pre><code>## [1]  0 71</code></pre>
<p>That’s quite a wide range! What is the probability that a fish lives to be at least 30 years old? 40 years old?</p>
<div class="sourceCode" id="cb927"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb927-1"><a href="4.3-mod-04-dists1.html#cb927-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">pgeom</span>(<span class="dv">30</span>, P)</span></code></pre></div>
<pre><code>## [1] 0.2039068</code></pre>
<div class="sourceCode" id="cb929"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb929-1"><a href="4.3-mod-04-dists1.html#cb929-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">pgeom</span>(<span class="dv">40</span>, P)</span></code></pre></div>
<pre><code>## [1] 0.1220865</code></pre>
</div>
<div id="beta-binomial-distribution" class="section level4" number="4.3.3.6">
<h4><span class="header-section-number">4.3.3.6</span> Beta-binomial distribution</h4>
<p>The <strong>beta-binomial distribution</strong> is a mixture that allows for modeling binomial processes with more variation than would be expected from a garden variety binomial distribution. The beta-binomial is a binomial distribution, but with the probability parameter <em>p</em> itself varying randomly according to a beta distribution (see below). This is similar to how a negative binomial distribution can be defined as a Poisson distribution mixed with a gamma distribution (with the Poisson <span class="math inline">\(\lambda\)</span> varying as a gamma variable).</p>
<p>A beta-binomial distribution <em>X</em> is given by:</p>
<p><span class="math display">\[X \sim Bin\left(n,\ p\right)\]</span></p>
<p><span class="math display">\[p \sim Beta\left(\alpha,\beta\right)\]</span></p>
<p>The parameters of the beta distribution are positive shape parameters (see below). The parameters of the beta part of the beta-binomial distribution can make the binomial part overdispersed relative to an ordinary binomial distribution.</p>
</div>
<div id="multinomial-distribution" class="section level4" number="4.3.3.7">
<h4><span class="header-section-number">4.3.3.7</span> Multinomial distribution</h4>
<p>The <strong>multinomial distribution</strong> is a generalization of the binomial distribution to cases with more than 2 possible outcomes. For example, rolling a 6-sided die many times would yield a distribution of outcomes (1, 2, 3, 4, 5, or 6) described by the multinomial distribution. The multinomial distribution is parameterized by the number of possible outcomes <em>k</em>, the number of trials <em>n</em>, and the probabilities of each outcome <span class="math inline">\(p_1, \ldots, p_k\)</span>. The probabilities must sum to 1.</p>
<p>There are some special cases of the multinomial distribution:</p>
<ul>
<li>When <em>k</em> = 2 and <em>n</em> = 1, the multinomial distribution reduces to the Bernoulli distribution</li>
<li>When <em>k</em> = 2 and <em>n</em> &gt; 1, the multinomial distribution reduces to the binomial distribution</li>
<li>When <em>k</em> &gt; 2 and <em>n</em> = 1, the multinomial distribution is the categorical distribution.</li>
</ul>
<p>The example below shows how to work with the multinomial distribution in R.</p>
<div class="sourceCode" id="cb931"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb931-1"><a href="4.3-mod-04-dists1.html#cb931-1" aria-hidden="true" tabindex="-1"></a><span class="co"># define 2 different sets of probabilities for</span></span>
<span id="cb931-2"><a href="4.3-mod-04-dists1.html#cb931-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 5 different outcomes</span></span>
<span id="cb931-3"><a href="4.3-mod-04-dists1.html#cb931-3" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.1</span>, <span class="fl">0.1</span>, <span class="fl">0.4</span>)</span>
<span id="cb931-4"><a href="4.3-mod-04-dists1.html#cb931-4" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.4</span>, <span class="fl">0.2</span>, <span class="fl">0.1</span>)</span>
<span id="cb931-5"><a href="4.3-mod-04-dists1.html#cb931-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb931-6"><a href="4.3-mod-04-dists1.html#cb931-6" aria-hidden="true" tabindex="-1"></a><span class="co"># sample from the multinomial distribution</span></span>
<span id="cb931-7"><a href="4.3-mod-04-dists1.html#cb931-7" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="fl">1e3</span></span>
<span id="cb931-8"><a href="4.3-mod-04-dists1.html#cb931-8" aria-hidden="true" tabindex="-1"></a>r1 <span class="ot">&lt;-</span> <span class="fu">rmultinom</span>(N, N, <span class="at">prob=</span>p1)</span>
<span id="cb931-9"><a href="4.3-mod-04-dists1.html#cb931-9" aria-hidden="true" tabindex="-1"></a>r2 <span class="ot">&lt;-</span> <span class="fu">rmultinom</span>(N, N, <span class="at">prob=</span>p2)</span>
<span id="cb931-10"><a href="4.3-mod-04-dists1.html#cb931-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb931-11"><a href="4.3-mod-04-dists1.html#cb931-11" aria-hidden="true" tabindex="-1"></a><span class="co"># summarize by outcome</span></span>
<span id="cb931-12"><a href="4.3-mod-04-dists1.html#cb931-12" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">&lt;-</span> <span class="fu">apply</span>(r1, <span class="dv">1</span>, mean)</span>
<span id="cb931-13"><a href="4.3-mod-04-dists1.html#cb931-13" aria-hidden="true" tabindex="-1"></a>y2 <span class="ot">&lt;-</span> <span class="fu">apply</span>(r2, <span class="dv">1</span>, mean)</span>
<span id="cb931-14"><a href="4.3-mod-04-dists1.html#cb931-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb931-15"><a href="4.3-mod-04-dists1.html#cb931-15" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the results</span></span>
<span id="cb931-16"><a href="4.3-mod-04-dists1.html#cb931-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, y1, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">xlab=</span><span class="st">&quot;X&quot;</span>, </span>
<span id="cb931-17"><a href="4.3-mod-04-dists1.html#cb931-17" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">&quot;Frequency&quot;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1000</span>))</span>
<span id="cb931-18"><a href="4.3-mod-04-dists1.html#cb931-18" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, y2, <span class="at">pch=</span><span class="dv">16</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-340-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="continuous-distributions" class="section level3" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> Continuous distributions</h3>
<p>A <strong>continuous distribution</strong> can take an infinite number of values. These values can come from an interval on the real line, or the entire real line. Contrast this to a discrete distribution, which can only take on integer values. Computing the probability of any possible outcome of a discrete distribution is relative straightforward because there are a limited number of outcomes. For example, a binomial distribution with <em>n</em> = 10 and <em>p</em> = 0.5 has only 11 possible outcomes (0, 1, 2, …, 9, or 10). The probabilities <span class="math inline">\(p(0)\)</span>, <span class="math inline">\(p(1)\)</span>, …, <span class="math inline">\(p(10)\)</span> must all sum to 1. The probability mass function (PMF) of the binomial distribution at any value is the probability of that value occurring.</p>
<p>This leads to an interesting question. How could we calculate the probability of any given outcome of a continuous distribution? If the probabilities of each individual value must all sum to 1, and there are infinitely many possible values, then doesn’t the probability of each value equal 0? If the probability of every outcome is 0, how can the distribution take on any value?</p>
<p>To resolve this apparent contradiction, we have to take a step back and think about what distributions really mean. The first step is to realize that even if any single value has probability 0, an <em>interval</em> of values can have a non-zero probability. After all, the entire domain of a distribution has probability 1 (by definition). We can define some interval in the domain that covers half of the total probability, or one-quarter, or any arbitrary fraction. This means that for any value <em>x</em> in a distribution <em>X</em> (note lower case vs. upper case) we can calculate the probability of observing a value <span class="math inline">\(\le x\)</span>. The figure below shows this:</p>
<p><img src="_main_files/figure-html/unnamed-chunk-341-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>The <em>y</em>-axis in the figure, <span class="math inline">\(P\left(X \le x\right)\)</span>, is called the <strong>cumulative distribution function (CDF)</strong>. This name derives from the fact that the CDF of some value <em>x</em> gives the cumulative probability of all values up to and including <em>x</em>. The CDF is sometimes labeled “<strong>F(x)</strong>” (note the capitalized F). Another way to interpret this is that a value <em>x</em> lies at the <em>CDF(x)</em> quantile of a distribution. For example, if <em>CDF(x)</em> = 0.4, then <em>x</em> lies at the 0.4 quantile or 40th percentile of the distribution. Critically, this means that 40% of the total probability of the distribution lies at or to the left of <em>x</em>.</p>
<p>Just as with discrete distributions, the relative probability of any given value in a continuous distribution is given by the rate at which the CDF changes at that value. For discrete distributions this relative probability also happens to be the absolute probability (because <em>dx</em> = 1 in the expression below). For continuous distributions, this probability is relative. The relative probability of a value in a continuous distribution is given by the <strong>probability density function (PDF)</strong>. The PDF, <strong><em>f(x)</em></strong>, is the derivative of the CDF:</p>
<p><span class="math display">\[f\left(x\right)=\frac{dF(x)}{dx}\]</span></p>
<p>This also means that the CDF is the integral of the PDF, according to the fundamental theorem of calculus:</p>
<p><span class="math display">\[F\left(x\right)=\int_{-\infty}^{x}{f\left(x\right)\ dx}\]</span></p>
<p>This might be easier to see with an example. The plots below show the PDF and CDF of a standard normal distribution (see below). Because the normal is unbounded, its PDF and CDF have the domain [<span class="math inline">\(-\infty\)</span>, <span class="math inline">\(+\infty\)</span>], but we usually truncate the plot to a range that covers most of the CDF.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-342-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>On the left, notice that the PDF peaks near <em>x</em> = 0 and tapers off quickly to either side. On the right, the slope of the CDF is greatest at <em>x</em> = 0. The value of the PDF at <em>x</em> = 0, about 0.4, is neither the probability of observing <em>x</em> = 0 nor the probability of observing <em>x</em> <span class="math inline">\(\le\)</span> 0, which is 0.5. The value <span class="math inline">\(f(0) = 0.4\)</span> is the rate of change in <span class="math inline">\(F(X)\)</span> at <em>x</em> = 0.</p>
<div id="uniform-distribution" class="section level4" number="4.3.4.1">
<h4><span class="header-section-number">4.3.4.1</span> Uniform distribution</h4>
<p>The simplest continuous distribution is the <strong>uniform distribution</strong>. The uniform distribution is parameterized by its upper and lower bounds, usually called <em>a</em> and <em>b</em>, respectively. All values of a uniform distribution in the interval [<em>a</em>, <em>b</em>] are equally likely, and all values outside [<em>a</em>, <em>b</em>] have probability 0. The figure below shows the PDF of 3 different uniform distributions.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-343-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Notice how each distribution has a flat PDF, but that the value of the PDF decreases as the width of the uniform distribution increases. Given what you learned above about the relationship between the CDF and the PDF, can you work out why this is?</p>
<p>Like the normal distribution, there is a standard uniform distribution that is frequently used. The standard uniform is defined as <em>Uniform(0, 1)</em>: a uniform distribution in the interval [0, 1]. The uniform distribution can sometimes be abbreviated as <em>U(a,b)</em> or <em>Unif(a,b)</em> instead of <em>Uniform(a,b)</em>.</p>
<p>The mean of a uniform distribution is just the mean of its limits:</p>
<p><span class="math display">\[\mu\left(X\right)=\frac{a+b}{2}\]</span></p>
<p>The variance of a uniform distribution is:</p>
<p><span class="math display">\[\sigma^2\left(X\right)=\frac{{(b-a)}^2}{12}\]</span></p>
<div id="uniform-distribution-in-r" class="section level5" number="4.3.4.1.1">
<h5><span class="header-section-number">4.3.4.1.1</span> Uniform distribution in R</h5>
<p>The uniform distribution is accessed using the <code>_unif</code> group of functions, where the space could be <code>d</code>, <code>p</code>, <code>q</code>, or <code>r</code>. These functions calculate or returns something different:</p>
<ul>
<li><code>dunif()</code>: Calculates probability density function (PDF) at <em>x</em>.</li>
<li><code>punif()</code>: Calculates CDF, from <em>a</em> up to <em>x</em>. Answers the question, “at what quantile of the distribution should some value fall?”. The reverse of <code>qunif()</code>.</li>
<li><code>qunif()</code>: Calculates the value at a specified quantile or quantiles. The reverse of <code>punif()</code>.</li>
<li><code>runif()</code>: Draws random numbers from the uniform distribution.</li>
</ul>
<p>The help files for many R functions include a call to <code>runif()</code> to generate example values from the uniform distribution. This can be confusing to new users, who might interpret “runif” as “run if” (i.e., some sort of conditional statement).</p>
<p>One extremely useful application is the generation of values from the standard uniform distribution:</p>
<div class="sourceCode" id="cb932"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb932-1"><a href="4.3-mod-04-dists1.html#cb932-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">20</span>)</span></code></pre></div>
<p>The line above generates 20 numbers from the interval [0, 1]. These values can be used as probabilities or values of a CDF.</p>
<p>If you want to implement a new probability distribution in R, you can use <code>runif()</code> followed by the <code>q__()</code> function that you define for your new distribution to implement a random number generator for it. The example below shows how to implement a “truncated normal” distribution:</p>
<div class="sourceCode" id="cb933"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb933-1"><a href="4.3-mod-04-dists1.html#cb933-1" aria-hidden="true" tabindex="-1"></a>rtnorm <span class="ot">&lt;-</span> <span class="cf">function</span>(N, lower, upper, mu, sigma){</span>
<span id="cb933-2"><a href="4.3-mod-04-dists1.html#cb933-2" aria-hidden="true" tabindex="-1"></a>    a <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(lower, mu, sigma)</span>
<span id="cb933-3"><a href="4.3-mod-04-dists1.html#cb933-3" aria-hidden="true" tabindex="-1"></a>    b <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(upper, mu, sigma)</span>
<span id="cb933-4"><a href="4.3-mod-04-dists1.html#cb933-4" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">runif</span>(N, a, b)</span>
<span id="cb933-5"><a href="4.3-mod-04-dists1.html#cb933-5" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(x, mu, sigma)</span>
<span id="cb933-6"><a href="4.3-mod-04-dists1.html#cb933-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(y)</span>
<span id="cb933-7"><a href="4.3-mod-04-dists1.html#cb933-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb933-8"><a href="4.3-mod-04-dists1.html#cb933-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb933-9"><a href="4.3-mod-04-dists1.html#cb933-9" aria-hidden="true" tabindex="-1"></a>use.n <span class="ot">&lt;-</span> <span class="fl">1e3</span></span>
<span id="cb933-10"><a href="4.3-mod-04-dists1.html#cb933-10" aria-hidden="true" tabindex="-1"></a>use.mu <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb933-11"><a href="4.3-mod-04-dists1.html#cb933-11" aria-hidden="true" tabindex="-1"></a>use.sd <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb933-12"><a href="4.3-mod-04-dists1.html#cb933-12" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(use.n, use.mu, use.sd)</span>
<span id="cb933-13"><a href="4.3-mod-04-dists1.html#cb933-13" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">rtnorm</span>(use.n, <span class="dv">8</span>, <span class="dv">12</span>, use.mu, use.sd)</span>
<span id="cb933-14"><a href="4.3-mod-04-dists1.html#cb933-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb933-15"><a href="4.3-mod-04-dists1.html#cb933-15" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb933-16"><a href="4.3-mod-04-dists1.html#cb933-16" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(x1, <span class="at">main=</span><span class="st">&quot;Normal&quot;</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">20</span>))</span>
<span id="cb933-17"><a href="4.3-mod-04-dists1.html#cb933-17" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(x2, <span class="at">main=</span><span class="st">&quot;Truncated normal&quot;</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">20</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-345-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="mod-04-norm" class="section level4" number="4.3.4.2">
<h4><span class="header-section-number">4.3.4.2</span> Normal distribution</h4>
<p>The <strong>normal distribution</strong> is probably the most important distribution in statistics. Many natural processes result in normal distributions. Consequently, most classical statistical methods (e.g., <em>t</em>-tests, ANOVA, and linear models) assume that data come from a normal distribution. The normal distribution is also sometimes called the <strong>Gaussian</strong> distribution because of the work of mathematician Carl Friedrich Gauss, although he did not discover it. The normal distribution is also sometimes called the bell curve because of the shape of its PDF. This term should be avoided because other probability distributions also have a bell shape, and because normal distributions are not always bell-shaped. The figure below shows several normal distributions with different means (<span class="math inline">\(\mu\)</span>) and standard deviations (SD, or <span class="math inline">\(\sigma\)</span>).</p>
<p><img src="_main_files/figure-html/unnamed-chunk-346-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Many phenomena result in normal distributions because of the <strong>Central Limit Theorem (CLT)</strong>. The CLT states that under certain conditions the sum of many random variables will approximate a normal distribution. The main condition is that the random variables will be independent and identically distributed (often abbreviated “<em>i.i.d.</em>”). In other words, the values do not depend on each other, and they all come from the same kind of distribution. The exact distribution does not matter. The example below uses the uniform distribution. The CLT also works with the mean of the random variables instead of the sum, because mean is just the sum scaled by sample size.</p>
<div class="sourceCode" id="cb934"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb934-1"><a href="4.3-mod-04-dists1.html#cb934-1" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="fl">1e4</span></span>
<span id="cb934-2"><a href="4.3-mod-04-dists1.html#cb934-2" aria-hidden="true" tabindex="-1"></a>xvec <span class="ot">&lt;-</span> <span class="fu">numeric</span>(N)</span>
<span id="cb934-3"><a href="4.3-mod-04-dists1.html#cb934-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N){xvec[i] <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">runif</span>(<span class="dv">10</span>))}</span>
<span id="cb934-4"><a href="4.3-mod-04-dists1.html#cb934-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(xvec)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-347-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>It should be noted that just because a sample size is large does not mean that it is normal. For example, the R commands below produce distributions <code>x1</code> and <code>x2</code> that are in no way normal.</p>
<div class="sourceCode" id="cb935"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb935-1"><a href="4.3-mod-04-dists1.html#cb935-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb935-2"><a href="4.3-mod-04-dists1.html#cb935-2" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="fl">1e5</span>)</span>
<span id="cb935-3"><a href="4.3-mod-04-dists1.html#cb935-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(x1)</span>
<span id="cb935-4"><a href="4.3-mod-04-dists1.html#cb935-4" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="fl">1e5</span>), <span class="fu">rnorm</span>(<span class="fl">1e5</span>, <span class="dv">10</span>, <span class="dv">2</span>))</span>
<span id="cb935-5"><a href="4.3-mod-04-dists1.html#cb935-5" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(x2)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-348-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>The normal distribution is parameterized by its mean (<span class="math inline">\(\mu\)</span>, or “mu”) and its variance (<span class="math inline">\(\sigma^2\)</span>, “sigma squared”). Some people prefer to use the mean and standard deviation (<span class="math inline">\(\sigma\)</span>, “sigma”). This is fine because, as the symbols imply, the SD is simply the square root of the variance. Just pay attention to the notation being used. Using <span class="math inline">\(\sigma\)</span> instead of <span class="math inline">\(\sigma^2\)</span> can be convenient because <span class="math inline">\(\sigma\)</span> is in the same units as <span class="math inline">\(\mu\)</span>.</p>
<p>The <strong>standard normal distribution</strong> has <span class="math inline">\(\mu\)</span> = 0 and <span class="math inline">\(\sigma\)</span> = 1. This is often written as <em>N(0,1)</em>. These parameters are the defaults in the R functions that work with the normal distribution.</p>
<div id="normal-distribution-in-r" class="section level5" number="4.3.4.2.1">
<h5><span class="header-section-number">4.3.4.2.1</span> Normal distribution in R</h5>
<p>The normal distribution is accessed using the <code>_norm</code> group of functions, where the space could be <code>d</code>, <code>p</code>, <code>q</code>, or <code>r</code>. These functions calculate or returns something different:</p>
<ul>
<li><code>dnorm()</code>: Calculates probability density function (PDF) at <em>x</em>.</li>
<li><code>pnorm()</code>: Calculates CDF, from <span class="math inline">\(-\infty\)</span> up to <em>x</em>. Answers the question, “at what quantile of the distribution should some value fall?”. The reverse of <code>qnorm()</code>.</li>
<li><code>qnorm()</code>: Calculates the value at a specified quantile or quantiles. The reverse of <code>pnorm()</code>.</li>
<li><code>rnorm()</code>: Draws random numbers from the normal distribution.</li>
</ul>
<p>The normal distribution in R is parameterized by the mean (argument <code>mean</code>) and the SD, not the variance (argument <code>sd</code>).
The figure generated below shows the effect of increasing the SD on the shape of a distribution. Greater variance (i.e., greater SD) means that the distribution is more spread out.</p>
<div class="sourceCode" id="cb936"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb936-1"><a href="4.3-mod-04-dists1.html#cb936-1" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb936-2"><a href="4.3-mod-04-dists1.html#cb936-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="at">by=</span><span class="fl">0.1</span>)</span>
<span id="cb936-3"><a href="4.3-mod-04-dists1.html#cb936-3" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x, mu, <span class="dv">2</span>)</span>
<span id="cb936-4"><a href="4.3-mod-04-dists1.html#cb936-4" aria-hidden="true" tabindex="-1"></a>y2 <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x, mu, <span class="dv">5</span>)</span>
<span id="cb936-5"><a href="4.3-mod-04-dists1.html#cb936-5" aria-hidden="true" tabindex="-1"></a>y3 <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x, mu, <span class="dv">10</span>)</span>
<span id="cb936-6"><a href="4.3-mod-04-dists1.html#cb936-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb936-7"><a href="4.3-mod-04-dists1.html#cb936-7" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb936-8"><a href="4.3-mod-04-dists1.html#cb936-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y1, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">xlab=</span><span class="st">&quot;X&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PDF&quot;</span>)</span>
<span id="cb936-9"><a href="4.3-mod-04-dists1.html#cb936-9" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, y2, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb936-10"><a href="4.3-mod-04-dists1.html#cb936-10" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x, y3, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span>
<span id="cb936-11"><a href="4.3-mod-04-dists1.html#cb936-11" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="fu">expression</span>(sigma<span class="sc">==</span><span class="dv">2</span>), <span class="fu">expression</span>(sigma<span class="sc">==</span><span class="dv">5</span>), <span class="fu">expression</span>(sigma<span class="sc">==</span><span class="dv">10</span>)),</span>
<span id="cb936-12"><a href="4.3-mod-04-dists1.html#cb936-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-349-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>The normal distribution has several useful properties. Generally, the mean and median are the same (if the distribution is not skewed). Approximately 68% of values fall within 1 SD of the mean, 95% of values fall within about 2 SD of the mean (technically 1.9599 SD, or <code>qnorm(0.975)</code>), and 99% of values fall within about 3 SD of the mean. So, deviations of &gt;3 SD are very rare and may signify outliers. The number of SD a value falls away from the mean is sometimes referred to as a <strong><em>z</em>-score</strong> or a <strong>sigma</strong>. <em>Z</em>-scores are calculated as:</p>
<p><span class="math display">\[z\left(x\right)=\frac{x-\mu}{\sigma}\]</span></p>
<p>Where <em>x</em> is the value, <span class="math inline">\(\mu\)</span> is the mean, and <span class="math inline">\(\sigma\)</span> is the SD.</p>
<p><em>Z</em>-scores are sometimes used when comparing variables that are normally distributed, but on very different scales. Converting the raw values to their <em>z</em>-scores is referred to as <strong>standardizing</strong> them. Standardized values are sometimes used in regression analyses in place of raw values. Many ordination methods such as principal components analysis (PCA) standardize variables automatically. <em>Z</em>-scores (or standardized values) are calculated in R using the <code>scale()</code> function:</p>
<div class="sourceCode" id="cb937"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb937-1"><a href="4.3-mod-04-dists1.html#cb937-1" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">100</span>, <span class="dv">40</span>)</span>
<span id="cb937-2"><a href="4.3-mod-04-dists1.html#cb937-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb937-3"><a href="4.3-mod-04-dists1.html#cb937-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(x1)</span>
<span id="cb937-4"><a href="4.3-mod-04-dists1.html#cb937-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">scale</span>(x1))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-350-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="lognormal-distribution" class="section level4" number="4.3.4.3">
<h4><span class="header-section-number">4.3.4.3</span> Lognormal distribution</h4>
<p>The <strong>lognormal distribution (a.k.a.: log-normal)</strong> is, as the name implies, a distribution that is <em>normal on a logarithmic scale</em>. By convention the <strong>natural log</strong> (log<sub><em>e</em></sub>, ln, or just log) is used although you can use log<sub>10</sub> if you pay attention to what you are doing and are explicit in your write-up<a href="literature-cited.html#fn37" class="footnote-ref" id="fnref37"><sup>37</sup></a>. The functions in R that deal with the lognormal use the natural log<a href="literature-cited.html#fn38" class="footnote-ref" id="fnref38"><sup>38</sup></a>.</p>
<p>The lognormal distribution arises in two ways. First, it comes about from processes where quantities are <em>multiplied together rather than added</em>. For example, growth of organisms or population sizes. This is because of the way that exponentiation relates multiplication and addition. This relationship to multiplication also means that the lognormal distribution results from a version of the CLT where values are multiplied, not added. The example below shows this.</p>
<div class="sourceCode" id="cb938"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb938-1"><a href="4.3-mod-04-dists1.html#cb938-1" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="fl">1e4</span></span>
<span id="cb938-2"><a href="4.3-mod-04-dists1.html#cb938-2" aria-hidden="true" tabindex="-1"></a>xvec <span class="ot">&lt;-</span> <span class="fu">numeric</span>(N)</span>
<span id="cb938-3"><a href="4.3-mod-04-dists1.html#cb938-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N){xvec[i] <span class="ot">&lt;-</span> <span class="fu">prod</span>(<span class="fu">runif</span>(<span class="dv">10</span>))}</span>
<span id="cb938-4"><a href="4.3-mod-04-dists1.html#cb938-4" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb938-5"><a href="4.3-mod-04-dists1.html#cb938-5" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(xvec)</span>
<span id="cb938-6"><a href="4.3-mod-04-dists1.html#cb938-6" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">log</span>(xvec))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-351-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>The second way that the lognormal arises is more phenomenological (i.e., descriptive). Processes that result in positive values with a long tail (mostly small values with few very large values) or positive values with a variance much larger than the mean. The latter case can also be well described by the gamma distribution. The classic example of a lognormal distribution is personal income: most populations will have mostly small values, but with a small proportion of extreme outliers.</p>
<p>The lognormal distribution is parameterized by a mean (<span class="math inline">\(\mu\)</span>) and variance (<span class="math inline">\(\sigma^2\)</span>), or by a mean and standard deviation (<span class="math inline">\(\sigma\)</span>). These parameters are on the logarithmic scale. The figure below shows various lognormal distributions with <span class="math inline">\(\mu\)</span> = 3 and different SD on a logarithmic scale (left) and a linear scale.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-352-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>The figures show the effect that variance can have on the lognormal distribution. When the variance on the log scale is &lt;<span class="math inline">\(\mu\)</span>, the distribution is approximately normal on the log scale. As the variance gets larger, the distribution gets more and more right-skewed. Right-skewed means that the values are more and more concentrated near 0, and there are fewer very large values.</p>
<p>Interestingly, the mean of a log-normal distribution is not simply <span class="math inline">\(e^\mu\)</span> as one might expect. The mean of a lognormal distribution <em>X</em> on the linear scale is</p>
<p><span class="math display">\[mean\left(X\right)=e^{\left(\frac{\mu+\sigma^2}{2}\right)}\]</span></p>
<p>In this equation, <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are the mean and SD on the logarithmic scale. The variance on the linear scale is:</p>
<p><span class="math display">\[Var\left(X\right)=e^{2\mu+\sigma^2}\left(e^{\sigma^2}-1\right)\]</span></p>
<p>What this means is that you cannot transform the parameters of a lognormal distribution from the logarithmic to the linear scale by simply exponentiating.</p>
<div id="logormal-distribution-in-r" class="section level5" number="4.3.4.3.1">
<h5><span class="header-section-number">4.3.4.3.1</span> Logormal distribution in R</h5>
<p>The lognormal distribution is accessed using the <code>_lnorm</code> group of functions, where the space could be <code>d</code>, <code>p</code>, <code>q</code>, or <code>r</code>. These functions calculate or returns something different:</p>
<ul>
<li><code>dlnorm()</code>: Calculates probability density function (PDF) at <em>x</em>.</li>
<li><code>plnorm()</code>: Calculates CDF, from 0 up to <em>x</em>. Answers the question, “at what quantile of the distribution should some value fall?”. The reverse of <code>qlnorm()</code>.</li>
<li><code>qlnorm()</code>: Calculates the value at a specified quantile or quantiles. The reverse of <code>plnorm()</code>.</li>
<li><code>rlnorm()</code>: Draws random numbers from the lognormal distribution.</li>
</ul>
<p>When working with the lognormal distribution in R it is important to keep in mind that the parameters (<code>meanlog</code> and <code>sdlog</code>) of the <code>_lnorm</code> functions are on the <em>natural log scale</em>. The <code>meanlog</code> parameter is the <em>mean of the logarithm</em> of the values, not the mean of the values or the logarithm of the mean of the values. Similarly, <code>sdlog</code> is the <code>SD of the logarithm</code> of the values, not the SD of the values or the logarithm of the SD of the values. The example below shows this:</p>
<div class="sourceCode" id="cb939"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb939-1"><a href="4.3-mod-04-dists1.html#cb939-1" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">rlnorm</span>(<span class="fl">1e4</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb939-2"><a href="4.3-mod-04-dists1.html#cb939-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb939-3"><a href="4.3-mod-04-dists1.html#cb939-3" aria-hidden="true" tabindex="-1"></a><span class="co"># mean of the values vs. mean of the log(values):</span></span>
<span id="cb939-4"><a href="4.3-mod-04-dists1.html#cb939-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x1)</span></code></pre></div>
<pre><code>## [1] 12.10312</code></pre>
<div class="sourceCode" id="cb941"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb941-1"><a href="4.3-mod-04-dists1.html#cb941-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">log</span>(x1))</span></code></pre></div>
<pre><code>## [1] 2.01172</code></pre>
<div class="sourceCode" id="cb943"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb943-1"><a href="4.3-mod-04-dists1.html#cb943-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sd of the values vs. sd of the log(values):</span></span>
<span id="cb943-2"><a href="4.3-mod-04-dists1.html#cb943-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(x1)</span></code></pre></div>
<pre><code>## [1] 14.81899</code></pre>
<div class="sourceCode" id="cb945"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb945-1"><a href="4.3-mod-04-dists1.html#cb945-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(<span class="fu">log</span>(x1))</span></code></pre></div>
<pre><code>## [1] 0.9923424</code></pre>
<div class="sourceCode" id="cb947"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb947-1"><a href="4.3-mod-04-dists1.html#cb947-1" aria-hidden="true" tabindex="-1"></a><span class="co"># exp(meanlog) != mean(x1)</span></span>
<span id="cb947-2"><a href="4.3-mod-04-dists1.html#cb947-2" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 7.389056</code></pre>
<div class="sourceCode" id="cb949"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb949-1"><a href="4.3-mod-04-dists1.html#cb949-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x1)</span></code></pre></div>
<pre><code>## [1] 12.10312</code></pre>
</div>
</div>
<div id="gamma-distribution" class="section level4" number="4.3.4.4">
<h4><span class="header-section-number">4.3.4.4</span> Gamma distribution</h4>
<p>The <strong>gamma distribution</strong> describes waiting times until a certain number of events takes place. This means it is the continuous analogue of the negative binomial distribution, which describes the number of trials until some certain number of successes. The gamma distribution can also be used to describe positive data whose SD is much larger than the mean. This makes it an alternative to the lognormal distribution for right-skewed data, much like the negative binomial is an alternative to the Poisson. Example gamma distributions are shown below.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-354-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>The Gamma distribution is parameterized by its <strong>shape</strong> and <strong>scale</strong>. The shape parameter <em>k</em> describes the number of events; the scale parameter <span class="math inline">\(\theta\)</span> (“theta”) describes the mean time until each event. The scale is sometimes expressed as the <strong>rate</strong>, which is the reciprocal of scale. Both versions are implemented in R, so you need to specify your arguments when working with the gamma distribution. For example, Gamma(4, 2) is the distribution of length of time in days it would take to observe 4 events if events occur on average once every two days. Equivalently, it is the time to observe 4 events if events occur at a rate of 1/2 event per day. Consequently, the mean of a gamma distribution given shape <em>k</em> and scale <span class="math inline">\(\theta\)</span> (or rate <em>r</em>) is:</p>
<p><span class="math display">\[\mu=k\theta=\frac{k}{r}\]</span></p>
<p>The variance is calculated as:</p>
<p><span class="math display">\[\sigma^2=k\theta^2=\frac{k}{r^2}\]</span></p>
<p>Like the negative binomial, the gamma distribution is often used phenomenologically; that is, used to describe a variable even if its mechanistic description (waiting times) doesn’t make sense biologically. Just as the negative binomial can be used to model count data with variance greater than the mean (i.e., an overdispersed Poisson), a gamma distribution can be used for positive data with <span class="math inline">\(\sigma \gg \mu\)</span>. I.e., the use case for the gamma is similar to that of the lognormal.</p>
<div id="gamma-distribution-in-r" class="section level5" number="4.3.4.4.1">
<h5><span class="header-section-number">4.3.4.4.1</span> Gamma distribution in R</h5>
<p>The gamma distribution is accessed using the <code>_gamma</code> group of functions, where the space could be <code>d</code>, <code>p</code>, <code>q</code>, or <code>r</code>. These functions calculate or returns something different:</p>
<ul>
<li><code>dgamma()</code>: Calculates probability density function (PDF) at <em>x</em>.</li>
<li><code>pgamma()</code>: Calculates CDF, from 0 up to <em>x</em>. Answers the question, “at what quantile of the distribution should some value fall?”. The reverse of <code>qgamma()</code>.</li>
<li><code>qgamma()</code>: Calculates the value at a specified quantile or quantiles. The reverse of <code>pgamma()</code>.</li>
<li><code>rgamma()</code>: Draws random numbers from the gamma distribution.</li>
</ul>
<p>Note that when working with the gamma distribution in R, you must supply either the <code>shape</code> and the <code>rate</code>, or the <code>shape</code> and the <code>scale</code>. Supplying <code>scale</code> and <code>rate</code> will return an error.</p>
<div class="sourceCode" id="cb951"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb951-1"><a href="4.3-mod-04-dists1.html#cb951-1" aria-hidden="true" tabindex="-1"></a><span class="co"># will work:</span></span>
<span id="cb951-2"><a href="4.3-mod-04-dists1.html#cb951-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rgamma</span>(<span class="dv">10</span>, <span class="at">shape=</span><span class="dv">3</span>, <span class="at">scale=</span><span class="dv">2</span>)</span>
<span id="cb951-3"><a href="4.3-mod-04-dists1.html#cb951-3" aria-hidden="true" tabindex="-1"></a><span class="fu">rgamma</span>(<span class="dv">10</span>, <span class="at">shape=</span><span class="dv">3</span>, <span class="at">rate=</span><span class="fl">0.5</span>)</span>
<span id="cb951-4"><a href="4.3-mod-04-dists1.html#cb951-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb951-5"><a href="4.3-mod-04-dists1.html#cb951-5" aria-hidden="true" tabindex="-1"></a><span class="co"># will return error:</span></span>
<span id="cb951-6"><a href="4.3-mod-04-dists1.html#cb951-6" aria-hidden="true" tabindex="-1"></a><span class="fu">rgamma</span>(<span class="dv">10</span>, <span class="at">scale=</span><span class="dv">2</span>, <span class="at">rate=</span><span class="fl">0.5</span>)</span></code></pre></div>
</div>
</div>
<div id="beta-distribution" class="section level4" number="4.3.4.5">
<h4><span class="header-section-number">4.3.4.5</span> Beta distribution</h4>
<p>The <strong>beta distribution</strong> is defined on the interval [0, 1] and is parameterized by two positive shape parameters, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. For this reason, the beta distribution is often used to model the distribution of probabilities. Besides the uniform, the beta distribution is probably the most well-known continuous distribution that is bounded by an interval. The beta distribution can also be used to model any continuous variable that occurs on a bounded interval, by rescaling the variable to the interval [0, 1]. However, this may be better accomplished with a logit transformation (see the <a href="4.5-mod-04-trans.html#mod-04-trans">section on transformations</a>).</p>
<p>The parameters of the beta distribution are a little tricky to understand, and relate to the binomial distribution. Each shape parameter is one plus the number of successes (<span class="math inline">\(\alpha\)</span>) and failures (<span class="math inline">\(\beta\)</span>) in a binomial trial. This gets a little weird when <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are &lt;1 (how can you have &lt;0 successes or failures?) but the distribution is still defined. The shape parameters can also be non-integers. The figure below shows various beta distributions. Notice how the distribution becomes U-shaped when <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> both get close to 0.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-356-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>The beta distribution has mean</p>
<p><span class="math display">\[\mu=\frac{\alpha}{\alpha+\beta}\]</span></p>
<p>and variance</p>
<p><span class="math display">\[\sigma^2=\frac{\alpha\beta}{\left(\alpha+\beta\right)^2\left(\alpha+\beta+1\right)}\]</span></p>
<p>These expressions can be re-arranged to solve for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> given a mean and variance:</p>
<p><span class="math display">\[\alpha=\left(\frac{1-\mu}{\sigma^2}-\frac{1}{\mu}\right)\mu^2\]</span></p>
<p><span class="math display">\[\beta=\alpha\left(\frac{1}{\mu}-1\right)\]</span></p>
<p>This is useful if you want to use data that were reported as a mean and variance (or SD, or SE) that describe a proportion. For example, if a paper reports a survival rate estimate as 0.25 <span class="math inline">\(\pm\)</span> 0.18 SE, this implicitly suggests that the survival rate is a normally-distributed variable because a normal distribution is defined by the mean and SD (SE of a parameter estimate is equivalent to the SD of a distribution). However, this would imply that about 8% of the time, the survival rate was negative! (Verify this using R: <code>pnorm(0, 0.25, 0.18)</code>). So, you should convert these estimates to a beta distribution if you want to understand how they might vary:</p>
<p><span class="math display">\[
\alpha=\left(\frac{1-0.25}{\left(0.18\right)^2}-\frac{1}{0.25}\right){0.25}^2\approx1.1968\]</span></p>
<p><span class="math display">\[\beta=1.1968\left(\frac{1}{0.25}-1\right)\approx3.5903\]</span></p>
<p>The figure below shows the two distributions, the normal in black and the beta in blue. The dashed vertical line at 0 shows that part of the normal distribution implied by the mean and SE of a survival “probability” is not possible. Converting to a beta distribution preserves the mean and variance, but probably more accurately reflects the true nature of the uncertainty about the probability. Note that this conversion cannot be done for some combinations of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>: both <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> must both be positive, so if you calculate a non-positive value for either parameter then the conversion won’t work. This can sometimes happen for probabilties very close to 0 or 1 with large SE.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-357-1.png" width="576" style="display: block; margin: auto;" /></p>
<div id="beta-distribution-in-r" class="section level5" number="4.3.4.5.1">
<h5><span class="header-section-number">4.3.4.5.1</span> Beta distribution in R</h5>
<p>The beta distribution is accessed using the <code>_beta</code> group of functions, where the space could be <code>d</code>, <code>p</code>, <code>q</code>, or <code>r</code>. These functions calculate or returns something different:</p>
<ul>
<li><code>dbeta()</code>: Calculates probability density function (PDF) at <em>x</em>.</li>
<li><code>pbeta()</code>: Calculates CDF, from 0 up to <em>x</em>. Answers the question, “at what quantile of the distribution should some value fall?”. The reverse of <code>qbeta()</code>.</li>
<li><code>qbeta()</code>: Calculates the value at a specified quantile or quantiles. The reverse of <code>pbeta()</code>.</li>
<li><code>rbeta()</code>: Draws random numbers from the beta distribution.</li>
</ul>
</div>
<div id="the-beta-and-the-binomial" class="section level5" number="4.3.4.5.2">
<h5><span class="header-section-number">4.3.4.5.2</span> The beta and the binomial</h5>
<p>The relationship between the beta distribution and the binomial distribution should be obvious: uncertainty about the probability parameter of a binomial distribution (<em>p</em>) can be modeled using a beta distribution. In fact, this practice is so common that it has a name: the beta-binomial distribution.</p>
<p>We can take advantage of the relationship between the binomial and beta distributions to make inferences from count data. Imagine a study where biologists track the probability that fruit flies die before they are 3 weeks old. They report that 30 out of 130 flies die on or before day 21 of life. What can we estimate about the underlying distribution of 3-week survival rates?</p>
<p>First, express the values as <em>successes</em> and <em>failures</em>. Let’s consider survival to be success (<em>n</em> = 100) and mortality to be failure (<em>n</em> = 30). This suggests that the underlying probability of survival to 21 days follows a beta distribution with <span class="math inline">\(\alpha\)</span> = 101 and <span class="math inline">\(\beta\)</span> = 31. Alternatively, we could define “success” as mortality. In this case, the mortality rate would follow a beta distribution with <span class="math inline">\(\alpha\)</span> = 31 and <span class="math inline">\(\beta\)</span> = 101. In R this can be calculated and plotted as shown below. Notice how reversing <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, or reversing perspective from survival to mortality, changes the distribution to its complement:</p>
<div class="sourceCode" id="cb952"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb952-1"><a href="4.3-mod-04-dists1.html#cb952-1" aria-hidden="true" tabindex="-1"></a><span class="co"># domain of probability</span></span>
<span id="cb952-2"><a href="4.3-mod-04-dists1.html#cb952-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length=</span><span class="fl">1e3</span>)</span>
<span id="cb952-3"><a href="4.3-mod-04-dists1.html#cb952-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb952-4"><a href="4.3-mod-04-dists1.html#cb952-4" aria-hidden="true" tabindex="-1"></a><span class="co"># survival rate distribution</span></span>
<span id="cb952-5"><a href="4.3-mod-04-dists1.html#cb952-5" aria-hidden="true" tabindex="-1"></a>y.surv <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(x, <span class="at">shape1=</span><span class="dv">101</span>, <span class="at">shape2=</span><span class="dv">31</span>)</span>
<span id="cb952-6"><a href="4.3-mod-04-dists1.html#cb952-6" aria-hidden="true" tabindex="-1"></a>y.mort <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(x, <span class="at">shape1=</span><span class="dv">31</span>, <span class="at">shape2=</span><span class="dv">101</span>)</span>
<span id="cb952-7"><a href="4.3-mod-04-dists1.html#cb952-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb952-8"><a href="4.3-mod-04-dists1.html#cb952-8" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">mar=</span><span class="fu">c</span>(<span class="fl">5.1</span>, <span class="fl">5.1</span>, <span class="fl">1.1</span>, <span class="fl">1.1</span>),</span>
<span id="cb952-9"><a href="4.3-mod-04-dists1.html#cb952-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">bty=</span><span class="st">&quot;n&quot;</span>, <span class="at">lend=</span><span class="dv">1</span>, <span class="at">las=</span><span class="dv">1</span>, </span>
<span id="cb952-10"><a href="4.3-mod-04-dists1.html#cb952-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">cex.axis=</span><span class="fl">1.3</span>, <span class="at">cex.lab=</span><span class="fl">1.3</span>)</span>
<span id="cb952-11"><a href="4.3-mod-04-dists1.html#cb952-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y.surv, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, </span>
<span id="cb952-12"><a href="4.3-mod-04-dists1.html#cb952-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;P(survival)&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PDF&quot;</span>)</span>
<span id="cb952-13"><a href="4.3-mod-04-dists1.html#cb952-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y.mort, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, </span>
<span id="cb952-14"><a href="4.3-mod-04-dists1.html#cb952-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab=</span><span class="st">&quot;P(mortality)&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PDF&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-358-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>We could calculate this distribution in another way. Consider the number of flies that survive to come from a binomial distribution. The distribution would have <em>n</em> = 130, and <em>p</em> = 100/130 <span class="math inline">\(\approx\)</span> 0.7692. Using the properties of the binomial distribution, we could infer that the mean of the binomial distribution was</p>
<p><span class="math display">\[\mu=np=100\]</span></p>
<p>and its variance was</p>
<p><span class="math display">\[\sigma^2=\ np(1-p)\approx23.08\]</span></p>
<p>This would imply that the SD of the binomial distribution was about 4.8038, and thus the CV was about 0.048038. The CV is the ratio of the SD to the mean. We could then estimate the SD of <em>p</em> was</p>
<p><span class="math display">\[\sigma\left(p\right)=\left(0.048\right)\left(0.7692\right)\approx0.0369\]</span></p>
<p>We could then use these values, <span class="math inline">\(\mu\left(p\right)\)</span> = 0.7692 and <span class="math inline">\(\sigma\left(p\right)\)</span> = 0.0369 into the expressions for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> to obtain:</p>
<p><span class="math display">\[\alpha=\left(\frac{1-0.7692}{{(0.0369)}^2}-\frac{1}{0.7692}\right){(0.7692)}^2\approx99.23\]</span></p>
<p><span class="math display">\[\beta=99.52\left(\frac{1}{0.7692}-1\right)\approx29.77\]</span></p>
<p>These expressions get us almost the exact answers. The R code to perform these calculations is below:</p>
<div class="sourceCode" id="cb953"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb953-1"><a href="4.3-mod-04-dists1.html#cb953-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">130</span></span>
<span id="cb953-2"><a href="4.3-mod-04-dists1.html#cb953-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">100</span><span class="sc">/</span><span class="dv">130</span></span>
<span id="cb953-3"><a href="4.3-mod-04-dists1.html#cb953-3" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="ot">&lt;-</span> n<span class="sc">*</span>p<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p)</span>
<span id="cb953-4"><a href="4.3-mod-04-dists1.html#cb953-4" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(sigma2)</span>
<span id="cb953-5"><a href="4.3-mod-04-dists1.html#cb953-5" aria-hidden="true" tabindex="-1"></a>cv <span class="ot">&lt;-</span> sigma<span class="sc">/</span><span class="dv">100</span></span>
<span id="cb953-6"><a href="4.3-mod-04-dists1.html#cb953-6" aria-hidden="true" tabindex="-1"></a>sdp <span class="ot">&lt;-</span> cv<span class="sc">*</span>p</span>
<span id="cb953-7"><a href="4.3-mod-04-dists1.html#cb953-7" aria-hidden="true" tabindex="-1"></a>Alpha <span class="ot">&lt;-</span> (((<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">/</span>(sdp<span class="sc">^</span><span class="dv">2</span>))<span class="sc">-</span>(<span class="dv">1</span><span class="sc">/</span>p))<span class="sc">*</span>(p<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb953-8"><a href="4.3-mod-04-dists1.html#cb953-8" aria-hidden="true" tabindex="-1"></a>Beta <span class="ot">&lt;-</span> Alpha<span class="sc">*</span>((<span class="dv">1</span><span class="sc">/</span>p)<span class="sc">-</span><span class="dv">1</span>)</span></code></pre></div>
<p>We can compare the distributions using <code>dbeta</code>.</p>
<div class="sourceCode" id="cb954"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb954-1"><a href="4.3-mod-04-dists1.html#cb954-1" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">999</span><span class="sc">/</span><span class="fl">1e3</span></span>
<span id="cb954-2"><a href="4.3-mod-04-dists1.html#cb954-2" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(x1, <span class="dv">101</span>, <span class="dv">31</span>) <span class="co"># based on counts</span></span>
<span id="cb954-3"><a href="4.3-mod-04-dists1.html#cb954-3" aria-hidden="true" tabindex="-1"></a>y2 <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(x1, Alpha, Beta) <span class="co"># calculated from binomial</span></span>
<span id="cb954-4"><a href="4.3-mod-04-dists1.html#cb954-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb954-5"><a href="4.3-mod-04-dists1.html#cb954-5" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">bty=</span><span class="st">&quot;n&quot;</span>, <span class="at">mar=</span><span class="fu">c</span>(<span class="fl">5.1</span>, <span class="fl">5.1</span>, <span class="fl">1.1</span>, <span class="fl">1.1</span>),</span>
<span id="cb954-6"><a href="4.3-mod-04-dists1.html#cb954-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">las=</span><span class="dv">1</span>, <span class="at">cex.axis=</span><span class="fl">1.2</span>, <span class="at">cex.lab=</span><span class="fl">1.2</span>, <span class="at">lend=</span><span class="dv">1</span>)</span>
<span id="cb954-7"><a href="4.3-mod-04-dists1.html#cb954-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x1, y1, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">xlab=</span><span class="st">&quot;X&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PDF&quot;</span>)</span>
<span id="cb954-8"><a href="4.3-mod-04-dists1.html#cb954-8" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x1, y2, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb954-9"><a href="4.3-mod-04-dists1.html#cb954-9" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;Count-based&quot;</span>, <span class="st">&quot;Calculated&quot;</span>),</span>
<span id="cb954-10"><a href="4.3-mod-04-dists1.html#cb954-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="at">bty=</span><span class="st">&quot;n&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-360-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>The calculated values in <code>y2</code> result in a beta distribution of probabilities very close to the correct values. The difference results from a result known as the <strong>rule of succession</strong>, first published by French mathematician Pierre-Simon LaPlace in the 18th century. Briefly, we should assign the mean probability of success in a future Bernoulli trial <span class="math inline">\(\hat{p}\)</span> as</p>
<p><span class="math display">\[\hat{p}=\frac{x+1}{n+2}\]</span></p>
<p>where <em>x</em> is the number of successes in <em>n</em> trials. In other words, for some vector <em>x</em> of successes and failures (1s and 0s) we need to add one additional 1 and one additional 0 in order to estimate underlying distribution of success rates. The R code below produces the correct result (notice the new values of <em>n</em> and <em>p</em>).</p>
<div class="sourceCode" id="cb955"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb955-1"><a href="4.3-mod-04-dists1.html#cb955-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">132</span></span>
<span id="cb955-2"><a href="4.3-mod-04-dists1.html#cb955-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">101</span><span class="sc">/</span><span class="dv">132</span></span>
<span id="cb955-3"><a href="4.3-mod-04-dists1.html#cb955-3" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="ot">&lt;-</span> n<span class="sc">*</span>p<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>p)</span>
<span id="cb955-4"><a href="4.3-mod-04-dists1.html#cb955-4" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(sigma2)</span>
<span id="cb955-5"><a href="4.3-mod-04-dists1.html#cb955-5" aria-hidden="true" tabindex="-1"></a>cv <span class="ot">&lt;-</span> sigma<span class="sc">/</span><span class="dv">100</span></span>
<span id="cb955-6"><a href="4.3-mod-04-dists1.html#cb955-6" aria-hidden="true" tabindex="-1"></a>sdp <span class="ot">&lt;-</span> cv<span class="sc">*</span>p</span>
<span id="cb955-7"><a href="4.3-mod-04-dists1.html#cb955-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb955-8"><a href="4.3-mod-04-dists1.html#cb955-8" aria-hidden="true" tabindex="-1"></a>Alpha <span class="ot">&lt;-</span> (((<span class="dv">1</span><span class="sc">-</span>p)<span class="sc">/</span>(sdp<span class="sc">^</span><span class="dv">2</span>))<span class="sc">-</span>(<span class="dv">1</span><span class="sc">/</span>p))<span class="sc">*</span>(p<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb955-9"><a href="4.3-mod-04-dists1.html#cb955-9" aria-hidden="true" tabindex="-1"></a>Beta <span class="ot">&lt;-</span> Alpha<span class="sc">*</span>((<span class="dv">1</span><span class="sc">/</span>p)<span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb955-10"><a href="4.3-mod-04-dists1.html#cb955-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb955-11"><a href="4.3-mod-04-dists1.html#cb955-11" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">999</span><span class="sc">/</span><span class="fl">1e3</span></span>
<span id="cb955-12"><a href="4.3-mod-04-dists1.html#cb955-12" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(x1, <span class="dv">101</span>, <span class="dv">31</span>) <span class="co"># based on counts</span></span>
<span id="cb955-13"><a href="4.3-mod-04-dists1.html#cb955-13" aria-hidden="true" tabindex="-1"></a>y2 <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(x1, Alpha, Beta) <span class="co"># calculated from binomial</span></span>
<span id="cb955-14"><a href="4.3-mod-04-dists1.html#cb955-14" aria-hidden="true" tabindex="-1"></a>                             <span class="co"># and rule of succession</span></span>
<span id="cb955-15"><a href="4.3-mod-04-dists1.html#cb955-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb955-16"><a href="4.3-mod-04-dists1.html#cb955-16" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">bty=</span><span class="st">&quot;n&quot;</span>, <span class="at">mar=</span><span class="fu">c</span>(<span class="fl">5.1</span>, <span class="fl">5.1</span>, <span class="fl">1.1</span>, <span class="fl">1.1</span>),</span>
<span id="cb955-17"><a href="4.3-mod-04-dists1.html#cb955-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">las=</span><span class="dv">1</span>, <span class="at">cex.axis=</span><span class="fl">1.2</span>, <span class="at">cex.lab=</span><span class="fl">1.2</span>, <span class="at">lend=</span><span class="dv">1</span>)</span>
<span id="cb955-18"><a href="4.3-mod-04-dists1.html#cb955-18" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x1, y1, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">xlab=</span><span class="st">&quot;X&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PDF&quot;</span>)</span>
<span id="cb955-19"><a href="4.3-mod-04-dists1.html#cb955-19" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x1, y2, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb955-20"><a href="4.3-mod-04-dists1.html#cb955-20" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;Count-based&quot;</span>, <span class="st">&quot;Calculated&quot;</span>),</span>
<span id="cb955-21"><a href="4.3-mod-04-dists1.html#cb955-21" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="at">bty=</span><span class="st">&quot;n&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-361-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="dirichlet-distribution" class="section level4" number="4.3.4.6">
<h4><span class="header-section-number">4.3.4.6</span> Dirichlet distribution</h4>
<p>The <strong>Dirichlet distribution</strong> (pronounced “Deer-eesh-lay”) is the distribution of probabilities for multiple outcomes of a random process. This makes it the generalization of beta distribution to multiple outcomes. The values of a Dirichlet distribution must add up to 1. For example, the beta distribution models the probability of throwing heads when you flip a coin. The Dirichlet distribution describes the probability of getting 1, 2, 3, 4, 5, or 6 when you throw a 6-sided die. Just as the probabilities of heads and not-heads must add to 1, the probabilities of 1, 2, 3, 4, 5, and 6 must add up to 1.</p>
<p>The Dirichlet distribution doesn’t come up on its own very often. Usually, biologists encounter the Dirichlet distribution when performing Bayesian analysis of multinomial outcomes. The Dirichlet distribution is the “conjugate prior” of the categorical and multinomial distributions.</p>
</div>
<div id="exponential-distribution" class="section level4" number="4.3.4.7">
<h4><span class="header-section-number">4.3.4.7</span> Exponential distribution</h4>
<p>The <strong>exponential distribution</strong> describes the distribution of waiting times until a single event occurs, given a constant probability per unit time of that event occurring. This makes it the continuous analog of the geometric distribution. The exponential distribution is also a special case of the gamma distribution where k = 1.</p>
<p>The exponential distribution should not be confused with the <strong>exponential family of distributions</strong>, although the exponential distribution is part of that family. The exponential family of distributions includes many whose PDF can be expressed as an exponential function (e.g., <span class="math inline">\(f\left(x\right)=e^x\)</span>). The exponential family includes the normal, exponential, gamma, beta, Poisson, and many others.</p>
<p>The exponential distribution is parameterized by a single rate parameter, <span class="math inline">\(\lambda\)</span>, which describes the number of events occurring per unit time. This means that <span class="math inline">\(\lambda\)</span> must be &gt;0. This is exactly the same as the rate parameter <em>r</em> sometimes used to describe the gamma distribution. The mean of an exponential distribution <em>X</em> is:</p>
<p><span class="math display">\[\mu\left(X\right)=\frac{1}{\lambda}\]</span></p>
<p>and the variance is:</p>
<p><span class="math display">\[\sigma^2\left(X\right)=\frac{1}{\lambda^2}\]</span></p>
<p>Interestingly, this implies that the standard deviation <span class="math inline">\(\sigma\)</span> is the same as the mean <span class="math inline">\(\mu\)</span>. Contrast this with the Poisson distribution, where the <em>variance</em> <span class="math inline">\(\sigma^2\)</span> is the same as the mean. Thus, the CV of the exponential distribution is always 1.</p>
<p>The exponential distribution is supported for all non-negative real numbers; i.e., the half-open interval [0, <span class="math inline">\(+\infty\)</span>). Like the gamma distribution, the exponential distribution can be used to model biological processes for which its mechanistic description makes sense (e.g., waiting times or lifespans), or for any situation resulting in primarily 0 or small values and few large values.</p>
<div id="exponential-distribution-in-r" class="section level5" number="4.3.4.7.1">
<h5><span class="header-section-number">4.3.4.7.1</span> Exponential distribution in R</h5>
<p>The exponential distribution is accessed using the <code>_exp</code> group of functions, where the space could be <code>d</code>, <code>p</code>, <code>q</code>, or <code>r</code>. These functions calculate or returns something different:</p>
<ul>
<li><code>dexp()</code>: Calculates probability density function (PDF) at <em>x</em>.</li>
<li><code>pexp()</code>: Calculates CDF up to <em>x</em>. Answers the question, “at what quantile of the distribution should some value fall?”. The reverse of <code>qexp()</code>.</li>
<li><code>qexp()</code>: Calculates the value at a specified quantile or quantiles. The reverse of <code>pexp()</code>.</li>
<li><code>rexp()</code>: Draws random numbers from the exponential distribution.</li>
</ul>
</div>
</div>
<div id="triangular-distribution" class="section level4" number="4.3.4.8">
<h4><span class="header-section-number">4.3.4.8</span> Triangular distribution</h4>
<p>The <strong>triangular distribution</strong> is sometimes called the “distribution of ignorance” or “lack of knowledge distribution”. Sometimes we need to model a process about which we have very little information. For example, we may want to simulate population dynamics without knowing a key survival rate, or organismal growth without knowing a key growth constant. In these situations we might have only a vague idea of how a parameter or an outcome are distributed. At a minimum, we can usually infer or estimate the range and central tendency of a variable. Those are enough to estimate a triangular distribution.</p>
<p>The triangular distribution is parameterized by three parameters: the lower limit <em>a</em>, the upper limit <em>b</em>, and the mode (most common value) <em>c</em>. Any triangular distribution must satisfy <em>a</em> &lt; <em>b</em> and <em>a</em> <span class="math inline">\(\le\)</span> <em>c</em> <span class="math inline">\(\le\)</span> <em>b</em>.</p>
<p>The mean of a triangular distribution <em>X</em> is the mean of its parameters:</p>
<p><span class="math display">\[\mu\left(X\right)=\frac{a+b+c}{3}\]</span></p>
<p>and the variance is</p>
<p><span class="math display">\[\sigma^2\left(X\right)=\frac{a^2+b^2+c^2-ab-ac-bc}{18}\]</span></p>
<p>In addition to serving as a stand-in distribution when data are scarce, the triangular distribution can arise in several natural situations. For example, the mean of two standard uniform variables follows a triangular distribution (see below).</p>
<div id="triangular-distribution-in-r" class="section level5" number="4.3.4.8.1">
<h5><span class="header-section-number">4.3.4.8.1</span> Triangular distribution in R</h5>
<p>The triangular distribution is available in the add-on package “triangle” <span class="citation">(<a href="#ref-carnell2019" role="doc-biblioref">Carnell 2019</a>)</span>. The triangular distribution is accessed using the <code>_triangle</code> group of functions, where the space could be <code>d</code>, <code>p</code>, <code>q</code>, or <code>r</code>. These functions calculate or returns something different:</p>
<ul>
<li><code>dtriangle()</code>: Calculates probability density function (PDF) at <em>x</em>.</li>
<li><code>ptriangle()</code>: Calculates CDF up <em>a</em> to <em>x</em>. Answers the question, “at what quantile of the distribution should some value fall?”. The reverse of <code>qtriangle()</code>.</li>
<li><code>qtriangle()</code>: Calculates the value at a specified quantile or quantiles. The reverse of <code>ptriangle()</code>.</li>
<li><code>rtriangle()</code>: Draws random numbers from the triangular distribution.</li>
</ul>
<p>The code below shows the PDFs of various triangular distributions. Notice that <code>c</code> is not used as a variable name, to avoid potentially masking the very critical R function <code>c</code>.</p>
<div class="sourceCode" id="cb956"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb956-1"><a href="4.3-mod-04-dists1.html#cb956-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(triangle)</span></code></pre></div>
<pre><code>## Warning: package &#39;triangle&#39; was built under R version 4.1.2</code></pre>
<div class="sourceCode" id="cb958"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb958-1"><a href="4.3-mod-04-dists1.html#cb958-1" aria-hidden="true" tabindex="-1"></a>ax <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">3</span>)</span>
<span id="cb958-2"><a href="4.3-mod-04-dists1.html#cb958-2" aria-hidden="true" tabindex="-1"></a>bx <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">7</span>)</span>
<span id="cb958-3"><a href="4.3-mod-04-dists1.html#cb958-3" aria-hidden="true" tabindex="-1"></a>cx <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">6</span>)</span>
<span id="cb958-4"><a href="4.3-mod-04-dists1.html#cb958-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb958-5"><a href="4.3-mod-04-dists1.html#cb958-5" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">seq</span>(ax[<span class="dv">1</span>], bx[<span class="dv">1</span>], <span class="at">length=</span><span class="dv">50</span>)</span>
<span id="cb958-6"><a href="4.3-mod-04-dists1.html#cb958-6" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">seq</span>(ax[<span class="dv">2</span>], bx[<span class="dv">2</span>], <span class="at">length=</span><span class="dv">50</span>)</span>
<span id="cb958-7"><a href="4.3-mod-04-dists1.html#cb958-7" aria-hidden="true" tabindex="-1"></a>x3 <span class="ot">&lt;-</span> <span class="fu">seq</span>(ax[<span class="dv">3</span>], bx[<span class="dv">3</span>], <span class="at">length=</span><span class="dv">50</span>)</span>
<span id="cb958-8"><a href="4.3-mod-04-dists1.html#cb958-8" aria-hidden="true" tabindex="-1"></a>y1 <span class="ot">&lt;-</span> <span class="fu">dtriangle</span>(x1, ax[<span class="dv">1</span>], bx[<span class="dv">1</span>], cx[<span class="dv">1</span>])</span>
<span id="cb958-9"><a href="4.3-mod-04-dists1.html#cb958-9" aria-hidden="true" tabindex="-1"></a>y2 <span class="ot">&lt;-</span> <span class="fu">dtriangle</span>(x2, ax[<span class="dv">2</span>], bx[<span class="dv">2</span>], cx[<span class="dv">2</span>])</span>
<span id="cb958-10"><a href="4.3-mod-04-dists1.html#cb958-10" aria-hidden="true" tabindex="-1"></a>y3 <span class="ot">&lt;-</span> <span class="fu">dtriangle</span>(x3, ax[<span class="dv">3</span>], bx[<span class="dv">3</span>], cx[<span class="dv">3</span>])</span>
<span id="cb958-11"><a href="4.3-mod-04-dists1.html#cb958-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb958-12"><a href="4.3-mod-04-dists1.html#cb958-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x1, y1, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">xlab=</span><span class="st">&quot;X&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;PDF&quot;</span>,</span>
<span id="cb958-13"><a href="4.3-mod-04-dists1.html#cb958-13" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>))</span>
<span id="cb958-14"><a href="4.3-mod-04-dists1.html#cb958-14" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x2, y2, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb958-15"><a href="4.3-mod-04-dists1.html#cb958-15" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(x3, y3, <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="st">&quot;blue&quot;</span>)</span>
<span id="cb958-16"><a href="4.3-mod-04-dists1.html#cb958-16" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;Tri(1, 5, 3)&quot;</span>, <span class="st">&quot;Tri(1, 10, 3)&quot;</span>, <span class="st">&quot;Tri(3, 7, 6)&quot;</span>), </span>
<span id="cb958-17"><a href="4.3-mod-04-dists1.html#cb958-17" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-362-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>The code below demonstrates how a triangular distribution can arise as the distribution of means of two standard uniform variables x1 and x2. The command density estimates the kernel density estimate of a vector. The kernel density estimate is an empirical estimate of the PDF of a variable.</p>
<div class="sourceCode" id="cb959"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb959-1"><a href="4.3-mod-04-dists1.html#cb959-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb959-2"><a href="4.3-mod-04-dists1.html#cb959-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span>(<span class="dv">2</span><span class="sc">:</span><span class="dv">4</span>)</span>
<span id="cb959-3"><a href="4.3-mod-04-dists1.html#cb959-3" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> y <span class="ot">&lt;-</span> x <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="fu">length</span>(n))</span>
<span id="cb959-4"><a href="4.3-mod-04-dists1.html#cb959-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(n)){</span>
<span id="cb959-5"><a href="4.3-mod-04-dists1.html#cb959-5" aria-hidden="true" tabindex="-1"></a>    x[[i]] <span class="ot">&lt;-</span> (<span class="fu">runif</span>(n[i]) <span class="sc">+</span> <span class="fu">runif</span>(n[i]))<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb959-6"><a href="4.3-mod-04-dists1.html#cb959-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb959-7"><a href="4.3-mod-04-dists1.html#cb959-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(n)){</span>
<span id="cb959-8"><a href="4.3-mod-04-dists1.html#cb959-8" aria-hidden="true" tabindex="-1"></a>    z <span class="ot">&lt;-</span> <span class="fu">density</span>(x[[i]])</span>
<span id="cb959-9"><a href="4.3-mod-04-dists1.html#cb959-9" aria-hidden="true" tabindex="-1"></a>    x1[[i]] <span class="ot">&lt;-</span> z<span class="sc">$</span>x</span>
<span id="cb959-10"><a href="4.3-mod-04-dists1.html#cb959-10" aria-hidden="true" tabindex="-1"></a>    y[[i]] <span class="ot">&lt;-</span> z<span class="sc">$</span>y</span>
<span id="cb959-11"><a href="4.3-mod-04-dists1.html#cb959-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb959-12"><a href="4.3-mod-04-dists1.html#cb959-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb959-13"><a href="4.3-mod-04-dists1.html#cb959-13" aria-hidden="true" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">rainbow</span>(<span class="dv">3</span>)</span>
<span id="cb959-14"><a href="4.3-mod-04-dists1.html#cb959-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x1[[<span class="dv">1</span>]], y[[<span class="dv">1</span>]], <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span>cols[<span class="dv">1</span>],</span>
<span id="cb959-15"><a href="4.3-mod-04-dists1.html#cb959-15" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">&quot;X&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Kernel density estimate&quot;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">2</span>))</span>
<span id="cb959-16"><a href="4.3-mod-04-dists1.html#cb959-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>){</span>
<span id="cb959-17"><a href="4.3-mod-04-dists1.html#cb959-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">points</span>(x1[[i]], y[[i]], <span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span>cols[i])</span>
<span id="cb959-18"><a href="4.3-mod-04-dists1.html#cb959-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb959-19"><a href="4.3-mod-04-dists1.html#cb959-19" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;n=100&quot;</span>, <span class="st">&quot;n=1000&quot;</span>, <span class="st">&quot;n=10000&quot;</span>),</span>
<span id="cb959-20"><a href="4.3-mod-04-dists1.html#cb959-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">bty=</span><span class="st">&quot;n&quot;</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span>cols[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>])</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-363-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
<div id="distributions-summary" class="section level3" number="4.3.5">
<h3><span class="header-section-number">4.3.5</span> Distributions summary</h3>
<p>The table below summarizes some the key features of the <strong>discrete distributions</strong> we explored in this module.</p>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th>Distribution</th>
<th>Support</th>
<th>What it models</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bernoulli</td>
<td>0 or 1</td>
<td>Outcome of a single binary trial</td>
</tr>
<tr class="even">
<td>Binomial</td>
<td>[0, <em>n</em>]</td>
<td>Number of successes in <em>n</em> trials with constant probability <em>p</em>.</td>
</tr>
<tr class="odd">
<td>Poisson</td>
<td>[0, <span class="math inline">\(+\infty\)</span>]</td>
<td>Number of events occurring independently at constant rate (i.e., count data)</td>
</tr>
<tr class="even">
<td>Negative binomial</td>
<td>[0, <span class="math inline">\(+\infty\)</span>]</td>
<td>Number of failures until a success; or, counts with overdispersion</td>
</tr>
<tr class="odd">
<td>Geometric</td>
<td>[0, <span class="math inline">\(+\infty\)</span>]</td>
<td>Number of trials until a single failure with constant probability</td>
</tr>
<tr class="even">
<td>Beta-binomial</td>
<td>[0, <em>n</em>]</td>
<td>Number of successes in <em>n</em> trials, with varying <em>p</em>.</td>
</tr>
<tr class="odd">
<td>Multinomial</td>
<td>[0, <em>n</em>] for each <em>x<sub>i</sub></em>, with sum(<em>x<sub>i</sub></em>) = <em>n</em></td>
<td>Number of counts <em>x<sub>i</sub></em> in <em>k</em> categories out of <em>n</em> trials.</td>
</tr>
</tbody>
</table>
<p>The table below summarizes some the key features of the <strong>continuous distributions</strong> we explored in this module.</p>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th>Distribution</th>
<th>Support</th>
<th>What it models</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Uniform</td>
<td>[min, max]</td>
<td>Continuous variables where all values are equally likely.</td>
</tr>
<tr class="even">
<td>Normal</td>
<td>[<span class="math inline">\(-\infty\)</span>, <span class="math inline">\(+\infty\)</span>]</td>
<td>Many natural processes</td>
</tr>
<tr class="odd">
<td>Lognormal</td>
<td>(0, <span class="math inline">\(+\infty\)</span>)</td>
<td>Many processes that are normally distributed on log scale; values arising from multiplicative processes</td>
</tr>
<tr class="even">
<td>Gamma</td>
<td>(0, <span class="math inline">\(+\infty\)</span>]</td>
<td>Waiting times until an event occurs</td>
</tr>
<tr class="odd">
<td>Beta</td>
<td>[0, 1]</td>
<td>Probabilities of single events (i.e., probabilities for binomial processes)</td>
</tr>
<tr class="even">
<td>Dirichlet</td>
<td>[0, 1] for each <em>x<sub>i</sub></em>, and sum(<em>x<sub>i</sub></em>) = 1</td>
<td>Probabilities of multiple events (i.e., probabilities for multinomial processes)</td>
</tr>
<tr class="odd">
<td>Exponential</td>
<td>[0, <span class="math inline">\(+\infty\)</span>]</td>
<td>Waiting times between events</td>
</tr>
<tr class="even">
<td>Triangular</td>
<td>[min, max]</td>
<td>Continuous variables about which little is known; requires minimum, maximum, and mode.</td>
</tr>
</tbody>
</table>
<hr />
</div>
</div>
<h3>Literature Cited</h3>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-carnell2019" class="csl-entry">
Carnell, R. 2019. <a href="https://CRAN.R-project.org/package=triangle">Triangle: Provides the standard distribution functions for the triangle distribution</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="4.2-mod-04-vis.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="4.4-mod-04-dists2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
